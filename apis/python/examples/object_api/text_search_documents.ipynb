{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document text search\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"true\"\n",
    "import tiledb\n",
    "from tiledb.vector_search.object_api import object_index\n",
    "from tiledb.vector_search.object_readers import DirectoryTextReader\n",
    "from tiledb.vector_search.embeddings import SentenceTransformersEmbedding, LangChainEmbedding\n",
    "\n",
    "dataset = \"documents\"\n",
    "base_uri = f\"/tmp/{dataset}_demo\"\n",
    "documents_uri = f\"{base_uri}/documents\"\n",
    "index_uri = f\"{base_uri}/index\"\n",
    "config = {}\n",
    "vfs = tiledb.VFS(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create vector search index\n",
    "\n",
    "We point to a document directory that contains multiple files of different types (.pdf, .docx, .html, .jpg, .png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blogs', '.DS_Store', 'img', 'TileDB_Vector_Search_in_LangChain.docx', 'TileDB_Vector_Search_Updates.docx', 'VLDB17_TileDB.pdf']\n",
      "['TileDB_Vector_Search_101.html', '.DS_Store']\n",
      "['.DS_Store', 'TileDB_embedded_arch.png', 'TileDB_cloud_arch.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(documents_uri))\n",
    "print(os.listdir(f\"{documents_uri}/blogs\"))\n",
    "print(os.listdir(f\"{documents_uri}/img\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vector index using an open source text embedding function from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vfs.is_dir(index_uri):\n",
    "    vfs.remove_dir(index_uri)\n",
    "vfs.create_dir(index_uri)\n",
    "\n",
    "reader = DirectoryTextReader(\n",
    "        search_uri=documents_uri,\n",
    "        text_splitter=\"RecursiveCharacterTextSplitter\",\n",
    "        text_splitter_kwargs={\"chunk_size\":1000}\n",
    "    )\n",
    "embedding = SentenceTransformersEmbedding(model_name_or_path='BAAI/bge-small-en-v1.5', dimensions=384)\n",
    "# embedding = LangChainEmbedding(\n",
    "#     dimensions=384, \n",
    "#     embedding_class=\"HuggingFaceEmbeddings\", \n",
    "#     embedding_kwargs={\n",
    "#         \"model_name\": 'BAAI/bge-small-en-v1.5', \n",
    "#         }\n",
    "# )\n",
    "# embedding = LangChainEmbedding(\n",
    "#     dimensions=1536, \n",
    "#     embedding_class=\"OpenAIEmbeddings\", \n",
    "#     embedding_kwargs={\n",
    "#         \"model\": 'text-embedding-ada-002', \n",
    "#         }\n",
    "# )\n",
    "index = object_index.create(\n",
    "    uri=index_uri,\n",
    "    index_type=\"IVF_FLAT\",\n",
    "    object_reader=reader,\n",
    "    embedding=embedding,\n",
    "    config=config,\n",
    ")\n",
    "index.update_index(\n",
    "    files_per_partition=100,\n",
    "    config=config,\n",
    ")\n",
    "index = object_index.ObjectIndex(uri=index_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query\n",
    "\n",
    "Text similarity query with file type restrict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: file:///tmp/documents_demo/documents/VLDB17_TileDB.pdf\n",
      "Text: 359\n",
      "\n",
      "6.2 Sparse Arrays\n",
      "\n",
      "We next focus on sparse arrays, comparing TileDB with Vertica+Z (gzip-compressed and following SRAM [19]) and SciDB on the AIS dataset. HDF5 is not optimized for sparse arrays, thus we omit it from these experiments.\n"
     ]
    }
   ],
   "source": [
    "def display_results(results):\n",
    "    file_paths = results[\"file_path\"][0]\n",
    "    texts = results[\"text\"][0]\n",
    "    i = 0\n",
    "    for text in texts:\n",
    "        print(f\"File: {file_paths[i]}\")\n",
    "        print(f\"Text: {text}\")\n",
    "        i += 1\n",
    "\n",
    "def pdf_filter_fn(row):\n",
    "    return \".pdf\" in row['file_path']\n",
    "\n",
    "distances, _, results = index.query(\n",
    "                            {\"text\": [\"sparse arrays\"]}, \n",
    "                            metadata_df_filter_fn=pdf_filter_fn,\n",
    "                            k=1,\n",
    "                            nprobe=index.index.partitions,\n",
    "                            return_objects=False,\n",
    "                            return_metadata=True,\n",
    "                        )\n",
    "display_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiledb_vs_10_arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
