[
  {
    "objectID": "documentation/storage-format-spec.html",
    "href": "documentation/storage-format-spec.html",
    "title": "Storage Format Spec",
    "section": "",
    "text": "The underlying storage model used for indexing vectors in TileDB-Vector-Search is heavily dependent on the indexing algorithm used. However, there are also high level structures that are used across algorithms.",
    "crumbs": [
      "Home page",
      "Storage Format Spec"
    ]
  },
  {
    "objectID": "documentation/storage-format-spec.html#cross-algorithm-storage-format",
    "href": "documentation/storage-format-spec.html#cross-algorithm-storage-format",
    "title": "Storage Format Spec",
    "section": "Cross algorithm storage format",
    "text": "Cross algorithm storage format\nAll data and metadata required for a TileDB-Vector-Search index are stored inside a TileDB group (index_uri). All the listed, named arrays below are stored under this URI.\n\nIndex metadata\nMetadata values required for configuring the different properties of an index are stored in the index_uri group metadata. There are some metadata values that are required for all algorithm implementations as well as per-algorithm specific metadata values. Below is a table of all the metadata values that are recorded for all algorithms.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ndataset_type\nThe asset type for disambiguation in TileDB cloud. Value: vector_search\n\n\nindex_type\nThe index algorithm used for this index. Can be one of the following values: FLAT, IVF_FLAT, VAMANA, IVF_PQ\n\n\nstorage_version\nThe storage version used for the index. The storage version is used to make sure that indexing algorithms can update their storage logic without affecting previously created indexes and maintaining backwards compatibility.\n\n\ndtype\nThe data type of the vector values.\n\n\ningestion_timestamps\nAn ordered list of timestamps that correspond to different calls of ingestion and update consolidation through the lifetime of the index.\n\n\nbase_sizes\nAn ordered list of number of vectors in the base index at the different ingestion timestamps.\n\n\nhas_updates\nBoolean value denoting if there are updates recorded in the updates array.\n\n\n\n\n\nObject metadata\nThis is a 1D sparse array with external_id as dimension and attributes the user defined metadata attributes for the respective vectors.\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nSparse\n\n\nRank\n1D\n\n\nCell order\nRow-major\n\n\nTile order\nRow-major\n\n\n\n\n\nDimensions\n\n\n\nDimension Name\nTileDB Datatype\n\n\n\n\nexternal_id\nuint64_t\n\n\n\n\n\n\nUpdates\nTileDB-Vector-Search offers support for updates for all different index algorithms by recording updates outside the main indexing storage structure and periodically consolidating them. This implementation is using the updates array, a sparse 1D array with dimension the external_ids of the vectors and 1 variable length attribute encoding the vector itself or an empty value if the vector is deleted.\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nSparse\n\n\nRank\n1D\n\n\nCell order\nRow-major\n\n\nTile order\nRow-major\n\n\n\n\n\nDimensions\n\n\n\nDimension Name\nTileDB Datatype\n\n\n\n\nexternal_id\nuint64_t\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvector\nvariable dtype\nContains the vector value. Empty values correspond to vector deletions.",
    "crumbs": [
      "Home page",
      "Storage Format Spec"
    ]
  },
  {
    "objectID": "documentation/storage-format-spec.html#algorithm-specific-storage-format",
    "href": "documentation/storage-format-spec.html#algorithm-specific-storage-format",
    "title": "Storage Format Spec",
    "section": "Algorithm specific storage format",
    "text": "Algorithm specific storage format\n\nFLAT\n\nshuffled_vectors\nThis is a 2D dense array that holds all the vectors with no specific ordering.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n2D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, dimensions]\nCorresponds to the vector dimensions.\n\n\ncols\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in the set of vectors.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\ndtype\nContains the vector value at the specific dimension.\n\n\n\n\n\nshuffled_ids\nThis is a 1D dense array that maps vector positions in the shuffled_vectors array to external_ids of each vector.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n1D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in shuffled_vectors.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\nuint64_t\nContains the vector’s external_id.\n\n\n\n\n\n\nIVF_FLAT\n\nMetadata\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\npartition_history\nAn ordered list of the number of partitions used at different ingestion timestamps.\n\n\n\n\n\npartition_centroids\nThis is a 2D dense array storing the k-means centroids for the different vector partitions.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n2D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, dimensions]\nCorresponds to the centroid dimensions.\n\n\ncols\nint32_t\n[0, MAX_INT32]\nCorresponds to the centroid id.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\ncentroids\ndtype\nContains the centroid value at the specific dimension.\n\n\n\n\n\npartition_indexes\nThis is a 1D dense array recording the start-end index of each partition of vectors in the shuffled_vectors array.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n1D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, MAX_INT32]\nCorresponds to the partition id.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\nuint64_t\nContains to the position of the partition split in the shuffled_vectors array.\n\n\n\n\n\nshuffled_vectors\nThis is a 2D dense array that holds all the vectors. Each vector partition is stored in a consecutive index range of this array.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n2D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, dimensions]\nCorresponds to the vector dimensions.\n\n\ncols\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in the set of vectors.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\ndtype\nContains the vector value at the specific dimension.\n\n\n\n\n\nshuffled_ids\nThis is a 1D dense array that maps vector indices in the shuffled_vectors array to external_ids of each vector.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n1D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in shuffled_vectors.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\nuint64_t\nContains the vector external_id.\n\n\n\n\n\n\nVAMANA\n\nMetadata\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nl_build\nThe l_build parameter used when constructing the graph.\n\n\nr_max_degree\nThe r_max_degree parameter used when constructing the graph.\n\n\n\n\n\nshuffled_vectors\nThis is a 2D dense array that holds all the vectors. Each vector partition is stored in a consecutive index range of this array.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n2D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, dimensions]\nCorresponds to the vector dimensions.\n\n\ncols\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in the set of vectors.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\ndtype\nContains the vector value at the specific dimension.\n\n\n\n\n\nshuffled_ids\nThis is a 1D dense array that maps vector indices in the shuffled_vectors array to external_ids of each vector.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n1D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in shuffled_vectors.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\nuint64_t\nContains the vector external_id.\n\n\n\n\n\nadjacency_row_index_array_name\nThis is a 1D dense array that holds the edges for each node in the compressed sparse row (CSR) format graph. Each value indicates where the neighbors (edges) for each successive node start in adjacency_ids and adjacency_scores. For example, we might have [0, 2, 8, 13] which indicates that the neighbors for node 0 start at index 0, the neighbors for node 1 start at index 2, and the neighbors for node 2 start at index 8. The final value is the end of the array, so the neighbors for node 2 end at index 13. With that information, we can look in adjacency_ids to determine the destination node. The source node can be inferred by the index of the Adjacency Row Indices array. Once you know the source or destination node index, you can look at that index in shuffled_vectors or shuffled_ids to get the vector or external ID for that node.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n1D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in shuffled_vectors and shuffled_ids.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\nuint64_t\nContains the start and stop indexes in adjacency_ids and adjacency_scores for the node.\n\n\n\n\n\nadjacency_ids\nThis is a 1D dense array that holds the indexes of the destination vector for each edge in the compressed sparse row (CSR) format graph. Each value is an index into the shuffled_vectors and shuffled_ids arrays. This only holds the destination nodes of the graph, the source node is in adjacency_row_index_array_name, which itself points to adjacency_ids.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n1D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in shuffled_vectors and shuffled_ids.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\nuint64_t\nContains the index of the destination vector for this edge in the graph.\n\n\n\n\n\nadjacency_scores\nThis is a 1D dense array that holds the distance of the edge in adjacency_ids in the compressed sparse row (CSR) format graph. This follows the same pattern as adjacency_ids, but holds the edge distance instead of the destination node.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n1D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in adjacency_ids.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\nfloat\nContains the distance between neighbors in the graph.",
    "crumbs": [
      "Home page",
      "Storage Format Spec"
    ]
  },
  {
    "objectID": "documentation/Building.html",
    "href": "documentation/Building.html",
    "title": "Building and Running Tests",
    "section": "",
    "text": "TileDB Vector Search can be built from source for either C++ or Python.\n\n\nTo build for C++, run:\n# Configure:\ncmake -S ./src -B ./src/build -DCMAKE_BUILD_TYPE=Debug\n# Build:\ncmake --build ./src/build -j3\n# Run tests:\ncmake --build ./src/build --target check\nThough above makes it easy to build and run all tests, incremental rebuild will not work. To get incremental rebuild working, we turn off Superbuild with -DCMAKE_IDE=ON. Note that unlike when using Superbuild (which is the default when -DCMAKE_IDE=ON is not set), you must pass -DTileDB_DIR:PATH.\n# Configure:\ncmake -S ./src -B ./src/build  -DCMAKE_BUILD_TYPE=Debug -DCMAKE_IDE=ON -DTileDB_DIR:PATH=/Users/&lt;name&gt;/repo/tileDB/build/dist\n# Build everything:\ncmake --build ./src/build -j3\n# Build a single unit test:\ncmake --build ./src/build --target unit_tdb_partitioned_matrix\n# Run that single unit test:\n./src/build/include/test/unit_tdb_partitioned_matrix\nAlternatively, you can setup CLion, which is the suggested way to develop C++ in this project. To set up CLion:\n\nOpen up CLion to the root directory of this repo.\nGo to File -&gt; Settings -&gt; Build, Execution, Deployment -&gt; CMake.\n\nSet CMake options to G \"Unix Makefiles\" -DCMAKE_IDE=ON -DTileDB_DIR:PATH=/Users/&lt;name&gt;/repo/tileDB/build/dist -DTILEDB_VS_ENABLE_BLAS=on -DTILEDB_VS_PYTHON=off.\n\nNote that DTileDB_DIR will be specific to your TileDB installation. If you have it installed in a standard location, you can omit this option.\n\nSet Build directory to cmake-build-debug/libtiledbvectorsearch.\n\nNext right click on src/CMakeLists.txt and select Load CMake Project.\nAfter that you should see configurations for unit tests and build targets automatically generated by CLion.\n\nTo build with sanitizers, you can add -DTILEDB_SANITIZER=\"${sanitizer}\", where sanitizer = (address|memory|leak|thread). For example:\ncmake -S ./src -B ./src/build -DCMAKE_BUILD_TYPE=Debug -DTILEDB_SANITIZER=\"address\"\ncmake --build ./src/build -j3\ncmake --build ./src/build --target check\n\n\n\nBefore building you may want to set up a virtual environment:\nconda create --name TileDB-Vector-Search python=3.9\nconda activate TileDB-Vector-Search\nTo build for Python, run:\npip install .\nYou can run unit tests with pytest. You’ll also need to install the test dependencies:\npip install \".[test]\"\nThen you can run the tests:\ncd apis/python\n# To run all tests.\npytest\n# To run a single test and display standard output and standard error.\npytest test/test_ingestion.py -s\nTo test Demo notebooks:\ncd apis/python\npip install -r test/ipynb/requirements.txt\npytest --nbmake test/ipynb\nCredentials:\n\nSome tests run on TileDB Cloud using your current environment variable TILEDB_REST_TOKEN - you will need a valid API token for the tests to pass. See Create API Tokens for for instructions on getting one.\nFor continuous integration, the token is configured for the unittest user and all tests should pass.\n\n\n\n\nFirst install quarto with their instructions or with Homebrew.\nThen run:\npip install quartodoc\nquartodoc build\nquarto render --fail-if-warnings\nYou can them open up docs/documentation/index.html in a web browser to preview the results.",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/Building.html#c",
    "href": "documentation/Building.html#c",
    "title": "Building and Running Tests",
    "section": "",
    "text": "To build for C++, run:\n# Configure:\ncmake -S ./src -B ./src/build -DCMAKE_BUILD_TYPE=Debug\n# Build:\ncmake --build ./src/build -j3\n# Run tests:\ncmake --build ./src/build --target check\nThough above makes it easy to build and run all tests, incremental rebuild will not work. To get incremental rebuild working, we turn off Superbuild with -DCMAKE_IDE=ON. Note that unlike when using Superbuild (which is the default when -DCMAKE_IDE=ON is not set), you must pass -DTileDB_DIR:PATH.\n# Configure:\ncmake -S ./src -B ./src/build  -DCMAKE_BUILD_TYPE=Debug -DCMAKE_IDE=ON -DTileDB_DIR:PATH=/Users/&lt;name&gt;/repo/tileDB/build/dist\n# Build everything:\ncmake --build ./src/build -j3\n# Build a single unit test:\ncmake --build ./src/build --target unit_tdb_partitioned_matrix\n# Run that single unit test:\n./src/build/include/test/unit_tdb_partitioned_matrix\nAlternatively, you can setup CLion, which is the suggested way to develop C++ in this project. To set up CLion:\n\nOpen up CLion to the root directory of this repo.\nGo to File -&gt; Settings -&gt; Build, Execution, Deployment -&gt; CMake.\n\nSet CMake options to G \"Unix Makefiles\" -DCMAKE_IDE=ON -DTileDB_DIR:PATH=/Users/&lt;name&gt;/repo/tileDB/build/dist -DTILEDB_VS_ENABLE_BLAS=on -DTILEDB_VS_PYTHON=off.\n\nNote that DTileDB_DIR will be specific to your TileDB installation. If you have it installed in a standard location, you can omit this option.\n\nSet Build directory to cmake-build-debug/libtiledbvectorsearch.\n\nNext right click on src/CMakeLists.txt and select Load CMake Project.\nAfter that you should see configurations for unit tests and build targets automatically generated by CLion.\n\nTo build with sanitizers, you can add -DTILEDB_SANITIZER=\"${sanitizer}\", where sanitizer = (address|memory|leak|thread). For example:\ncmake -S ./src -B ./src/build -DCMAKE_BUILD_TYPE=Debug -DTILEDB_SANITIZER=\"address\"\ncmake --build ./src/build -j3\ncmake --build ./src/build --target check",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/Building.html#python",
    "href": "documentation/Building.html#python",
    "title": "Building and Running Tests",
    "section": "",
    "text": "Before building you may want to set up a virtual environment:\nconda create --name TileDB-Vector-Search python=3.9\nconda activate TileDB-Vector-Search\nTo build for Python, run:\npip install .\nYou can run unit tests with pytest. You’ll also need to install the test dependencies:\npip install \".[test]\"\nThen you can run the tests:\ncd apis/python\n# To run all tests.\npytest\n# To run a single test and display standard output and standard error.\npytest test/test_ingestion.py -s\nTo test Demo notebooks:\ncd apis/python\npip install -r test/ipynb/requirements.txt\npytest --nbmake test/ipynb\nCredentials:\n\nSome tests run on TileDB Cloud using your current environment variable TILEDB_REST_TOKEN - you will need a valid API token for the tests to pass. See Create API Tokens for for instructions on getting one.\nFor continuous integration, the token is configured for the unittest user and all tests should pass.",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/Building.html#quarto",
    "href": "documentation/Building.html#quarto",
    "title": "Building and Running Tests",
    "section": "",
    "text": "First install quarto with their instructions or with Homebrew.\nThen run:\npip install quartodoc\nquartodoc build\nquarto render --fail-if-warnings\nYou can them open up docs/documentation/index.html in a web browser to preview the results.",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/Building.html#linux",
    "href": "documentation/Building.html#linux",
    "title": "Building and Running Tests",
    "section": "Linux",
    "text": "Linux\nThere are several dependencies needed, for Ubuntu you can install via:\napt-get openblas-dev build-essentials cmake3\nTo build the python API after you have the dependencies, use pip:\npip install .",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/Building.html#docker",
    "href": "documentation/Building.html#docker",
    "title": "Building and Running Tests",
    "section": "Docker",
    "text": "Docker\nA docker image is also provided for simplicity:\ndocker build -t tiledb/tiledb-vector-search .\nYou run the example docker image which provides the python package with:\ndocker run --rm tiledb/tiledb-vector-search",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/reference/open.html",
    "href": "documentation/reference/open.html",
    "title": "open",
    "section": "",
    "text": "vector_search.open(uri, open_for_remote_query_execution=False, config=None, timestamp=None, **kwargs)\nFactory method that opens a vector index.\nRetrieves the index_type from the index group metadata and instantiates the appropriate Index subclass.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nFalse\n\n\nkwargs\n\nAdditional arguments to be passed to the Index subclass constructor.\n{}"
  },
  {
    "objectID": "documentation/reference/open.html#parameters",
    "href": "documentation/reference/open.html#parameters",
    "title": "open",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nFalse\n\n\nkwargs\n\nAdditional arguments to be passed to the Index subclass constructor.\n{}"
  },
  {
    "objectID": "documentation/reference/object_readers.ObjectPartition.html",
    "href": "documentation/reference/object_readers.ObjectPartition.html",
    "title": "object_readers.ObjectPartition",
    "section": "",
    "text": "vector_search.object_readers.ObjectPartition()\nAbstract class for capturing object partitions\n\n\n\n\n\nName\nDescription\n\n\n\n\nid\nReturns the id of the ObjectPartition.\n\n\ninit_kwargs\nReturns a dictionary containing kwargs that can be used to re-initialize the ObjectPartition.\n\n\n\n\n\nvector_search.object_readers.ObjectPartition.id()\nReturns the id of the ObjectPartition.\n\n\n\nvector_search.object_readers.ObjectPartition.init_kwargs()\nReturns a dictionary containing kwargs that can be used to re-initialize the ObjectPartition.\nThis is used to serialize the ObjectPartition and pass it as argument to UDF tasks."
  },
  {
    "objectID": "documentation/reference/object_readers.ObjectPartition.html#methods",
    "href": "documentation/reference/object_readers.ObjectPartition.html#methods",
    "title": "object_readers.ObjectPartition",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nid\nReturns the id of the ObjectPartition.\n\n\ninit_kwargs\nReturns a dictionary containing kwargs that can be used to re-initialize the ObjectPartition.\n\n\n\n\n\nvector_search.object_readers.ObjectPartition.id()\nReturns the id of the ObjectPartition.\n\n\n\nvector_search.object_readers.ObjectPartition.init_kwargs()\nReturns a dictionary containing kwargs that can be used to re-initialize the ObjectPartition.\nThis is used to serialize the ObjectPartition and pass it as argument to UDF tasks."
  },
  {
    "objectID": "documentation/reference/flat_index.html",
    "href": "documentation/reference/flat_index.html",
    "title": "flat_index",
    "section": "",
    "text": "vector_search.flat_index\nFlatIndex implementation.\nStores all vectors in a 2D TileDB array performing exhaustive similarity search between the query vectors and all the dataset vectors.\n\n\n\n\n\nName\nDescription\n\n\n\n\nFlatIndex\nOpens a FlatIndex loading all dataset vectors in main memory.\n\n\n\n\n\nvector_search.flat_index.FlatIndex(self, uri, config=None, timestamp=None, open_for_remote_query_execution=False, group=None, **kwargs)\nOpens a FlatIndex loading all dataset vectors in main memory.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nFalse\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries a FlatIndex using the vectors already loaded in main memory.\n\n\nvacuum\nThe vacuuming process permanently deletes index files that are consolidated through the consolidation\n\n\n\n\n\nvector_search.flat_index.FlatIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.flat_index.FlatIndex.query_internal(queries, k=10, nthreads=8, **kwargs)\nQueries a FlatIndex using the vectors already loaded in main memory.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nnthreads\nint\nNumber of threads to use for query execution.\n8\n\n\n\n\n\n\n\nvector_search.flat_index.FlatIndex.vacuum()\nThe vacuuming process permanently deletes index files that are consolidated through the consolidation process. TileDB separates consolidation from vacuuming, in order to make consolidation process-safe in the presence of concurrent reads and writes.\nNote:\n\nVacuuming is not process-safe and you should take extra care when invoking it.\nVacuuming may affect the granularity of the time traveling functionality.\n\nThe Flat class vacuums consolidated fragment, array metadata and commits for the db and ids arrays.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate\nCreates an empty FlatIndex.\n\n\n\n\n\nvector_search.flat_index.create(uri, dimensions, vector_type, group_exists=False, group=None, config=None, storage_version=STORAGE_VERSION, distance_metric=vspy.DistanceMetric.SUM_OF_SQUARES, asset_creation_threads=None, **kwargs)\nCreates an empty FlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\ngroup_exists\nbool\nIf False it creates the TileDB group for the index. If True the method expects the TileDB group to be already created.\nFalse\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use hte latest stable storage version.\nSTORAGE_VERSION\n\n\ndistance_metric\nvspy.DistanceMetric\nDistance metric to use for the index. If not provided, use L2 distance.\nvspy.DistanceMetric.SUM_OF_SQUARES\n\n\ngroup\ntiledb.Group\nTileDB group open in write mode. Internal, this is used to avoid opening the group multiple times during ingestion.\nNone\n\n\nasset_creation_threads\nSequence[Thread]\nList of asset creation threads to append new threads. Internal, this is used to parallelize all asset creation during ingestion.\nNone"
  },
  {
    "objectID": "documentation/reference/flat_index.html#classes",
    "href": "documentation/reference/flat_index.html#classes",
    "title": "flat_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nFlatIndex\nOpens a FlatIndex loading all dataset vectors in main memory.\n\n\n\n\n\nvector_search.flat_index.FlatIndex(self, uri, config=None, timestamp=None, open_for_remote_query_execution=False, group=None, **kwargs)\nOpens a FlatIndex loading all dataset vectors in main memory.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nFalse\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries a FlatIndex using the vectors already loaded in main memory.\n\n\nvacuum\nThe vacuuming process permanently deletes index files that are consolidated through the consolidation\n\n\n\n\n\nvector_search.flat_index.FlatIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.flat_index.FlatIndex.query_internal(queries, k=10, nthreads=8, **kwargs)\nQueries a FlatIndex using the vectors already loaded in main memory.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nnthreads\nint\nNumber of threads to use for query execution.\n8\n\n\n\n\n\n\n\nvector_search.flat_index.FlatIndex.vacuum()\nThe vacuuming process permanently deletes index files that are consolidated through the consolidation process. TileDB separates consolidation from vacuuming, in order to make consolidation process-safe in the presence of concurrent reads and writes.\nNote:\n\nVacuuming is not process-safe and you should take extra care when invoking it.\nVacuuming may affect the granularity of the time traveling functionality.\n\nThe Flat class vacuums consolidated fragment, array metadata and commits for the db and ids arrays."
  },
  {
    "objectID": "documentation/reference/flat_index.html#functions",
    "href": "documentation/reference/flat_index.html#functions",
    "title": "flat_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate\nCreates an empty FlatIndex.\n\n\n\n\n\nvector_search.flat_index.create(uri, dimensions, vector_type, group_exists=False, group=None, config=None, storage_version=STORAGE_VERSION, distance_metric=vspy.DistanceMetric.SUM_OF_SQUARES, asset_creation_threads=None, **kwargs)\nCreates an empty FlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\ngroup_exists\nbool\nIf False it creates the TileDB group for the index. If True the method expects the TileDB group to be already created.\nFalse\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use hte latest stable storage version.\nSTORAGE_VERSION\n\n\ndistance_metric\nvspy.DistanceMetric\nDistance metric to use for the index. If not provided, use L2 distance.\nvspy.DistanceMetric.SUM_OF_SQUARES\n\n\ngroup\ntiledb.Group\nTileDB group open in write mode. Internal, this is used to avoid opening the group multiple times during ingestion.\nNone\n\n\nasset_creation_threads\nSequence[Thread]\nList of asset creation threads to append new threads. Internal, this is used to parallelize all asset creation during ingestion.\nNone"
  },
  {
    "objectID": "documentation/reference/object_readers.ObjectReader.html",
    "href": "documentation/reference/object_readers.ObjectReader.html",
    "title": "object_readers.ObjectReader",
    "section": "",
    "text": "vector_search.object_readers.ObjectReader()\nAbstract class that can be used to read Objects from different sources and formats.\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_partitions\nReturns a list of ObjectPartitions for the reader.\n\n\ninit_kwargs\nReturns a dictionary containing kwargs that can be used to re-initialize the ObjectReader.\n\n\nmetadata_array_uri\nReturns the URI of a TileDB array that can be used to read Object metadata.\n\n\nmetadata_attributes\nReturns a list of TileDB Attributes describing the metadata of the Objects.\n\n\npartition_class_name\nReturns the class name of ObjectPartition generated by this ObjectReader.\n\n\nread_objects\nReads the objects corresponding to an ObjectPartition.\n\n\nread_objects_by_external_ids\nReads the objects corresponding to a list of external_ids.\n\n\n\n\n\nvector_search.object_readers.ObjectReader.get_partitions(**kwargs)\nReturns a list of ObjectPartitions for the reader. Each partition can be read independently and used for distributed embedding and ingestion.\n\n\n\nvector_search.object_readers.ObjectReader.init_kwargs()\nReturns a dictionary containing kwargs that can be used to re-initialize the ObjectReader.\nThis is used to serialize the ObjectReader and pass it as argument to UDF tasks.\n\n\n\nvector_search.object_readers.ObjectReader.metadata_array_uri()\nReturns the URI of a TileDB array that can be used to read Object metadata. This array should have only one external_id dimension and attributes the list of TileDB attributes returned by metadata_attributes.\nReturns None, if a metadata array does not exist and should be materialized by object ingestion.\n\n\n\nvector_search.object_readers.ObjectReader.metadata_attributes()\nReturns a list of TileDB Attributes describing the metadata of the Objects.\nReturns None, if there are no Object metadata.\n\n\n\nvector_search.object_readers.ObjectReader.partition_class_name()\nReturns the class name of ObjectPartition generated by this ObjectReader.\nThe ObjectPartition class should be defined in the same Python file as the ObjectReader.\n\n\n\nvector_search.object_readers.ObjectReader.read_objects(partition)\nReads the objects corresponding to an ObjectPartition.\nReturns a tuple containing the object data and metadata respectively. Data and metadata are OrderedDicts having structure similar to TileDB-Py read results. Data and metadata should contain at least an external_id dimension used to identify the different objects.\n\n\n\nvector_search.object_readers.ObjectReader.read_objects_by_external_ids(ids)\nReads the objects corresponding to a list of external_ids.\nReturns an OrderedDict, containing the object data, having structure similar to TileDB-Py read results."
  },
  {
    "objectID": "documentation/reference/object_readers.ObjectReader.html#methods",
    "href": "documentation/reference/object_readers.ObjectReader.html#methods",
    "title": "object_readers.ObjectReader",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_partitions\nReturns a list of ObjectPartitions for the reader.\n\n\ninit_kwargs\nReturns a dictionary containing kwargs that can be used to re-initialize the ObjectReader.\n\n\nmetadata_array_uri\nReturns the URI of a TileDB array that can be used to read Object metadata.\n\n\nmetadata_attributes\nReturns a list of TileDB Attributes describing the metadata of the Objects.\n\n\npartition_class_name\nReturns the class name of ObjectPartition generated by this ObjectReader.\n\n\nread_objects\nReads the objects corresponding to an ObjectPartition.\n\n\nread_objects_by_external_ids\nReads the objects corresponding to a list of external_ids.\n\n\n\n\n\nvector_search.object_readers.ObjectReader.get_partitions(**kwargs)\nReturns a list of ObjectPartitions for the reader. Each partition can be read independently and used for distributed embedding and ingestion.\n\n\n\nvector_search.object_readers.ObjectReader.init_kwargs()\nReturns a dictionary containing kwargs that can be used to re-initialize the ObjectReader.\nThis is used to serialize the ObjectReader and pass it as argument to UDF tasks.\n\n\n\nvector_search.object_readers.ObjectReader.metadata_array_uri()\nReturns the URI of a TileDB array that can be used to read Object metadata. This array should have only one external_id dimension and attributes the list of TileDB attributes returned by metadata_attributes.\nReturns None, if a metadata array does not exist and should be materialized by object ingestion.\n\n\n\nvector_search.object_readers.ObjectReader.metadata_attributes()\nReturns a list of TileDB Attributes describing the metadata of the Objects.\nReturns None, if there are no Object metadata.\n\n\n\nvector_search.object_readers.ObjectReader.partition_class_name()\nReturns the class name of ObjectPartition generated by this ObjectReader.\nThe ObjectPartition class should be defined in the same Python file as the ObjectReader.\n\n\n\nvector_search.object_readers.ObjectReader.read_objects(partition)\nReads the objects corresponding to an ObjectPartition.\nReturns a tuple containing the object data and metadata respectively. Data and metadata are OrderedDicts having structure similar to TileDB-Py read results. Data and metadata should contain at least an external_id dimension used to identify the different objects.\n\n\n\nvector_search.object_readers.ObjectReader.read_objects_by_external_ids(ids)\nReads the objects corresponding to a list of external_ids.\nReturns an OrderedDict, containing the object data, having structure similar to TileDB-Py read results."
  },
  {
    "objectID": "documentation/reference/ivf_pq_index.html",
    "href": "documentation/reference/ivf_pq_index.html",
    "title": "ivf_pq_index",
    "section": "",
    "text": "vector_search.ivf_pq_index\nIVFPQ Index implementation.\n\n\n\n\n\nName\nDescription\n\n\n\n\nIVFPQIndex\nOpens a IVFPQIndex.\n\n\n\n\n\nvector_search.ivf_pq_index.IVFPQIndex(self, uri, config=None, timestamp=None, memory_budget=-1, preload_k_factor_vectors=False, open_for_remote_query_execution=False, group=None, **kwargs)\nOpens a IVFPQIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nmemory_budget\nint\nMain memory budget, in number of vectors, for query execution. If not provided, all index data are loaded in main memory. Otherwise, no index data are loaded in main memory and this memory budget is applied during queries.\n-1\n\n\npreload_k_factor_vectors\nbool\nWhen using k_factor in a query, we first query for k_factor * k pq-encoded vectors, and then do a re-ranking step using the original input vectors for the top k vectors. If True, we will load all the input vectors in main memory. This can only be used with memory_budget set to -1, and is useful when the input vectors are small enough to fit in memory and you want to speed up re-ranking.\nFalse\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nFalse\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries a IVFPQIndex.\n\n\n\n\n\nvector_search.ivf_pq_index.IVFPQIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.ivf_pq_index.IVFPQIndex.query_internal(queries, k=10, k_factor=1.0, nprobe=100, **kwargs)\nQueries a IVFPQIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nk_factor\nfloat\nTo improve accuracy, IVF_PQ can search for more vectors than requested and then perform re-ranking using the original non-PQ-encoded vectors. This can be slightly slower, but is more accurate. k_factor is the factor by which to increase the number of vectors searched. 1 means we search for exactly k vectors. 10 means we search for 10*k vectors. Defaults to 1.\n1.0\n\n\nnprobe\nOptional[int]\nNumber of partitions to check per query. Use this parameter to trade-off accuracy for latency and cost.\n100\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate\nCreates an empty IVFPQIndex.\n\n\n\n\n\nvector_search.ivf_pq_index.create(uri, dimensions, vector_type, num_subspaces, config=None, storage_version=STORAGE_VERSION, distance_metric=vspy.DistanceMetric.SUM_OF_SQUARES, **kwargs)\nCreates an empty IVFPQIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\nnum_subspaces\nint\nNumber of subspaces to use in the PQ encoding. We will divide the dimensions into num_subspaces parts, and PQ encode each part separately. This means dimensions must be divisible by num_subspaces.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use the latest stable storage version.\nSTORAGE_VERSION"
  },
  {
    "objectID": "documentation/reference/ivf_pq_index.html#classes",
    "href": "documentation/reference/ivf_pq_index.html#classes",
    "title": "ivf_pq_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nIVFPQIndex\nOpens a IVFPQIndex.\n\n\n\n\n\nvector_search.ivf_pq_index.IVFPQIndex(self, uri, config=None, timestamp=None, memory_budget=-1, preload_k_factor_vectors=False, open_for_remote_query_execution=False, group=None, **kwargs)\nOpens a IVFPQIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nmemory_budget\nint\nMain memory budget, in number of vectors, for query execution. If not provided, all index data are loaded in main memory. Otherwise, no index data are loaded in main memory and this memory budget is applied during queries.\n-1\n\n\npreload_k_factor_vectors\nbool\nWhen using k_factor in a query, we first query for k_factor * k pq-encoded vectors, and then do a re-ranking step using the original input vectors for the top k vectors. If True, we will load all the input vectors in main memory. This can only be used with memory_budget set to -1, and is useful when the input vectors are small enough to fit in memory and you want to speed up re-ranking.\nFalse\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nFalse\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries a IVFPQIndex.\n\n\n\n\n\nvector_search.ivf_pq_index.IVFPQIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.ivf_pq_index.IVFPQIndex.query_internal(queries, k=10, k_factor=1.0, nprobe=100, **kwargs)\nQueries a IVFPQIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nk_factor\nfloat\nTo improve accuracy, IVF_PQ can search for more vectors than requested and then perform re-ranking using the original non-PQ-encoded vectors. This can be slightly slower, but is more accurate. k_factor is the factor by which to increase the number of vectors searched. 1 means we search for exactly k vectors. 10 means we search for 10*k vectors. Defaults to 1.\n1.0\n\n\nnprobe\nOptional[int]\nNumber of partitions to check per query. Use this parameter to trade-off accuracy for latency and cost.\n100"
  },
  {
    "objectID": "documentation/reference/ivf_pq_index.html#functions",
    "href": "documentation/reference/ivf_pq_index.html#functions",
    "title": "ivf_pq_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate\nCreates an empty IVFPQIndex.\n\n\n\n\n\nvector_search.ivf_pq_index.create(uri, dimensions, vector_type, num_subspaces, config=None, storage_version=STORAGE_VERSION, distance_metric=vspy.DistanceMetric.SUM_OF_SQUARES, **kwargs)\nCreates an empty IVFPQIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\nnum_subspaces\nint\nNumber of subspaces to use in the PQ encoding. We will divide the dimensions into num_subspaces parts, and PQ encode each part separately. This means dimensions must be divisible by num_subspaces.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use the latest stable storage version.\nSTORAGE_VERSION"
  },
  {
    "objectID": "documentation/reference/index.html",
    "href": "documentation/reference/index.html",
    "title": "Python",
    "section": "",
    "text": "open\nFactory method that opens a vector index.\n\n\ningestion\nVector Search ingestion Utilities\n\n\nindex.Index\nAbstract Vector Index class.\n\n\n\n\n\n\n\n\nflat_index\nFlatIndex implementation.\n\n\nivf_flat_index\nIVFFlat Index implementation.\n\n\nvamana_index\nVamana Index implementation.\n\n\nivf_pq_index\nIVFPQ Index implementation.\n\n\n\n\n\n\n\n\n\n\nobject_api.create\nCreates a new ObjectIndex.\n\n\nobject_api.ObjectIndex\nAn ObjectIndex represents a TileDB Vector Search index that is associated with a\n\n\nembeddings.ObjectEmbedding\nAbstract class that can be used to create embeddings for Objects of a specific format.\n\n\nobject_readers.ObjectReader\nAbstract class that can be used to read Objects from different sources and formats.\n\n\nobject_readers.ObjectPartition\nAbstract class for capturing object partitions",
    "crumbs": [
      "Home page",
      "API Reference",
      "Python"
    ]
  },
  {
    "objectID": "documentation/reference/index.html#vector-api",
    "href": "documentation/reference/index.html#vector-api",
    "title": "Python",
    "section": "",
    "text": "open\nFactory method that opens a vector index.\n\n\ningestion\nVector Search ingestion Utilities\n\n\nindex.Index\nAbstract Vector Index class.\n\n\n\n\n\n\n\n\nflat_index\nFlatIndex implementation.\n\n\nivf_flat_index\nIVFFlat Index implementation.\n\n\nvamana_index\nVamana Index implementation.\n\n\nivf_pq_index\nIVFPQ Index implementation.",
    "crumbs": [
      "Home page",
      "API Reference",
      "Python"
    ]
  },
  {
    "objectID": "documentation/reference/index.html#object-api",
    "href": "documentation/reference/index.html#object-api",
    "title": "Python",
    "section": "",
    "text": "object_api.create\nCreates a new ObjectIndex.\n\n\nobject_api.ObjectIndex\nAn ObjectIndex represents a TileDB Vector Search index that is associated with a\n\n\nembeddings.ObjectEmbedding\nAbstract class that can be used to create embeddings for Objects of a specific format.\n\n\nobject_readers.ObjectReader\nAbstract class that can be used to read Objects from different sources and formats.\n\n\nobject_readers.ObjectPartition\nAbstract class for capturing object partitions",
    "crumbs": [
      "Home page",
      "API Reference",
      "Python"
    ]
  },
  {
    "objectID": "documentation/index.html",
    "href": "documentation/index.html",
    "title": "TileDB Vector Search",
    "section": "",
    "text": "TileDB Vector Search\nTileDB-Vector-Search is a C++ library and Python API for vector search built on top of the TileDB Storage Engine.\n\n\nQuick Links\n\nBuild Instructions\nDocumentation\nPython API reference\n\n\n\nQuick Installation\nTileDB-Vector-Search is available from PyPI or the tiledb conda channel.\nTo install from PyPI with pip, use:\npip install tiledb-vector-search\nTo install from conda, use conda or mamba:\nconda install -c tiledb -c conda-forge tiledb-vector-search\nmamba install -c tiledb -c conda-forge tiledb-vector-search\n\n\nContributing\nWe welcome contributions. Please see Building for development-build instructions. For large new features, please open an issue to discuss goals and approach in order to ensure a smooth PR integration and review process. All contributions must be licensed under the repository’s MIT License.",
    "crumbs": [
      "Home page",
      "TileDB Vector Search"
    ]
  },
  {
    "objectID": "documentation/reference/ivf_flat_index.html",
    "href": "documentation/reference/ivf_flat_index.html",
    "title": "ivf_flat_index",
    "section": "",
    "text": "vector_search.ivf_flat_index\nIVFFlat Index implementation.\nIVFFlatIndex is based on k-means clustering and shuffling of the dataset vectors.\nDuring ingestion, TileDB computes the k-means clusters and shuffles the vectors into partitions. The vectors are stored grouped by partition in a 2D TileDB array allowing for partitions to be read with minimal I/O overhead.\nTo answer a query, the search focuses only on a small number of partitions, based on the query’s proximity to the k-means centroids. This is specified with a parameter called nprobe controlling how many partitions are checked for each query.\nIVFFlatIndex provides a vector search implementation that can trade-off accuracy for performance.\nQueries can be run in multiple modes:\n\nLocal main memory:\n\nLoads the entire index in memory during initialization and uses it to answer queries.\n\nLocal out of core:\n\nAvoids loading index data in memory by interleaving I/O and query execution, respecting the memory budget defined by the user.\n\nDistributed execution:\n\nExecutes the queries using multiple workers in TileDB Cloud.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nIVFFlatIndex\nOpens an IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex(self, uri, config=None, timestamp=None, memory_budget=-1, open_for_remote_query_execution=False, group=None, **kwargs)\nOpens an IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nmemory_budget\nint\nMain memory budget, in number of vectors, for query execution. If not provided, all index data are loaded in main memory. Otherwise, no index data are loaded in main memory and this memory budget is applied during queries.\n-1\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). We then load index data in the taskgraph based on memory_budget. If False, load index data in main memory locally according to memory_budget. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph..\nFalse\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries an IVFFlatIndex.\n\n\nvacuum\nThe vacuuming process permanently deletes index files that are consolidated through the consolidation\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.query_internal(queries, k=10, nprobe=1, nthreads=-1, use_nuv_implementation=False, mode=None, resource_class=None, resources=None, num_partitions=-1, num_workers=-1, **kwargs)\nQueries an IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nnprobe\nint\nNumber of partitions to check per query. Use this parameter to trade-off accuracy for latency and cost. As a rule of thumb, configuring nprobe to be the square root of partitions should result in accuracy close to 100%.\n1\n\n\nnthreads\nint\nNumber of threads to use for local query execution.\n-1\n\n\nuse_nuv_implementation\nbool\nWhether to use the nuv query implementation. Default: False\nFalse\n\n\nmode\nOptional[Mode]\nIf provided the query will be executed using TileDB cloud taskgraphs. For distributed execution you can use REALTIME or BATCH mode. For local execution you can use LOCAL mode.\nNone\n\n\nresource_class\nOptional[str]\nThe name of the resource class to use (“standard” or “large”). Resource classes define maximum limits for cpu and memory usage. Can only be used in REALTIME or BATCH mode. Cannot be used alongside resources. In REALTIME or BATCH mode if neither resource_class nor resources are provided, we default to the “large” resource class.\nNone\n\n\nresources\nOptional[Mapping[str, Any]]\nA specification for the amount of resources to use when executing using TileDB cloud taskgraphs, of the form: {“cpu”: “6”, “memory”: “12Gi”, “gpu”: 1}. Can only be used in BATCH mode. Cannot be used alongside resource_class.\nNone\n\n\nnum_partitions\nint\nOnly relevant for taskgraph based execution. If provided, we split the query execution in that many partitions.\n-1\n\n\nnum_workers\nint\nOnly relevant for taskgraph based execution. If provided, this is the number of workers to use for the query execution.\n-1\n\n\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.vacuum()\nThe vacuuming process permanently deletes index files that are consolidated through the consolidation process. TileDB separates consolidation from vacuuming, in order to make consolidation process-safe in the presence of concurrent reads and writes.\nNote:\n\nVacuuming is not process-safe and you should take extra care when invoking it.\nVacuuming may affect the granularity of the time traveling functionality.\n\nThe IVFFlat class vacuums consolidated fragment, array metadata and commits for the db and ids arrays.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate\nCreates an empty IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.create(uri, dimensions, vector_type, group_exists=False, config=None, storage_version=STORAGE_VERSION, distance_metric=vspy.DistanceMetric.SUM_OF_SQUARES, group=None, asset_creation_threads=None, **kwargs)\nCreates an empty IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\ngroup_exists\nbool\nIf False it creates the TileDB group for the index. If True the method expects the TileDB group to be already created.\nFalse\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use the latest stable storage version.\nSTORAGE_VERSION\n\n\ngroup\ntiledb.Group\nTileDB group open in write mode. Internal, this is used to avoid opening the group multiple times during ingestion.\nNone\n\n\nasset_creation_threads\nSequence[Thread]\nList of asset creation threads to append new threads. Internal, this is used to parallelize all asset creation during ingestion.\nNone"
  },
  {
    "objectID": "documentation/reference/ivf_flat_index.html#classes",
    "href": "documentation/reference/ivf_flat_index.html#classes",
    "title": "ivf_flat_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nIVFFlatIndex\nOpens an IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex(self, uri, config=None, timestamp=None, memory_budget=-1, open_for_remote_query_execution=False, group=None, **kwargs)\nOpens an IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nmemory_budget\nint\nMain memory budget, in number of vectors, for query execution. If not provided, all index data are loaded in main memory. Otherwise, no index data are loaded in main memory and this memory budget is applied during queries.\n-1\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). We then load index data in the taskgraph based on memory_budget. If False, load index data in main memory locally according to memory_budget. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph..\nFalse\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries an IVFFlatIndex.\n\n\nvacuum\nThe vacuuming process permanently deletes index files that are consolidated through the consolidation\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.query_internal(queries, k=10, nprobe=1, nthreads=-1, use_nuv_implementation=False, mode=None, resource_class=None, resources=None, num_partitions=-1, num_workers=-1, **kwargs)\nQueries an IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nnprobe\nint\nNumber of partitions to check per query. Use this parameter to trade-off accuracy for latency and cost. As a rule of thumb, configuring nprobe to be the square root of partitions should result in accuracy close to 100%.\n1\n\n\nnthreads\nint\nNumber of threads to use for local query execution.\n-1\n\n\nuse_nuv_implementation\nbool\nWhether to use the nuv query implementation. Default: False\nFalse\n\n\nmode\nOptional[Mode]\nIf provided the query will be executed using TileDB cloud taskgraphs. For distributed execution you can use REALTIME or BATCH mode. For local execution you can use LOCAL mode.\nNone\n\n\nresource_class\nOptional[str]\nThe name of the resource class to use (“standard” or “large”). Resource classes define maximum limits for cpu and memory usage. Can only be used in REALTIME or BATCH mode. Cannot be used alongside resources. In REALTIME or BATCH mode if neither resource_class nor resources are provided, we default to the “large” resource class.\nNone\n\n\nresources\nOptional[Mapping[str, Any]]\nA specification for the amount of resources to use when executing using TileDB cloud taskgraphs, of the form: {“cpu”: “6”, “memory”: “12Gi”, “gpu”: 1}. Can only be used in BATCH mode. Cannot be used alongside resource_class.\nNone\n\n\nnum_partitions\nint\nOnly relevant for taskgraph based execution. If provided, we split the query execution in that many partitions.\n-1\n\n\nnum_workers\nint\nOnly relevant for taskgraph based execution. If provided, this is the number of workers to use for the query execution.\n-1\n\n\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.vacuum()\nThe vacuuming process permanently deletes index files that are consolidated through the consolidation process. TileDB separates consolidation from vacuuming, in order to make consolidation process-safe in the presence of concurrent reads and writes.\nNote:\n\nVacuuming is not process-safe and you should take extra care when invoking it.\nVacuuming may affect the granularity of the time traveling functionality.\n\nThe IVFFlat class vacuums consolidated fragment, array metadata and commits for the db and ids arrays."
  },
  {
    "objectID": "documentation/reference/ivf_flat_index.html#functions",
    "href": "documentation/reference/ivf_flat_index.html#functions",
    "title": "ivf_flat_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate\nCreates an empty IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.create(uri, dimensions, vector_type, group_exists=False, config=None, storage_version=STORAGE_VERSION, distance_metric=vspy.DistanceMetric.SUM_OF_SQUARES, group=None, asset_creation_threads=None, **kwargs)\nCreates an empty IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\ngroup_exists\nbool\nIf False it creates the TileDB group for the index. If True the method expects the TileDB group to be already created.\nFalse\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use the latest stable storage version.\nSTORAGE_VERSION\n\n\ngroup\ntiledb.Group\nTileDB group open in write mode. Internal, this is used to avoid opening the group multiple times during ingestion.\nNone\n\n\nasset_creation_threads\nSequence[Thread]\nList of asset creation threads to append new threads. Internal, this is used to parallelize all asset creation during ingestion.\nNone"
  },
  {
    "objectID": "documentation/reference/ingestion.html",
    "href": "documentation/reference/ingestion.html",
    "title": "ingestion",
    "section": "",
    "text": "vector_search.ingestion\nVector Search ingestion Utilities\nThis contains the ingestion implementation for different TileDB Vector Search algorithms.\nIt enables:\n\nLocal ingestion:\n\nMulti-threaded execution that can leverage all the available local computing resources.\n\nDistributed ingestion:\n\nDistributed ingestion execution with multiple workers in TileDB Cloud. This can be used to ingest large datasets and speedup ingestion latency.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ningest\nIngest vectors into TileDB.\n\n\n\n\n\nvector_search.ingestion.ingest(index_type, index_uri, *, input_vectors=None, source_uri=None, source_type=None, external_ids=None, external_ids_uri='', external_ids_type=None, updates_uri=None, index_timestamp=None, config=None, namespace=None, size=-1, dimensions=-1, partitions=-1, num_subspaces=-1, l_build=-1, r_max_degree=-1, training_sampling_policy=TrainingSamplingPolicy.FIRST_N, copy_centroids_uri=None, training_sample_size=-1, training_input_vectors=None, training_source_uri=None, training_source_type=None, workers=-1, input_vectors_per_work_item=-1, max_tasks_per_stage=-1, input_vectors_per_work_item_during_sampling=-1, max_sampling_tasks=-1, storage_version=STORAGE_VERSION, verbose=False, trace_id=None, use_sklearn=True, mode=Mode.LOCAL, acn=None, ingest_resources=None, consolidate_partition_resources=None, copy_centroids_resources=None, random_sample_resources=None, kmeans_resources=None, compute_new_centroids_resources=None, assign_points_and_partial_new_centroids_resources=None, write_centroids_resources=None, partial_index_resources=None, distance_metric=vspy.DistanceMetric.SUM_OF_SQUARES, normalized=False, **kwargs)\nIngest vectors into TileDB.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nindex_type\nstr\nType of vector index (FLAT, IVF_FLAT, IVF_PQ, VAMANA).\nrequired\n\n\nindex_uri\nstr\nVector index URI (stored as TileDB group).\nrequired\n\n\ninput_vectors\nOptional[np.ndarray]\nInput vectors, if this is provided it takes precedence over source_uri and source_type.\nNone\n\n\nsource_uri\nOptional[str]\nVectors source URI.\nNone\n\n\nsource_type\nOptional[str]\nType of the source vectors. If left empty it is auto-detected.\nNone\n\n\nexternal_ids\nOptional[np.array]\nInput vector external_ids, if this is provided it takes precedence over external_ids_uri and external_ids_type.\nNone\n\n\nexternal_ids_uri\nOptional[str]\nSource URI for external_ids.\n''\n\n\nexternal_ids_type\nOptional[str]\nFile type of external_ids_uri. If left empty it is auto-detected.\nNone\n\n\nupdates_uri\nOptional[str]\nUpdates array URI. Used for consolidation of updates.\nNone\n\n\nindex_timestamp\nOptional[int]\nTimestamp to use for writing and reading data. By default it uses the current unix ms timestamp.\nNone\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nnamespace\nOptional[str]\nTileDB-Cloud namespace to use for Cloud execution.\nNone\n\n\nsize\nint\nNumber of input vectors, if not provided use the full size of the input dataset. If provided, we filter the first vectors from the input source.\n-1\n\n\ndimensions\nint\nNumber of vector dimensions, if not provided use the dimensions detected from the input dataset. If provided, this overrides the dimensions detected by read_source_metadata. This is only used when the input_vectors is not provided. Otherwise, it is ignored.\n-1\n\n\npartitions\nint\nFor IVF_FLAT and IVF_PQ indexes, the number of partitions to generate from the data during k-means clustering. If not provided, is auto-configured based on the dataset size.\n-1\n\n\nnum_subspaces\nint\nFor IVF_PQ encoded indexes, the number of subspaces to use in the PQ encoding. We will divide the dimensions into num_subspaces parts, and PQ encode each part separately. This means dimensions must be divisible by num_subspaces.\n-1\n\n\nl_build\nint\nFor Vamana indexes, the number of neighbors considered for each node during construction of the graph. Larger values will take more time to build but result in indices that provide higher recall for the same search complexity. l_build should be &gt;= r_max_degree unless you need to build indices quickly and can compromise on quality. Typically between 75 and 200. If not provided, use the default value of 100.\n-1\n\n\nr_max_degree\nint\nFor Vamana indexes, the maximum degree for each node in the final graph. Larger values will result in larger indices and longer indexing times, but better search quality. Typically between 60 and 150. If not provided, use the default value of 64.\n-1\n\n\ncopy_centroids_uri\nOptional[str]\nTileDB array URI to copy centroids from, if not provided, centroids are build running k-means.\nNone\n\n\ntraining_sample_size\nint\nSample size to use for computing k-means. If not provided, is auto-configured based on the dataset sizes. Should not be provided if training_source_uri is provided.\n-1\n\n\ntraining_input_vectors\nOptional[np.ndarray]\nTraining input vectors, if this is provided it takes precedence over training_source_uri and training_source_type. Should not be provided if training_sample_size or training_source_uri are provided.\nNone\n\n\ntraining_source_uri\nOptional[str]\nThe source URI to use for training centroids when building a IVF_FLAT vector index. If not provided, the first training_sample_size vectors from source_uri are used. Should not be provided if training_sample_size or training_input_vectors is provided.\nNone\n\n\ntraining_source_type\nOptional[str]\nType of the training source data in training_source_uri. If left empty, is auto-detected. Should only be provided when training_source_uri is provided.\nNone\n\n\nworkers\nint\nNumber of distributed workers to use for vector ingestion. If not provided, is auto-configured based on the dataset size.\n-1\n\n\ninput_vectors_per_work_item\nint\nNumber of vectors per ingestion work item. If not provided, is auto-configured.\n-1\n\n\nmax_tasks_per_stage\nint\nMax number of tasks per execution stage of ingestion. If not provided, is auto-configured.\n-1\n\n\ninput_vectors_per_work_item_during_sampling\nint\nNumber of vectors per sample ingestion work item. iIf not provided, is auto-configured. Only valid with training_sampling_policy=TrainingSamplingPolicy.RANDOM.\n-1\n\n\nmax_sampling_tasks\nint\nMax number of tasks per execution stage of sampling. If not provided, is auto-configured Only valid with training_sampling_policy=TrainingSamplingPolicy.RANDOM.\n-1\n\n\nstorage_version\nstr\nVector index storage format version. If not provided, defaults to the latest version.\nSTORAGE_VERSION\n\n\nverbose\nbool\nEnables verbose logging.\nFalse\n\n\ntrace_id\nOptional[str]\ntrace ID for logging.\nNone\n\n\nuse_sklearn\nbool\nWhether to use scikit-learn’s implementation of k-means clustering instead of tiledb.vector_search’s.\nTrue\n\n\nmode\nMode\nExecution mode, defaults to LOCAL use BATCH for distributed execution.\nMode.LOCAL\n\n\nacn\nOptional[str]\nAccess credential name to be used when running in BATCH mode for object store access\nNone\n\n\ningest_resources\nOptional[Mapping[str, Any]]\nResources to request when performing vector ingestion, only applies to BATCH mode\nNone\n\n\nconsolidate_partition_resources\nOptional[Mapping[str, Any]]\nResources to request when performing consolidation of a partition, only applies to BATCH mode\nNone\n\n\ncopy_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing copy of centroids from input array to output array, only applies to BATCH mode\nNone\n\n\nrandom_sample_resources\nOptional[Mapping[str, Any]]\nResources to request when performing random sample selection, only applies to BATCH mode\nNone\n\n\nkmeans_resources\nOptional[Mapping[str, Any]]\nResources to request when performing kmeans task, only applies to BATCH mode\nNone\n\n\ncompute_new_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing centroid computation, only applies to BATCH mode\nNone\n\n\nassign_points_and_partial_new_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the computation of partial centroids, only applies to BATCH mode\nNone\n\n\nwrite_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the write of centroids, only applies to BATCH mode\nNone\n\n\npartial_index_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the computation of partial indexing, only applies to BATCH mode\nNone\n\n\ndistance_metric\nvspy.DistanceMetric\nDistance metric to use for the index, defaults to ‘vspy.DistanceMetric.SUM_OF_SQUARES’. Options are ‘vspy.DistanceMetric.SUM_OF_SQUARES’, ‘vspy.DistanceMetric.INNER_PRODUCT’, ‘vspy.DistanceMetric.COSINE’, ‘vspy.DistanceMetric.L2’.\nvspy.DistanceMetric.SUM_OF_SQUARES"
  },
  {
    "objectID": "documentation/reference/ingestion.html#functions",
    "href": "documentation/reference/ingestion.html#functions",
    "title": "ingestion",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ningest\nIngest vectors into TileDB.\n\n\n\n\n\nvector_search.ingestion.ingest(index_type, index_uri, *, input_vectors=None, source_uri=None, source_type=None, external_ids=None, external_ids_uri='', external_ids_type=None, updates_uri=None, index_timestamp=None, config=None, namespace=None, size=-1, dimensions=-1, partitions=-1, num_subspaces=-1, l_build=-1, r_max_degree=-1, training_sampling_policy=TrainingSamplingPolicy.FIRST_N, copy_centroids_uri=None, training_sample_size=-1, training_input_vectors=None, training_source_uri=None, training_source_type=None, workers=-1, input_vectors_per_work_item=-1, max_tasks_per_stage=-1, input_vectors_per_work_item_during_sampling=-1, max_sampling_tasks=-1, storage_version=STORAGE_VERSION, verbose=False, trace_id=None, use_sklearn=True, mode=Mode.LOCAL, acn=None, ingest_resources=None, consolidate_partition_resources=None, copy_centroids_resources=None, random_sample_resources=None, kmeans_resources=None, compute_new_centroids_resources=None, assign_points_and_partial_new_centroids_resources=None, write_centroids_resources=None, partial_index_resources=None, distance_metric=vspy.DistanceMetric.SUM_OF_SQUARES, normalized=False, **kwargs)\nIngest vectors into TileDB.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nindex_type\nstr\nType of vector index (FLAT, IVF_FLAT, IVF_PQ, VAMANA).\nrequired\n\n\nindex_uri\nstr\nVector index URI (stored as TileDB group).\nrequired\n\n\ninput_vectors\nOptional[np.ndarray]\nInput vectors, if this is provided it takes precedence over source_uri and source_type.\nNone\n\n\nsource_uri\nOptional[str]\nVectors source URI.\nNone\n\n\nsource_type\nOptional[str]\nType of the source vectors. If left empty it is auto-detected.\nNone\n\n\nexternal_ids\nOptional[np.array]\nInput vector external_ids, if this is provided it takes precedence over external_ids_uri and external_ids_type.\nNone\n\n\nexternal_ids_uri\nOptional[str]\nSource URI for external_ids.\n''\n\n\nexternal_ids_type\nOptional[str]\nFile type of external_ids_uri. If left empty it is auto-detected.\nNone\n\n\nupdates_uri\nOptional[str]\nUpdates array URI. Used for consolidation of updates.\nNone\n\n\nindex_timestamp\nOptional[int]\nTimestamp to use for writing and reading data. By default it uses the current unix ms timestamp.\nNone\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nnamespace\nOptional[str]\nTileDB-Cloud namespace to use for Cloud execution.\nNone\n\n\nsize\nint\nNumber of input vectors, if not provided use the full size of the input dataset. If provided, we filter the first vectors from the input source.\n-1\n\n\ndimensions\nint\nNumber of vector dimensions, if not provided use the dimensions detected from the input dataset. If provided, this overrides the dimensions detected by read_source_metadata. This is only used when the input_vectors is not provided. Otherwise, it is ignored.\n-1\n\n\npartitions\nint\nFor IVF_FLAT and IVF_PQ indexes, the number of partitions to generate from the data during k-means clustering. If not provided, is auto-configured based on the dataset size.\n-1\n\n\nnum_subspaces\nint\nFor IVF_PQ encoded indexes, the number of subspaces to use in the PQ encoding. We will divide the dimensions into num_subspaces parts, and PQ encode each part separately. This means dimensions must be divisible by num_subspaces.\n-1\n\n\nl_build\nint\nFor Vamana indexes, the number of neighbors considered for each node during construction of the graph. Larger values will take more time to build but result in indices that provide higher recall for the same search complexity. l_build should be &gt;= r_max_degree unless you need to build indices quickly and can compromise on quality. Typically between 75 and 200. If not provided, use the default value of 100.\n-1\n\n\nr_max_degree\nint\nFor Vamana indexes, the maximum degree for each node in the final graph. Larger values will result in larger indices and longer indexing times, but better search quality. Typically between 60 and 150. If not provided, use the default value of 64.\n-1\n\n\ncopy_centroids_uri\nOptional[str]\nTileDB array URI to copy centroids from, if not provided, centroids are build running k-means.\nNone\n\n\ntraining_sample_size\nint\nSample size to use for computing k-means. If not provided, is auto-configured based on the dataset sizes. Should not be provided if training_source_uri is provided.\n-1\n\n\ntraining_input_vectors\nOptional[np.ndarray]\nTraining input vectors, if this is provided it takes precedence over training_source_uri and training_source_type. Should not be provided if training_sample_size or training_source_uri are provided.\nNone\n\n\ntraining_source_uri\nOptional[str]\nThe source URI to use for training centroids when building a IVF_FLAT vector index. If not provided, the first training_sample_size vectors from source_uri are used. Should not be provided if training_sample_size or training_input_vectors is provided.\nNone\n\n\ntraining_source_type\nOptional[str]\nType of the training source data in training_source_uri. If left empty, is auto-detected. Should only be provided when training_source_uri is provided.\nNone\n\n\nworkers\nint\nNumber of distributed workers to use for vector ingestion. If not provided, is auto-configured based on the dataset size.\n-1\n\n\ninput_vectors_per_work_item\nint\nNumber of vectors per ingestion work item. If not provided, is auto-configured.\n-1\n\n\nmax_tasks_per_stage\nint\nMax number of tasks per execution stage of ingestion. If not provided, is auto-configured.\n-1\n\n\ninput_vectors_per_work_item_during_sampling\nint\nNumber of vectors per sample ingestion work item. iIf not provided, is auto-configured. Only valid with training_sampling_policy=TrainingSamplingPolicy.RANDOM.\n-1\n\n\nmax_sampling_tasks\nint\nMax number of tasks per execution stage of sampling. If not provided, is auto-configured Only valid with training_sampling_policy=TrainingSamplingPolicy.RANDOM.\n-1\n\n\nstorage_version\nstr\nVector index storage format version. If not provided, defaults to the latest version.\nSTORAGE_VERSION\n\n\nverbose\nbool\nEnables verbose logging.\nFalse\n\n\ntrace_id\nOptional[str]\ntrace ID for logging.\nNone\n\n\nuse_sklearn\nbool\nWhether to use scikit-learn’s implementation of k-means clustering instead of tiledb.vector_search’s.\nTrue\n\n\nmode\nMode\nExecution mode, defaults to LOCAL use BATCH for distributed execution.\nMode.LOCAL\n\n\nacn\nOptional[str]\nAccess credential name to be used when running in BATCH mode for object store access\nNone\n\n\ningest_resources\nOptional[Mapping[str, Any]]\nResources to request when performing vector ingestion, only applies to BATCH mode\nNone\n\n\nconsolidate_partition_resources\nOptional[Mapping[str, Any]]\nResources to request when performing consolidation of a partition, only applies to BATCH mode\nNone\n\n\ncopy_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing copy of centroids from input array to output array, only applies to BATCH mode\nNone\n\n\nrandom_sample_resources\nOptional[Mapping[str, Any]]\nResources to request when performing random sample selection, only applies to BATCH mode\nNone\n\n\nkmeans_resources\nOptional[Mapping[str, Any]]\nResources to request when performing kmeans task, only applies to BATCH mode\nNone\n\n\ncompute_new_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing centroid computation, only applies to BATCH mode\nNone\n\n\nassign_points_and_partial_new_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the computation of partial centroids, only applies to BATCH mode\nNone\n\n\nwrite_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the write of centroids, only applies to BATCH mode\nNone\n\n\npartial_index_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the computation of partial indexing, only applies to BATCH mode\nNone\n\n\ndistance_metric\nvspy.DistanceMetric\nDistance metric to use for the index, defaults to ‘vspy.DistanceMetric.SUM_OF_SQUARES’. Options are ‘vspy.DistanceMetric.SUM_OF_SQUARES’, ‘vspy.DistanceMetric.INNER_PRODUCT’, ‘vspy.DistanceMetric.COSINE’, ‘vspy.DistanceMetric.L2’.\nvspy.DistanceMetric.SUM_OF_SQUARES"
  },
  {
    "objectID": "documentation/reference/object_api.ObjectIndex.html",
    "href": "documentation/reference/object_api.ObjectIndex.html",
    "title": "object_api.ObjectIndex",
    "section": "",
    "text": "vector_search.object_api.ObjectIndex(self, uri, config=None, timestamp=None, open_for_remote_query_execution=False, open_vector_index_for_remote_query_execution=False, load_embedding=True, load_metadata_in_memory=True, environment_variables={}, **kwargs)\nAn ObjectIndex represents a TileDB Vector Search index that is associated with a user-defined object reader and embedding function. This allows users to easily create and query TileDB Vector Search indexes that are backed by arbitrary data.\nFor example, an ObjectIndex can be used to create a TileDB Vector Search index that is backed by a collection of images. The object reader would be responsible for loading the images from disk, and the embedding function would be responsible for generating embeddings for the images.\nOnce the ObjectIndex is created, it can be queried using the query() method. The query() method takes a list of query objects and returns a list of the nearest neighbors for each query object.\nThe ObjectIndex class also provides methods for updating the index (update_index()) and updating the object reader (update_object_reader()).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nThe URI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nTimestamp to open the index at.\nNone\n\n\nload_embedding\nbool\nWhether to load the embedding function into memory.\nTrue\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load the embedding model and any index data locally, and instead perform all query functionality in a TileDB Cloud taskgraph.\nFalse\n\n\nopen_vector_index_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data and perform vector queries in a TileDB Cloud taskgraph. Compared to open_for_remote_query_execution, this loads the object embedding function and computes query object embeddings locally.\nFalse\n\n\nload_metadata_in_memory\nbool\nWhether to load the metadata array into memory.\nTrue\n\n\nenvironment_variables\nDict\nEnvironment variables to set for the object reader and embedding function.\n{}\n\n\n**kwargs\n\nKeyword arguments to pass to the index constructor.\n{}\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nquery\nQueries the index and returns the nearest neighbors for each query object.\n\n\nupdate_index\nUpdates the index with new data.\n\n\nupdate_object_reader\nUpdates the object reader for the index.\n\n\n\n\n\nvector_search.object_api.ObjectIndex.query(query_objects, k, query_metadata=None, metadata_array_cond=None, metadata_df_filter_fn=None, return_objects=True, return_metadata=True, driver_mode=Mode.REALTIME, driver_resource_class=None, driver_resources=None, extra_driver_modules=None, driver_access_credentials_name=None, merge_results_result_pos_as_score=True, merge_results_reverse_dist=None, merge_results_per_query_embedding_group_fn=max, merge_results_per_query_group_fn=operator.add, **kwargs)\nQueries the index and returns the nearest neighbors for each query object.\nThe query objects can be any type of object that is supported by the object reader. For example, if the object reader is configured to read images, then the query objects should be images.\nThe k parameter specifies the number of nearest neighbors to return for each query object.\nThe query_metadata parameter can be used to pass metadata for the query objects. This metadata will be passed to the embedding function, which can use it to generate embeddings for the query objects.\nThe metadata_array_cond parameter can be used to filter the results of the query based on the metadata that is stored in the metadata array. This parameter should be a string that contains a valid TileDB query condition. For example, the following query condition could be used to filter the results to only include objects that have a color attribute that is equal to “red”:\nmetadata_array_cond=\"color='red'\"\nThe metadata_df_filter_fn parameter can be used to filter the results of the query based on the metadata that is stored in the metadata array. This parameter should be a function that takes a pandas DataFrame as input and returns a pandas DataFrame as output. The input DataFrame will contain the metadata for all of the objects that match the query, and the output DataFrame should contain the metadata for the objects that should be returned to the user.\nThe return_objects parameter specifies whether to return the objects themselves, or just the object IDs. If this parameter is set to True, then the query() method will also return the objects instead of the object IDs.\nThe return_metadata parameter specifies whether to return the metadata for the objects. If this parameter is set to True, then the query() method will also return the object metadata along with the distances and object IDs.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nquery_objects\nnp.ndarray\nThe query objects.\nrequired\n\n\nk\nint\nThe number of nearest neighbors to return for each query object.\nrequired\n\n\nquery_metadata\nOptional[OrderedDict]\nMetadata for the query objects.\nNone\n\n\nmetadata_array_cond\nOptional[str]\nA TileDB query condition that can be used to filter the results of the query based on the metadata that is stored in the metadata array.\nNone\n\n\nmetadata_df_filter_fn\nOptional[str]\nA function that can be used to filter the results of the query based on the metadata that is stored in the metadata array.\nNone\n\n\nreturn_objects\nbool\nWhether to return the objects themselves, or just the object IDs.\nTrue\n\n\nreturn_metadata\nbool\nWhether to return the metadata for the objects.\nTrue\n\n\ndriver_mode\nOptional[Mode]\nIf not None, the query will be executed in a TileDB cloud taskgraph using the driver mode specified.\nMode.REALTIME\n\n\ndriver_resource_class\nOptional[str]\nIf driver_mode was REALTIME, the resources class (standard or large) to use for the driver execution.\nNone\n\n\ndriver_resources\nOptional[Mapping[str, Any]]\nIf driver_mode was BATCH, the resources to use for the driver execution. Example {\"cpu\": \"1\", \"memory\": \"4Gi\"}\nNone\n\n\nextra_driver_modules\nOptional[List[str]]\nA list of extra Python modules to install on the driver node.\nNone\n\n\ndriver_access_credentials_name\nOptional[str]\nIf driver_mode was not None, the access credentials name to use for the driver execution.\nNone\n\n\nmerge_results_result_pos_as_score\nbool\nApplies only when there are multiple query embeddings per query. If True, each result score is based on the position of the result for the query embedding.\nTrue\n\n\nmerge_results_reverse_dist\nOptional[bool]\nApplies only when there are multiple query embeddings per query. If True, the distances are reversed based on their reciprocal, (1 / dist).\nNone\n\n\nmerge_results_per_query_embedding_group_fn\nCallable\nApplies only when there are multiple query embeddings per query. Group function used to group together object scores per query embedding (i.e max, min, etc.).\nmax\n\n\nmerge_results_per_query_group_fn\nCallable\nApplies only when there are multiple query embeddings per query. Group function used to group together object scores per query (i.e add). This is applied after merge_results_per_query_embedding_group_fn\noperator.add\n\n\n**kwargs\n\nKeyword arguments to pass to the index query method.\n{}\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nUnion[\nTuple[np.ndarray, OrderedDict, Dict], Tuple[np.ndarray, OrderedDict], Tuple[np.ndarray, np.ndarray, Dict], Tuple[np.ndarray, np.ndarray],\n\n\n]\nA tuple containing the distances, objects or object IDs, and optionally the object metadata.\n\n\n\n\n\n\n\nvector_search.object_api.ObjectIndex.update_index(index_timestamp=None, workers=-1, worker_resources=None, worker_image=None, extra_worker_modules=None, driver_resources=None, driver_image=None, extra_driver_modules=None, worker_access_credentials_name=None, max_tasks_per_stage=-1, verbose=False, trace_id=None, embeddings_generation_mode=Mode.LOCAL, embeddings_generation_driver_mode=Mode.LOCAL, vector_indexing_mode=Mode.LOCAL, config=None, namespace=None, environment_variables={}, use_updates_array=True, **kwargs)\nUpdates the index with new data.\nThis method can be used to update the index with new data. This is useful if the data that the index is built on has changed.\nUpdate uses the ingest_embeddings_with_driver function to add embeddings into a TileDB vector search index.\nThis function orchestrates the embedding ingestion process by creating and executing a TileDB Cloud DAG (Directed Acyclic Graph). The DAG consists of two main stages:\n\nEmbeddings Generation: This stage is responsible for computing embeddings for the objects to be indexed.\nVector Indexing: This stage is responsible for ingesting the generated embeddings into the TileDB vector search index.\n\nBoth stages can be be executed in one of three modes:\n\nLOCAL: Embeddings are ingested locally within the current process.\nREALTIME: Embeddings are ingested using a TileDB Cloud REALTIME TaskGraph.\nBATCH: Embeddings are ingested using a TileDB Cloud BATCH TaskGraph.\n\nThe ingest_embeddings_with_driver function provides flexibility in configuring the execution environment for both stages as well as can run the full execution within a driver UDF. Users can specify the number of workers, resources, Docker images, and extra modules for both the driver and worker nodes.\nThe update_index() method takes the following parameters:\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nindex_timestamp\nint\nTimestamp to use for the update to take place at.\nNone\n\n\nworkers\nint\nThe number of workers to use for the update. If this parameter is not specified, then the default number of workers will be used.\n-1\n\n\nworker_resources\nDict\nThe resources to use for each worker.\nNone\n\n\nworker_image\nstr\nThe Docker image to use for each worker.\nNone\n\n\nextra_worker_modules\nOptional[List[str]]\nExtra modules to install on the worker nodes.\nNone\n\n\ndriver_resources\nDict\nThe resources to use for the driver.\nNone\n\n\ndriver_image\nstr\nThe Docker image to use for the driver.\nNone\n\n\nextra_driver_modules\nOptional[List[str]]\nExtra modules to install on the driver node.\nNone\n\n\nworker_access_credentials_name\nstr\nThe name of the TileDB Cloud access credentials to use for the workers.\nNone\n\n\nmax_tasks_per_stage\nint\nThe maximum number of tasks to run per stage.\n-1\n\n\nverbose\nbool\nWhether to print verbose output.\nFalse\n\n\ntrace_id\nOptional[str]\nThe trace ID to use for the update.\nNone\n\n\nembeddings_generation_mode\nMode\nThe mode to use for generating embeddings.\nMode.LOCAL\n\n\nembeddings_generation_driver_mode\nMode\nThe mode to use for the driver of the embeddings generation task.\nMode.LOCAL\n\n\nvector_indexing_mode\nMode\nThe mode to use for indexing the vectors.\nMode.LOCAL\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nnamespace\nOptional[str]\nThe TileDB Cloud namespace to use for the update. If this parameter is not specified, then the default namespace will be used.\nNone\n\n\nenvironment_variables\nDict\nEnvironment variables to set for the object reader and embedding function.\n{}\n\n\n**kwargs\n\nKeyword arguments to pass to the ingestion function.\n{}\n\n\n\n\n\n\n\nvector_search.object_api.ObjectIndex.update_object_reader(object_reader, config=None)\nUpdates the object reader for the index.\nThis method can be used to update the object reader for the index. This is useful if the object reader needs to be updated to read objects from a different location, or if the object reader needs to be updated to read objects in a different format.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobject_reader\nObjectReader\nThe new object reader.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone"
  },
  {
    "objectID": "documentation/reference/object_api.ObjectIndex.html#parameters",
    "href": "documentation/reference/object_api.ObjectIndex.html#parameters",
    "title": "object_api.ObjectIndex",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nThe URI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nTimestamp to open the index at.\nNone\n\n\nload_embedding\nbool\nWhether to load the embedding function into memory.\nTrue\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load the embedding model and any index data locally, and instead perform all query functionality in a TileDB Cloud taskgraph.\nFalse\n\n\nopen_vector_index_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data and perform vector queries in a TileDB Cloud taskgraph. Compared to open_for_remote_query_execution, this loads the object embedding function and computes query object embeddings locally.\nFalse\n\n\nload_metadata_in_memory\nbool\nWhether to load the metadata array into memory.\nTrue\n\n\nenvironment_variables\nDict\nEnvironment variables to set for the object reader and embedding function.\n{}\n\n\n**kwargs\n\nKeyword arguments to pass to the index constructor.\n{}"
  },
  {
    "objectID": "documentation/reference/object_api.ObjectIndex.html#methods",
    "href": "documentation/reference/object_api.ObjectIndex.html#methods",
    "title": "object_api.ObjectIndex",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nquery\nQueries the index and returns the nearest neighbors for each query object.\n\n\nupdate_index\nUpdates the index with new data.\n\n\nupdate_object_reader\nUpdates the object reader for the index.\n\n\n\n\n\nvector_search.object_api.ObjectIndex.query(query_objects, k, query_metadata=None, metadata_array_cond=None, metadata_df_filter_fn=None, return_objects=True, return_metadata=True, driver_mode=Mode.REALTIME, driver_resource_class=None, driver_resources=None, extra_driver_modules=None, driver_access_credentials_name=None, merge_results_result_pos_as_score=True, merge_results_reverse_dist=None, merge_results_per_query_embedding_group_fn=max, merge_results_per_query_group_fn=operator.add, **kwargs)\nQueries the index and returns the nearest neighbors for each query object.\nThe query objects can be any type of object that is supported by the object reader. For example, if the object reader is configured to read images, then the query objects should be images.\nThe k parameter specifies the number of nearest neighbors to return for each query object.\nThe query_metadata parameter can be used to pass metadata for the query objects. This metadata will be passed to the embedding function, which can use it to generate embeddings for the query objects.\nThe metadata_array_cond parameter can be used to filter the results of the query based on the metadata that is stored in the metadata array. This parameter should be a string that contains a valid TileDB query condition. For example, the following query condition could be used to filter the results to only include objects that have a color attribute that is equal to “red”:\nmetadata_array_cond=\"color='red'\"\nThe metadata_df_filter_fn parameter can be used to filter the results of the query based on the metadata that is stored in the metadata array. This parameter should be a function that takes a pandas DataFrame as input and returns a pandas DataFrame as output. The input DataFrame will contain the metadata for all of the objects that match the query, and the output DataFrame should contain the metadata for the objects that should be returned to the user.\nThe return_objects parameter specifies whether to return the objects themselves, or just the object IDs. If this parameter is set to True, then the query() method will also return the objects instead of the object IDs.\nThe return_metadata parameter specifies whether to return the metadata for the objects. If this parameter is set to True, then the query() method will also return the object metadata along with the distances and object IDs.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nquery_objects\nnp.ndarray\nThe query objects.\nrequired\n\n\nk\nint\nThe number of nearest neighbors to return for each query object.\nrequired\n\n\nquery_metadata\nOptional[OrderedDict]\nMetadata for the query objects.\nNone\n\n\nmetadata_array_cond\nOptional[str]\nA TileDB query condition that can be used to filter the results of the query based on the metadata that is stored in the metadata array.\nNone\n\n\nmetadata_df_filter_fn\nOptional[str]\nA function that can be used to filter the results of the query based on the metadata that is stored in the metadata array.\nNone\n\n\nreturn_objects\nbool\nWhether to return the objects themselves, or just the object IDs.\nTrue\n\n\nreturn_metadata\nbool\nWhether to return the metadata for the objects.\nTrue\n\n\ndriver_mode\nOptional[Mode]\nIf not None, the query will be executed in a TileDB cloud taskgraph using the driver mode specified.\nMode.REALTIME\n\n\ndriver_resource_class\nOptional[str]\nIf driver_mode was REALTIME, the resources class (standard or large) to use for the driver execution.\nNone\n\n\ndriver_resources\nOptional[Mapping[str, Any]]\nIf driver_mode was BATCH, the resources to use for the driver execution. Example {\"cpu\": \"1\", \"memory\": \"4Gi\"}\nNone\n\n\nextra_driver_modules\nOptional[List[str]]\nA list of extra Python modules to install on the driver node.\nNone\n\n\ndriver_access_credentials_name\nOptional[str]\nIf driver_mode was not None, the access credentials name to use for the driver execution.\nNone\n\n\nmerge_results_result_pos_as_score\nbool\nApplies only when there are multiple query embeddings per query. If True, each result score is based on the position of the result for the query embedding.\nTrue\n\n\nmerge_results_reverse_dist\nOptional[bool]\nApplies only when there are multiple query embeddings per query. If True, the distances are reversed based on their reciprocal, (1 / dist).\nNone\n\n\nmerge_results_per_query_embedding_group_fn\nCallable\nApplies only when there are multiple query embeddings per query. Group function used to group together object scores per query embedding (i.e max, min, etc.).\nmax\n\n\nmerge_results_per_query_group_fn\nCallable\nApplies only when there are multiple query embeddings per query. Group function used to group together object scores per query (i.e add). This is applied after merge_results_per_query_embedding_group_fn\noperator.add\n\n\n**kwargs\n\nKeyword arguments to pass to the index query method.\n{}\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nUnion[\nTuple[np.ndarray, OrderedDict, Dict], Tuple[np.ndarray, OrderedDict], Tuple[np.ndarray, np.ndarray, Dict], Tuple[np.ndarray, np.ndarray],\n\n\n]\nA tuple containing the distances, objects or object IDs, and optionally the object metadata.\n\n\n\n\n\n\n\nvector_search.object_api.ObjectIndex.update_index(index_timestamp=None, workers=-1, worker_resources=None, worker_image=None, extra_worker_modules=None, driver_resources=None, driver_image=None, extra_driver_modules=None, worker_access_credentials_name=None, max_tasks_per_stage=-1, verbose=False, trace_id=None, embeddings_generation_mode=Mode.LOCAL, embeddings_generation_driver_mode=Mode.LOCAL, vector_indexing_mode=Mode.LOCAL, config=None, namespace=None, environment_variables={}, use_updates_array=True, **kwargs)\nUpdates the index with new data.\nThis method can be used to update the index with new data. This is useful if the data that the index is built on has changed.\nUpdate uses the ingest_embeddings_with_driver function to add embeddings into a TileDB vector search index.\nThis function orchestrates the embedding ingestion process by creating and executing a TileDB Cloud DAG (Directed Acyclic Graph). The DAG consists of two main stages:\n\nEmbeddings Generation: This stage is responsible for computing embeddings for the objects to be indexed.\nVector Indexing: This stage is responsible for ingesting the generated embeddings into the TileDB vector search index.\n\nBoth stages can be be executed in one of three modes:\n\nLOCAL: Embeddings are ingested locally within the current process.\nREALTIME: Embeddings are ingested using a TileDB Cloud REALTIME TaskGraph.\nBATCH: Embeddings are ingested using a TileDB Cloud BATCH TaskGraph.\n\nThe ingest_embeddings_with_driver function provides flexibility in configuring the execution environment for both stages as well as can run the full execution within a driver UDF. Users can specify the number of workers, resources, Docker images, and extra modules for both the driver and worker nodes.\nThe update_index() method takes the following parameters:\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nindex_timestamp\nint\nTimestamp to use for the update to take place at.\nNone\n\n\nworkers\nint\nThe number of workers to use for the update. If this parameter is not specified, then the default number of workers will be used.\n-1\n\n\nworker_resources\nDict\nThe resources to use for each worker.\nNone\n\n\nworker_image\nstr\nThe Docker image to use for each worker.\nNone\n\n\nextra_worker_modules\nOptional[List[str]]\nExtra modules to install on the worker nodes.\nNone\n\n\ndriver_resources\nDict\nThe resources to use for the driver.\nNone\n\n\ndriver_image\nstr\nThe Docker image to use for the driver.\nNone\n\n\nextra_driver_modules\nOptional[List[str]]\nExtra modules to install on the driver node.\nNone\n\n\nworker_access_credentials_name\nstr\nThe name of the TileDB Cloud access credentials to use for the workers.\nNone\n\n\nmax_tasks_per_stage\nint\nThe maximum number of tasks to run per stage.\n-1\n\n\nverbose\nbool\nWhether to print verbose output.\nFalse\n\n\ntrace_id\nOptional[str]\nThe trace ID to use for the update.\nNone\n\n\nembeddings_generation_mode\nMode\nThe mode to use for generating embeddings.\nMode.LOCAL\n\n\nembeddings_generation_driver_mode\nMode\nThe mode to use for the driver of the embeddings generation task.\nMode.LOCAL\n\n\nvector_indexing_mode\nMode\nThe mode to use for indexing the vectors.\nMode.LOCAL\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nnamespace\nOptional[str]\nThe TileDB Cloud namespace to use for the update. If this parameter is not specified, then the default namespace will be used.\nNone\n\n\nenvironment_variables\nDict\nEnvironment variables to set for the object reader and embedding function.\n{}\n\n\n**kwargs\n\nKeyword arguments to pass to the ingestion function.\n{}\n\n\n\n\n\n\n\nvector_search.object_api.ObjectIndex.update_object_reader(object_reader, config=None)\nUpdates the object reader for the index.\nThis method can be used to update the object reader for the index. This is useful if the object reader needs to be updated to read objects from a different location, or if the object reader needs to be updated to read objects in a different format.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobject_reader\nObjectReader\nThe new object reader.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone"
  },
  {
    "objectID": "documentation/reference/index.Index.html",
    "href": "documentation/reference/index.Index.html",
    "title": "index.Index",
    "section": "",
    "text": "vector_search.index.Index(self, uri, open_for_remote_query_execution=False, config=None, timestamp=None, group=None)\nAbstract Vector Index class. Do not use this directly but rather use the open factory method.\nAll Vector Index algorithm implementations are instantiations of this class. Apart from the abstract method interfaces, Index provides implementations for common tasks i.e. supporting updates, time-traveling and metadata management.\nOpens an Index reading metadata and applying time-traveling options.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nFalse\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nclear_history\nClears the history maintained in a Vector Index based on its URI.\n\n\nconsolidate_updates\nConsolidates updates by merging updates form the updates table into the base index.\n\n\ndelete\nDeletes a vector by its external_id.\n\n\ndelete_batch\nDeletes vectors by their external_ids.\n\n\ndelete_index\nDeletes an index from storage based on its URI.\n\n\nget_dimensions\nAbstract method implemented by all Vector Index implementations.\n\n\nquery\nQueries an index with a set of query vectors, retrieving the k most similar vectors for each query.\n\n\nquery_internal\nAbstract method implemented by all Vector Index implementations.\n\n\nupdate\nUpdates a vector by its external_id.\n\n\nupdate_batch\nUpdates a set vectors by their external_ids.\n\n\nvacuum\nThe vacuuming process permanently deletes index files that are consolidated through the consolidation\n\n\n\n\n\nvector_search.index.Index.clear_history(uri, timestamp, config=None)\nClears the history maintained in a Vector Index based on its URI.\nThis clears the update history before the provided timestamp.\nUse this in collaboration with consolidate_updates to periodically cleanup update history.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ntimestamp\nint\nClears update history before this timestamp.\nrequired\n\n\n\n\n\n\n\nvector_search.index.Index.consolidate_updates(retrain_index=False, **kwargs)\nConsolidates updates by merging updates form the updates table into the base index.\nThe consolidation process is used to avoid query latency degradation as more updates are added to the index. It triggers a base index re-indexing, merging the non-consolidated updates and the rest of the base vectors.\nTODO(sc-51202): This throws with a unintuitive error message if update()/delete()/etc. has not been called.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nretrain_index\nbool\nIf true, retrain the index. If false, reuse data from the previous index. For IVF_FLAT retraining means we will recompute the centroids - when doing so you can pass any ingest() arguments used to configure computing centroids and we will use them when recomputing the centroids. Otherwise, if false, we will reuse the centroids from the previous index.\nFalse\n\n\n**kwargs\n\nExtra kwargs passed here are passed to ingest function.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.delete(external_id, timestamp=None)\nDeletes a vector by its external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nexternal_id\nnp.uint64\nExternal ID of the vector to be deleted.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the deletes to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.delete_batch(external_ids, timestamp=None)\nDeletes vectors by their external_ids.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nexternal_ids\nnp.array\nExternal IDs of the vectors to be deleted.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the deletes to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.delete_index(uri, config=None)\nDeletes an index from storage based on its URI.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.get_dimensions()\nAbstract method implemented by all Vector Index implementations.\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.index.Index.query(queries, k, driver_mode=None, driver_resource_class=None, driver_resources=None, driver_access_credentials_name=None, **kwargs)\nQueries an index with a set of query vectors, retrieving the k most similar vectors for each query.\nThis provides an algorithm-agnostic implementation for updates:\n\nQueries the non-consolidated updates table.\nCalls the algorithm specific implementation of query_internal to query the base data.\nMerges the results applying the updated data.\n\nYou can control where the query is executed by setting the driver_mode parameter: - With driver_mode = None, the driver logic for the query will be executed locally. - If driver_mode is not None, we will use a TileDB cloud taskgraph to re-open the index and run the query. With both options, certain implementations, i.e. IVF Flat, may let you create further TileDB taskgraphs as defined in the implementation specific query_internal methods.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\nrequired\n\n\ndriver_mode\nOptional[Mode]\nIf not None, the query will be executed in a TileDB cloud taskgraph using the driver mode specified.\nNone\n\n\ndriver_resource_class\nOptional[str]\nIf driver_mode was REALTIME, the resources class (standard or large) to use for the driver execution.\nNone\n\n\ndriver_resources\nOptional[Mapping[str, Any]]\nIf driver_mode was BATCH, the resources to use for the driver execution. Example {\"cpu\": \"1\", \"memory\": \"4Gi\"}\nNone\n\n\ndriver_access_credentials_name\nOptional[str]\nIf driver_mode was not None, the access credentials name to use for the driver execution.\nNone\n\n\n**kwargs\n\nExtra kwargs passed here are passed to the query_internal implementation of the concrete index class.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.query_internal(queries, k, **kwargs)\nAbstract method implemented by all Vector Index implementations.\nQueries the base index with a set of query vectors, retrieving the k most similar vectors for each query.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\nrequired\n\n\n**kwargs\n\nExtra kwargs passed here for each algorithm implementation.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.update(vector, external_id, timestamp=None)\nUpdates a vector by its external_id.\nThis can be used to add new vectors or update an existing vector with the same external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvector\nnp.array\nVector data to be updated.\nrequired\n\n\nexternal_id\nnp.uint64\nExternal ID of the vector.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the update to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.update_batch(vectors, external_ids, timestamp=None)\nUpdates a set vectors by their external_ids.\nThis can be used to add new vectors or update existing vectors with the same external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvectors\nnp.ndarray\n2D array containing the vectors to be updated.\nrequired\n\n\nexternal_ids\nnp.array\nExternal IDs of the vectors.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the updates to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.vacuum()\nThe vacuuming process permanently deletes index files that are consolidated through the consolidation process. TileDB separates consolidation from vacuuming, in order to make consolidation process-safe in the presence of concurrent reads and writes.\nNote:\n\nVacuuming is not process-safe and you should take extra care when invoking it.\nVacuuming may affect the granularity of the time traveling functionality.\n\nThe Index class vacuums consolidated fragments of the updates array."
  },
  {
    "objectID": "documentation/reference/index.Index.html#parameters",
    "href": "documentation/reference/index.Index.html#parameters",
    "title": "index.Index",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nFalse"
  },
  {
    "objectID": "documentation/reference/index.Index.html#methods",
    "href": "documentation/reference/index.Index.html#methods",
    "title": "index.Index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nclear_history\nClears the history maintained in a Vector Index based on its URI.\n\n\nconsolidate_updates\nConsolidates updates by merging updates form the updates table into the base index.\n\n\ndelete\nDeletes a vector by its external_id.\n\n\ndelete_batch\nDeletes vectors by their external_ids.\n\n\ndelete_index\nDeletes an index from storage based on its URI.\n\n\nget_dimensions\nAbstract method implemented by all Vector Index implementations.\n\n\nquery\nQueries an index with a set of query vectors, retrieving the k most similar vectors for each query.\n\n\nquery_internal\nAbstract method implemented by all Vector Index implementations.\n\n\nupdate\nUpdates a vector by its external_id.\n\n\nupdate_batch\nUpdates a set vectors by their external_ids.\n\n\nvacuum\nThe vacuuming process permanently deletes index files that are consolidated through the consolidation\n\n\n\n\n\nvector_search.index.Index.clear_history(uri, timestamp, config=None)\nClears the history maintained in a Vector Index based on its URI.\nThis clears the update history before the provided timestamp.\nUse this in collaboration with consolidate_updates to periodically cleanup update history.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ntimestamp\nint\nClears update history before this timestamp.\nrequired\n\n\n\n\n\n\n\nvector_search.index.Index.consolidate_updates(retrain_index=False, **kwargs)\nConsolidates updates by merging updates form the updates table into the base index.\nThe consolidation process is used to avoid query latency degradation as more updates are added to the index. It triggers a base index re-indexing, merging the non-consolidated updates and the rest of the base vectors.\nTODO(sc-51202): This throws with a unintuitive error message if update()/delete()/etc. has not been called.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nretrain_index\nbool\nIf true, retrain the index. If false, reuse data from the previous index. For IVF_FLAT retraining means we will recompute the centroids - when doing so you can pass any ingest() arguments used to configure computing centroids and we will use them when recomputing the centroids. Otherwise, if false, we will reuse the centroids from the previous index.\nFalse\n\n\n**kwargs\n\nExtra kwargs passed here are passed to ingest function.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.delete(external_id, timestamp=None)\nDeletes a vector by its external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nexternal_id\nnp.uint64\nExternal ID of the vector to be deleted.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the deletes to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.delete_batch(external_ids, timestamp=None)\nDeletes vectors by their external_ids.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nexternal_ids\nnp.array\nExternal IDs of the vectors to be deleted.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the deletes to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.delete_index(uri, config=None)\nDeletes an index from storage based on its URI.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.get_dimensions()\nAbstract method implemented by all Vector Index implementations.\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.index.Index.query(queries, k, driver_mode=None, driver_resource_class=None, driver_resources=None, driver_access_credentials_name=None, **kwargs)\nQueries an index with a set of query vectors, retrieving the k most similar vectors for each query.\nThis provides an algorithm-agnostic implementation for updates:\n\nQueries the non-consolidated updates table.\nCalls the algorithm specific implementation of query_internal to query the base data.\nMerges the results applying the updated data.\n\nYou can control where the query is executed by setting the driver_mode parameter: - With driver_mode = None, the driver logic for the query will be executed locally. - If driver_mode is not None, we will use a TileDB cloud taskgraph to re-open the index and run the query. With both options, certain implementations, i.e. IVF Flat, may let you create further TileDB taskgraphs as defined in the implementation specific query_internal methods.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\nrequired\n\n\ndriver_mode\nOptional[Mode]\nIf not None, the query will be executed in a TileDB cloud taskgraph using the driver mode specified.\nNone\n\n\ndriver_resource_class\nOptional[str]\nIf driver_mode was REALTIME, the resources class (standard or large) to use for the driver execution.\nNone\n\n\ndriver_resources\nOptional[Mapping[str, Any]]\nIf driver_mode was BATCH, the resources to use for the driver execution. Example {\"cpu\": \"1\", \"memory\": \"4Gi\"}\nNone\n\n\ndriver_access_credentials_name\nOptional[str]\nIf driver_mode was not None, the access credentials name to use for the driver execution.\nNone\n\n\n**kwargs\n\nExtra kwargs passed here are passed to the query_internal implementation of the concrete index class.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.query_internal(queries, k, **kwargs)\nAbstract method implemented by all Vector Index implementations.\nQueries the base index with a set of query vectors, retrieving the k most similar vectors for each query.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\nrequired\n\n\n**kwargs\n\nExtra kwargs passed here for each algorithm implementation.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.update(vector, external_id, timestamp=None)\nUpdates a vector by its external_id.\nThis can be used to add new vectors or update an existing vector with the same external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvector\nnp.array\nVector data to be updated.\nrequired\n\n\nexternal_id\nnp.uint64\nExternal ID of the vector.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the update to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.update_batch(vectors, external_ids, timestamp=None)\nUpdates a set vectors by their external_ids.\nThis can be used to add new vectors or update existing vectors with the same external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvectors\nnp.ndarray\n2D array containing the vectors to be updated.\nrequired\n\n\nexternal_ids\nnp.array\nExternal IDs of the vectors.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the updates to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.vacuum()\nThe vacuuming process permanently deletes index files that are consolidated through the consolidation process. TileDB separates consolidation from vacuuming, in order to make consolidation process-safe in the presence of concurrent reads and writes.\nNote:\n\nVacuuming is not process-safe and you should take extra care when invoking it.\nVacuuming may affect the granularity of the time traveling functionality.\n\nThe Index class vacuums consolidated fragments of the updates array."
  },
  {
    "objectID": "documentation/reference/vamana_index.html",
    "href": "documentation/reference/vamana_index.html",
    "title": "vamana_index",
    "section": "",
    "text": "vector_search.vamana_index\nVamana Index implementation.\nVamana is based on Microsoft’s DiskANN vector search library, as described in these papers:\n  Subramanya, Suhas Jayaram, and Rohan Kadekodi. DiskANN: Fast Accurate Billion-Point Nearest Neighbor Search on a Single Node.\n\n  Singh, Aditi, et al. FreshDiskANN: A Fast and Accurate Graph-Based ANN Index for Streaming Similarity Search. arXiv:2105.09613, arXiv, 20 May 2021, http://arxiv.org/abs/2105.09613.\n\n  Gollapudi, Siddharth, et al. “Filtered-DiskANN: Graph Algorithms for Approximate Nearest Neighbor Search with Filters.” Proceedings of the ACM Web Conference 2023, ACM, 2023, pp. 3406-16, https://doi.org/10.1145/3543507.3583552.\n\n\n\n\n\nName\nDescription\n\n\n\n\nVamanaIndex\nOpens a VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.VamanaIndex(self, uri, config=None, timestamp=None, open_for_remote_query_execution=False, group=None, **kwargs)\nOpens a VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nFalse\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries a VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.VamanaIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.vamana_index.VamanaIndex.query_internal(queries, k=10, l_search=L_SEARCH_DEFAULT, **kwargs)\nQueries a VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nl_search\nOptional[int]\nHow deep to search. Larger parameters will result in slower latencies, but higher accuracies. Should be &gt;= k, and if it’s not, we will set it to k.\nL_SEARCH_DEFAULT\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate\nCreates an empty VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.create(uri, dimensions, vector_type, l_build=L_BUILD_DEFAULT, r_max_degree=R_MAX_DEGREE_DEFAULT, config=None, storage_version=STORAGE_VERSION, distance_metric=vspy.DistanceMetric.SUM_OF_SQUARES, **kwargs)\nCreates an empty VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\nl_build\nint\nThe number of neighbors considered for each node during construction of the graph. Larger values will take more time to build but result in indices that provide higher recall for the same search complexity. l_build should be &gt;= r_max_degree unless you need to build indices quickly and can compromise on quality. Typically between 75 and 200. If not provided, use the default value of 100.\nL_BUILD_DEFAULT\n\n\nr_max_degree\nint\nThe maximum degree for each node in the final graph. Larger values will result in larger indices and longer indexing times, but better search quality. Typically between 60 and 150. If not provided, use the default value of 64.\nR_MAX_DEGREE_DEFAULT\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use the latest stable storage version.\nSTORAGE_VERSION"
  },
  {
    "objectID": "documentation/reference/vamana_index.html#classes",
    "href": "documentation/reference/vamana_index.html#classes",
    "title": "vamana_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nVamanaIndex\nOpens a VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.VamanaIndex(self, uri, config=None, timestamp=None, open_for_remote_query_execution=False, group=None, **kwargs)\nOpens a VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nFalse\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries a VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.VamanaIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.vamana_index.VamanaIndex.query_internal(queries, k=10, l_search=L_SEARCH_DEFAULT, **kwargs)\nQueries a VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nl_search\nOptional[int]\nHow deep to search. Larger parameters will result in slower latencies, but higher accuracies. Should be &gt;= k, and if it’s not, we will set it to k.\nL_SEARCH_DEFAULT"
  },
  {
    "objectID": "documentation/reference/vamana_index.html#functions",
    "href": "documentation/reference/vamana_index.html#functions",
    "title": "vamana_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate\nCreates an empty VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.create(uri, dimensions, vector_type, l_build=L_BUILD_DEFAULT, r_max_degree=R_MAX_DEGREE_DEFAULT, config=None, storage_version=STORAGE_VERSION, distance_metric=vspy.DistanceMetric.SUM_OF_SQUARES, **kwargs)\nCreates an empty VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\nl_build\nint\nThe number of neighbors considered for each node during construction of the graph. Larger values will take more time to build but result in indices that provide higher recall for the same search complexity. l_build should be &gt;= r_max_degree unless you need to build indices quickly and can compromise on quality. Typically between 75 and 200. If not provided, use the default value of 100.\nL_BUILD_DEFAULT\n\n\nr_max_degree\nint\nThe maximum degree for each node in the final graph. Larger values will result in larger indices and longer indexing times, but better search quality. Typically between 60 and 150. If not provided, use the default value of 64.\nR_MAX_DEGREE_DEFAULT\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use the latest stable storage version.\nSTORAGE_VERSION"
  },
  {
    "objectID": "documentation/reference/embeddings.ObjectEmbedding.html",
    "href": "documentation/reference/embeddings.ObjectEmbedding.html",
    "title": "embeddings.ObjectEmbedding",
    "section": "",
    "text": "vector_search.embeddings.ObjectEmbedding()\nAbstract class that can be used to create embeddings for Objects of a specific format.\n\n\n\n\n\nName\nDescription\n\n\n\n\ndimensions\nReturns the number of dimensions of the embedding vectors.\n\n\nembed\nCreates embedding vectors for objects. Returns a numpy array of embedding vectors.\n\n\ninit_kwargs\nReturns a dictionary containing kwargs that can be used to re-initialize the ObjectEmbedding.\n\n\nload\nLoads the model in order to be ready for embedding objects.\n\n\nvector_type\nReturns the datatype of the embedding vectors.\n\n\n\n\n\nvector_search.embeddings.ObjectEmbedding.dimensions()\nReturns the number of dimensions of the embedding vectors.\n\n\n\nvector_search.embeddings.ObjectEmbedding.embed(objects, metadata)\nCreates embedding vectors for objects. Returns a numpy array of embedding vectors. There is no enforced restriction on the object format. ObjectReaders and ObjectEmbeddings should use compatible object and metadata formats.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobjects\nOrderedDict\nAn OrderedDict, containing the object data, having structure similar to TileDB-Py read results.\nrequired\n\n\nmetadata\nOrderedDict\nAn OrderedDict, containing the object metadata, having structure similar to TileDB-Py read results.\nrequired\n\n\n\n\n\n\n\nvector_search.embeddings.ObjectEmbedding.init_kwargs()\nReturns a dictionary containing kwargs that can be used to re-initialize the ObjectEmbedding.\nThis is used to serialize the ObjectEmbedding and pass it as argument to UDF tasks.\n\n\n\nvector_search.embeddings.ObjectEmbedding.load()\nLoads the model in order to be ready for embedding objects.\nThis method will be called once per worker to avoid loading the model multiple times.\n\n\n\nvector_search.embeddings.ObjectEmbedding.vector_type()\nReturns the datatype of the embedding vectors."
  },
  {
    "objectID": "documentation/reference/embeddings.ObjectEmbedding.html#methods",
    "href": "documentation/reference/embeddings.ObjectEmbedding.html#methods",
    "title": "embeddings.ObjectEmbedding",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndimensions\nReturns the number of dimensions of the embedding vectors.\n\n\nembed\nCreates embedding vectors for objects. Returns a numpy array of embedding vectors.\n\n\ninit_kwargs\nReturns a dictionary containing kwargs that can be used to re-initialize the ObjectEmbedding.\n\n\nload\nLoads the model in order to be ready for embedding objects.\n\n\nvector_type\nReturns the datatype of the embedding vectors.\n\n\n\n\n\nvector_search.embeddings.ObjectEmbedding.dimensions()\nReturns the number of dimensions of the embedding vectors.\n\n\n\nvector_search.embeddings.ObjectEmbedding.embed(objects, metadata)\nCreates embedding vectors for objects. Returns a numpy array of embedding vectors. There is no enforced restriction on the object format. ObjectReaders and ObjectEmbeddings should use compatible object and metadata formats.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nobjects\nOrderedDict\nAn OrderedDict, containing the object data, having structure similar to TileDB-Py read results.\nrequired\n\n\nmetadata\nOrderedDict\nAn OrderedDict, containing the object metadata, having structure similar to TileDB-Py read results.\nrequired\n\n\n\n\n\n\n\nvector_search.embeddings.ObjectEmbedding.init_kwargs()\nReturns a dictionary containing kwargs that can be used to re-initialize the ObjectEmbedding.\nThis is used to serialize the ObjectEmbedding and pass it as argument to UDF tasks.\n\n\n\nvector_search.embeddings.ObjectEmbedding.load()\nLoads the model in order to be ready for embedding objects.\nThis method will be called once per worker to avoid loading the model multiple times.\n\n\n\nvector_search.embeddings.ObjectEmbedding.vector_type()\nReturns the datatype of the embedding vectors."
  },
  {
    "objectID": "documentation/reference/object_api.create.html",
    "href": "documentation/reference/object_api.create.html",
    "title": "object_api.create",
    "section": "",
    "text": "vector_search.object_api.create(uri, index_type, object_reader, embedding, config=None, storage_version=STORAGE_VERSION, metadata_tile_size=10000, **kwargs)\nCreates a new ObjectIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nThe URI of the index.\nrequired\n\n\nindex_type\nstr\nThe type of index to create. Can be one of “FLAT”, “IVF_FLAT”, “VAMANA”, or “IVF_PQ”.\nrequired\n\n\nobject_reader\nObjectReader\nThe object reader to use for the index.\nrequired\n\n\nembedding\nObjectEmbedding\nThe embedding function to use for the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe storage version to use for the index.\nSTORAGE_VERSION\n\n\n**kwargs\n\nKeyword arguments to pass to the index constructor.\n{}\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nObjectIndex\nThe newly created ObjectIndex."
  },
  {
    "objectID": "documentation/reference/object_api.create.html#parameters",
    "href": "documentation/reference/object_api.create.html#parameters",
    "title": "object_api.create",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nThe URI of the index.\nrequired\n\n\nindex_type\nstr\nThe type of index to create. Can be one of “FLAT”, “IVF_FLAT”, “VAMANA”, or “IVF_PQ”.\nrequired\n\n\nobject_reader\nObjectReader\nThe object reader to use for the index.\nrequired\n\n\nembedding\nObjectEmbedding\nThe embedding function to use for the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe storage version to use for the index.\nSTORAGE_VERSION\n\n\n**kwargs\n\nKeyword arguments to pass to the index constructor.\n{}"
  },
  {
    "objectID": "documentation/reference/object_api.create.html#returns",
    "href": "documentation/reference/object_api.create.html#returns",
    "title": "object_api.create",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nObjectIndex\nThe newly created ObjectIndex."
  },
  {
    "objectID": "documentation/Benchmarks.html",
    "href": "documentation/Benchmarks.html",
    "title": "Benchmarks",
    "section": "",
    "text": "We have implemented a big-ann-benchmarks interface for TileDB-Vector-Search, which is available in the tiledb branch of our fork:\n\nhttps://github.com/TileDB-Inc/big-ann-benchmarks/tree/tiledb. This interface implements two new algorithms: tiledb-flat and tiledb-ivf-flat, which are usable within the framework’s runner.\n\n\n\n\nBuild the Dockerfile at the root of this repository:\n\ncd tiledb-vector-search\ndocker build -f Dockerfile . -t tiledb_vs\n\nBuild the TileDB docker image in the big-ann fork (requires image from step 1):\n\ngit clone https://github.com/TileDB-Inc/big-ann-benchmarks/tree/tiledb\ncd big-ann-benchmarks\ndocker build -f install/Dockerfile.tiledb . -t billion-scale-benchmark-tiledb\n\n\n\n\nCreate a local dataset.\nnote: the create_dataset.py command will download remote files the first time it runs, some of which can total &gt;100GB). Use --skip-data to avoid downloading the large base set.\nThis command will download 7.7MB of data:\n\npython create_dataset.py --dataset bigann-10M --skip-data\n\nRun the benchmarks, choosing either tiledb-flat or tiledb-ivf-flat:\n\npython run.py --dataset bigann-10M --algorithm tiledb-flat",
    "crumbs": [
      "Home page",
      "Benchmarks"
    ]
  },
  {
    "objectID": "documentation/Benchmarks.html#building",
    "href": "documentation/Benchmarks.html#building",
    "title": "Benchmarks",
    "section": "",
    "text": "Build the Dockerfile at the root of this repository:\n\ncd tiledb-vector-search\ndocker build -f Dockerfile . -t tiledb_vs\n\nBuild the TileDB docker image in the big-ann fork (requires image from step 1):\n\ngit clone https://github.com/TileDB-Inc/big-ann-benchmarks/tree/tiledb\ncd big-ann-benchmarks\ndocker build -f install/Dockerfile.tiledb . -t billion-scale-benchmark-tiledb",
    "crumbs": [
      "Home page",
      "Benchmarks"
    ]
  },
  {
    "objectID": "documentation/Benchmarks.html#running-benchmarks",
    "href": "documentation/Benchmarks.html#running-benchmarks",
    "title": "Benchmarks",
    "section": "",
    "text": "Create a local dataset.\nnote: the create_dataset.py command will download remote files the first time it runs, some of which can total &gt;100GB). Use --skip-data to avoid downloading the large base set.\nThis command will download 7.7MB of data:\n\npython create_dataset.py --dataset bigann-10M --skip-data\n\nRun the benchmarks, choosing either tiledb-flat or tiledb-ivf-flat:\n\npython run.py --dataset bigann-10M --algorithm tiledb-flat",
    "crumbs": [
      "Home page",
      "Benchmarks"
    ]
  }
]