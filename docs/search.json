[
  {
    "objectID": "documentation/Building.html",
    "href": "documentation/Building.html",
    "title": "Building From Source",
    "section": "",
    "text": "TileDB Vector Search can be built from source. For information on dependencies, see below.\n\n\npip install git+https://github.com/TileDB-Inc/TileDB-Vector-Search.git#subdirectory=apis/python\n\n\n\ncd apis/python\npip install ."
  },
  {
    "objectID": "documentation/Building.html#installation-from-github-with-pip",
    "href": "documentation/Building.html#installation-from-github-with-pip",
    "title": "Building From Source",
    "section": "",
    "text": "pip install git+https://github.com/TileDB-Inc/TileDB-Vector-Search.git#subdirectory=apis/python"
  },
  {
    "objectID": "documentation/Building.html#installation-from-a-local-checkout",
    "href": "documentation/Building.html#installation-from-a-local-checkout",
    "title": "Building From Source",
    "section": "",
    "text": "cd apis/python\npip install ."
  },
  {
    "objectID": "documentation/Building.html#linux",
    "href": "documentation/Building.html#linux",
    "title": "Building From Source",
    "section": "Linux",
    "text": "Linux\nThere are several dependencies needed, for Ubuntu you can install via:\napt-get openblas-dev build-essentials cmake3\nTo build the python API after you have the dependencies, use pip:\ncd apis/python\npip install ."
  },
  {
    "objectID": "documentation/Building.html#docker",
    "href": "documentation/Building.html#docker",
    "title": "Building From Source",
    "section": "Docker",
    "text": "Docker\nA docker image is also provided for simplicity:\ndocker build -t tiledb/tiledb-vector-search .\nYou run the example docker image which provides the python package with:\ndocker run --rm tiledb/tiledb-vector-search"
  },
  {
    "objectID": "documentation/reference/ingestion.html",
    "href": "documentation/reference/ingestion.html",
    "title": "ingestion",
    "section": "",
    "text": "vector_search.ingestion\n\n\n\n\n\nName\nDescription\n\n\n\n\ningest\nIngest vectors into TileDB.\n\n\n\n\n\nvector_search.ingestion.ingest(index_type, index_uri, *, input_vectors=None, source_uri=None, source_type=None, external_ids=None, external_ids_uri='', external_ids_type=None, updates_uri=None, index_timestamp=None, config=None, namespace=None, size=-1, partitions=-1, copy_centroids_uri=None, training_sample_size=-1, workers=-1, input_vectors_per_work_item=-1, storage_version=STORAGE_VERSION, verbose=False, trace_id=None, use_sklearn=False, mode=Mode.LOCAL, **kwargs)\nIngest vectors into TileDB.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nindex_type\nstr\nType of vector index (FLAT, IVF_FLAT)\nrequired\n\n\nindex_uri\nstr\nVector index URI (stored as TileDB group)\nrequired\n\n\ninput_vectors\nnp.ndarray\nInput vectors, if this is provided it takes precedence over source_uri and source_type.\nNone\n\n\nsource_uri\nstr\nData source URI\nNone\n\n\nsource_type\nstr\nType of the source data. If left empty it is auto-detected from the suffix of source_uri\nNone\n\n\nexternal_ids\nnp.array\nInput vector external_ids, if this is provided it takes precedence over external_ids_uri and external_ids_type\nNone\n\n\nexternal_ids_uri\nstr\nSource URI for external_ids\n''\n\n\nexternal_ids_type\nstr\nFile type of external_ids_uri. If left empty it is auto-detected from the suffix of external_ids_uri\nNone\n\n\nupdates_uri\nstr\nUpdates\nNone\n\n\nindex_timestamp\nint\nTimestamp to use for writing and reading data. By default it sues the current unix ms timestamp.\nNone\n\n\nconfig\nOptional[Mapping[str, Any]]\nconfig dictionary, defaults to None\nNone\n\n\nnamespace\nOptional[str]\nTileDB-Cloud namespace, defaults to None\nNone\n\n\nsize\nint\nNumber of input vectors, if not provided use the full size of the input dataset\n-1\n\n\npartitions\nint\nNumber of partitions to load the data with, if not provided, is auto-configured based on the dataset size\n-1\n\n\ncopy_centroids_uri\nstr\nTileDB array URI to copy centroids from, if not provided, centroids are build running kmeans\nNone\n\n\ntraining_sample_size\nint\nvector sample size to train centroids with, if not provided, is auto-configured based on the dataset sizes\n-1\n\n\nworkers\nint\nnumber of workers for vector ingestion, if not provided, is auto-configured based on the dataset size\n-1\n\n\ninput_vectors_per_work_item\nint\nnumber of vectors per ingestion work item, if not provided, is auto-configured\n-1\n\n\nstorage_version\nstr\nVector index storage format version.\nSTORAGE_VERSION\n\n\nverbose\nbool\nverbose logging, defaults to False\nFalse\n\n\ntrace_id\nOptional[str]\ntrace ID for logging, defaults to None\nNone\n\n\nuse_sklearn\nbool\nWhether to use scikit-learn’s implementation of k-means clustering instead of tiledb.vector_search’s. Defaults to false.\nFalse\n\n\nmode\nMode\nexecution mode, defaults to LOCAL use BATCH for distributed execution\nMode.LOCAL"
  },
  {
    "objectID": "documentation/reference/ingestion.html#functions",
    "href": "documentation/reference/ingestion.html#functions",
    "title": "ingestion",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ningest\nIngest vectors into TileDB.\n\n\n\n\n\nvector_search.ingestion.ingest(index_type, index_uri, *, input_vectors=None, source_uri=None, source_type=None, external_ids=None, external_ids_uri='', external_ids_type=None, updates_uri=None, index_timestamp=None, config=None, namespace=None, size=-1, partitions=-1, copy_centroids_uri=None, training_sample_size=-1, workers=-1, input_vectors_per_work_item=-1, storage_version=STORAGE_VERSION, verbose=False, trace_id=None, use_sklearn=False, mode=Mode.LOCAL, **kwargs)\nIngest vectors into TileDB.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nindex_type\nstr\nType of vector index (FLAT, IVF_FLAT)\nrequired\n\n\nindex_uri\nstr\nVector index URI (stored as TileDB group)\nrequired\n\n\ninput_vectors\nnp.ndarray\nInput vectors, if this is provided it takes precedence over source_uri and source_type.\nNone\n\n\nsource_uri\nstr\nData source URI\nNone\n\n\nsource_type\nstr\nType of the source data. If left empty it is auto-detected from the suffix of source_uri\nNone\n\n\nexternal_ids\nnp.array\nInput vector external_ids, if this is provided it takes precedence over external_ids_uri and external_ids_type\nNone\n\n\nexternal_ids_uri\nstr\nSource URI for external_ids\n''\n\n\nexternal_ids_type\nstr\nFile type of external_ids_uri. If left empty it is auto-detected from the suffix of external_ids_uri\nNone\n\n\nupdates_uri\nstr\nUpdates\nNone\n\n\nindex_timestamp\nint\nTimestamp to use for writing and reading data. By default it sues the current unix ms timestamp.\nNone\n\n\nconfig\nOptional[Mapping[str, Any]]\nconfig dictionary, defaults to None\nNone\n\n\nnamespace\nOptional[str]\nTileDB-Cloud namespace, defaults to None\nNone\n\n\nsize\nint\nNumber of input vectors, if not provided use the full size of the input dataset\n-1\n\n\npartitions\nint\nNumber of partitions to load the data with, if not provided, is auto-configured based on the dataset size\n-1\n\n\ncopy_centroids_uri\nstr\nTileDB array URI to copy centroids from, if not provided, centroids are build running kmeans\nNone\n\n\ntraining_sample_size\nint\nvector sample size to train centroids with, if not provided, is auto-configured based on the dataset sizes\n-1\n\n\nworkers\nint\nnumber of workers for vector ingestion, if not provided, is auto-configured based on the dataset size\n-1\n\n\ninput_vectors_per_work_item\nint\nnumber of vectors per ingestion work item, if not provided, is auto-configured\n-1\n\n\nstorage_version\nstr\nVector index storage format version.\nSTORAGE_VERSION\n\n\nverbose\nbool\nverbose logging, defaults to False\nFalse\n\n\ntrace_id\nOptional[str]\ntrace ID for logging, defaults to None\nNone\n\n\nuse_sklearn\nbool\nWhether to use scikit-learn’s implementation of k-means clustering instead of tiledb.vector_search’s. Defaults to false.\nFalse\n\n\nmode\nMode\nexecution mode, defaults to LOCAL use BATCH for distributed execution\nMode.LOCAL"
  },
  {
    "objectID": "documentation/reference/flat_index.FlatIndex.html",
    "href": "documentation/reference/flat_index.FlatIndex.html",
    "title": "flat_index.FlatIndex",
    "section": "",
    "text": "vector_search.flat_index.FlatIndex(self, uri, config=None, timestamp=None, **kwargs)\nOpen a flat index\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nconfig dictionary, defaults to None\nNone\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nquery_internal\nQuery a flat index\n\n\n\n\n\nvector_search.flat_index.FlatIndex.query_internal(queries, k=10, nthreads=8)\nQuery a flat index\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\nND Array of queries\nrequired\n\n\nk\nint\nNumber of top results to return per query\n10\n\n\nnthreads\nint\nNumber of threads to use for query\n8"
  },
  {
    "objectID": "documentation/reference/flat_index.FlatIndex.html#parameters",
    "href": "documentation/reference/flat_index.FlatIndex.html#parameters",
    "title": "flat_index.FlatIndex",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nconfig dictionary, defaults to None\nNone"
  },
  {
    "objectID": "documentation/reference/flat_index.FlatIndex.html#methods",
    "href": "documentation/reference/flat_index.FlatIndex.html#methods",
    "title": "flat_index.FlatIndex",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nquery_internal\nQuery a flat index\n\n\n\n\n\nvector_search.flat_index.FlatIndex.query_internal(queries, k=10, nthreads=8)\nQuery a flat index\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\nND Array of queries\nrequired\n\n\nk\nint\nNumber of top results to return per query\n10\n\n\nnthreads\nint\nNumber of threads to use for query\n8"
  },
  {
    "objectID": "documentation/reference/index.html",
    "href": "documentation/reference/index.html",
    "title": "Python",
    "section": "",
    "text": "index.Index\nOpen a Vector index\n\n\nflat_index.FlatIndex\nOpen a flat index\n\n\nivf_flat_index.IVFFlatIndex\nOpen a IVF Flat index\n\n\ningestion"
  },
  {
    "objectID": "documentation/reference/index.html#tiledb.vector_search",
    "href": "documentation/reference/index.html#tiledb.vector_search",
    "title": "Python",
    "section": "",
    "text": "index.Index\nOpen a Vector index\n\n\nflat_index.FlatIndex\nOpen a flat index\n\n\nivf_flat_index.IVFFlatIndex\nOpen a IVF Flat index\n\n\ningestion"
  },
  {
    "objectID": "documentation/index.html",
    "href": "documentation/index.html",
    "title": "TileDB Vector Search",
    "section": "",
    "text": "TileDB Vector Search\nTileDB-Vector-Search is a C++ library and Python API for vector search built on top of the TileDB Storage Engine.\n\n\nQuick Links\n\nBuild Instructions\nDocumentation\nPython API reference\n\n\n\nQuick Installation\nTileDB-Vector-Search is available from PyPI or the tiledb conda channel.\nTo install from PyPI with pip, use:\npip install tiledb-vector-search\nTo install from conda, use conda or mamba:\nconda install -c tiledb -c conda-forge tiledb-vector-search\nmamba install -c tiledb -c conda-forge tiledb-vector-search\n\n\nContributing\nWe welcome contributions. Please see Building for development-build instructions. For large new features, please open an issue to discuss goals and approach in order to ensure a smooth PR integration and review process. All contributions must be licensed under the repository’s MIT License."
  },
  {
    "objectID": "documentation/reference/index.Index.html",
    "href": "documentation/reference/index.Index.html",
    "title": "index.Index",
    "section": "",
    "text": "vector_search.index.Index(self, uri, config=None, timestamp=None)\nOpen a Vector index\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nconfig dictionary, defaults to None\nNone\n\n\ntimestamp\n\n(default None) If int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone"
  },
  {
    "objectID": "documentation/reference/index.Index.html#parameters",
    "href": "documentation/reference/index.Index.html#parameters",
    "title": "index.Index",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nconfig dictionary, defaults to None\nNone\n\n\ntimestamp\n\n(default None) If int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone"
  },
  {
    "objectID": "documentation/reference/ivf_flat_index.IVFFlatIndex.html",
    "href": "documentation/reference/ivf_flat_index.IVFFlatIndex.html",
    "title": "ivf_flat_index.IVFFlatIndex",
    "section": "",
    "text": "vector_search.ivf_flat_index.IVFFlatIndex(self, uri, config=None, timestamp=None, memory_budget=-1, **kwargs)\nOpen a IVF Flat index\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nconfig dictionary, defaults to None\nNone\n\n\nmemory_budget\nint\nMain memory budget. If not provided, no memory budget is applied.\n-1\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nquery_internal\nQuery an IVF_FLAT index\n\n\ntaskgraph_query\nQuery an IVF_FLAT index using TileDB cloud taskgraphs\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.query_internal(queries, k=10, nprobe=1, nthreads=-1, use_nuv_implementation=False, mode=None, num_partitions=-1, num_workers=-1)\nQuery an IVF_FLAT index\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\nND Array of queries\nrequired\n\n\nk\nint\nNumber of top results to return per query\n10\n\n\nnprobe\nint\nnumber of probes\n1\n\n\nnthreads\nint\nNumber of threads to use for query\n-1\n\n\nuse_nuv_implementation\nbool\nwether to use the nuv query implementation. Default: False\nFalse\n\n\nmode\nMode\nIf provided the query will be executed using TileDB cloud taskgraphs. For distributed execution you can use REALTIME or BATCH mode\nNone\n\n\nnum_partitions\nint\nOnly relevant for taskgraph based execution. If provided, we split the query execution in that many partitions.\n-1\n\n\nnum_workers\nint\nOnly relevant for taskgraph based execution. If provided, this is the number of workers to use for the query execution.\n-1\n\n\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.taskgraph_query(queries, k=10, nprobe=10, nthreads=-1, mode=None, num_partitions=-1, num_workers=-1, config=None)\nQuery an IVF_FLAT index using TileDB cloud taskgraphs\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\nND Array of queries\nrequired\n\n\nk\nint\nNumber of top results to return per query\n10\n\n\nnprobe\nint\nnumber of probes\n10\n\n\nnthreads\nint\nNumber of threads to use for query\n-1\n\n\nmode\nMode\nIf provided the query will be executed using TileDB cloud taskgraphs. For distributed execution you can use REALTIME or BATCH mode\nNone\n\n\nnum_partitions\nint\nOnly relevant for taskgraph based execution. If provided, we split the query execution in that many partitions.\n-1\n\n\nnum_workers\nint\nOnly relevant for taskgraph based execution. If provided, this is the number of workers to use for the query execution.\n-1\n\n\nconfig\nOptional[Mapping[str, Any]]\nconfig dictionary, defaults to None\nNone"
  },
  {
    "objectID": "documentation/reference/ivf_flat_index.IVFFlatIndex.html#parameters",
    "href": "documentation/reference/ivf_flat_index.IVFFlatIndex.html#parameters",
    "title": "ivf_flat_index.IVFFlatIndex",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nconfig dictionary, defaults to None\nNone\n\n\nmemory_budget\nint\nMain memory budget. If not provided, no memory budget is applied.\n-1"
  },
  {
    "objectID": "documentation/reference/ivf_flat_index.IVFFlatIndex.html#methods",
    "href": "documentation/reference/ivf_flat_index.IVFFlatIndex.html#methods",
    "title": "ivf_flat_index.IVFFlatIndex",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nquery_internal\nQuery an IVF_FLAT index\n\n\ntaskgraph_query\nQuery an IVF_FLAT index using TileDB cloud taskgraphs\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.query_internal(queries, k=10, nprobe=1, nthreads=-1, use_nuv_implementation=False, mode=None, num_partitions=-1, num_workers=-1)\nQuery an IVF_FLAT index\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\nND Array of queries\nrequired\n\n\nk\nint\nNumber of top results to return per query\n10\n\n\nnprobe\nint\nnumber of probes\n1\n\n\nnthreads\nint\nNumber of threads to use for query\n-1\n\n\nuse_nuv_implementation\nbool\nwether to use the nuv query implementation. Default: False\nFalse\n\n\nmode\nMode\nIf provided the query will be executed using TileDB cloud taskgraphs. For distributed execution you can use REALTIME or BATCH mode\nNone\n\n\nnum_partitions\nint\nOnly relevant for taskgraph based execution. If provided, we split the query execution in that many partitions.\n-1\n\n\nnum_workers\nint\nOnly relevant for taskgraph based execution. If provided, this is the number of workers to use for the query execution.\n-1\n\n\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.taskgraph_query(queries, k=10, nprobe=10, nthreads=-1, mode=None, num_partitions=-1, num_workers=-1, config=None)\nQuery an IVF_FLAT index using TileDB cloud taskgraphs\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\nND Array of queries\nrequired\n\n\nk\nint\nNumber of top results to return per query\n10\n\n\nnprobe\nint\nnumber of probes\n10\n\n\nnthreads\nint\nNumber of threads to use for query\n-1\n\n\nmode\nMode\nIf provided the query will be executed using TileDB cloud taskgraphs. For distributed execution you can use REALTIME or BATCH mode\nNone\n\n\nnum_partitions\nint\nOnly relevant for taskgraph based execution. If provided, we split the query execution in that many partitions.\n-1\n\n\nnum_workers\nint\nOnly relevant for taskgraph based execution. If provided, this is the number of workers to use for the query execution.\n-1\n\n\nconfig\nOptional[Mapping[str, Any]]\nconfig dictionary, defaults to None\nNone"
  },
  {
    "objectID": "documentation/Benchmarks.html",
    "href": "documentation/Benchmarks.html",
    "title": "Benchmarks",
    "section": "",
    "text": "We have implemented a big-ann-benchmarks interface for TileDB-Vector-Search, which is available in the tiledb branch of our fork: - https://github.com/TileDB-Inc/big-ann-benchmarks/tree/tiledb. This interface implements two new algorithms: tiledb-flat and tiledb-ivf-flat, which are usable within the framework’s runner.\n\n\n\nBuild the Dockerfile at the root of this repository:\n\ncd tiledb-vector-search\ndocker build -f Dockerfile . -t tiledb_vs\n\nBuild the TileDB docker image in the big-ann fork (requires image from step 1):\n\ngit clone https://github.com/TileDB-Inc/big-ann-benchmarks/tree/tiledb\ncd big-ann-benchmarks\ndocker build -f install/Dockerfile.tiledb . -t billion-scale-benchmark-tiledb\n\n\n\n\nCreate a local dataset.\nnote: the create_dataset.py command will download remote files the first time it runs, some of which can total &gt;100GB). Use --skip-data to avoid downloading the large base set.\nThis command will download 7.7MB of data:\n\npython create_dataset.py --dataset bigann-10M --skip-data\n\nRun the benchmarks, choosing either tiledb-flat or tiledb-ivf-flat:\n\npython run.py --dataset bigann-10M --algorithm tiledb-flat"
  },
  {
    "objectID": "documentation/Benchmarks.html#building",
    "href": "documentation/Benchmarks.html#building",
    "title": "Benchmarks",
    "section": "",
    "text": "Build the Dockerfile at the root of this repository:\n\ncd tiledb-vector-search\ndocker build -f Dockerfile . -t tiledb_vs\n\nBuild the TileDB docker image in the big-ann fork (requires image from step 1):\n\ngit clone https://github.com/TileDB-Inc/big-ann-benchmarks/tree/tiledb\ncd big-ann-benchmarks\ndocker build -f install/Dockerfile.tiledb . -t billion-scale-benchmark-tiledb"
  },
  {
    "objectID": "documentation/Benchmarks.html#running-benchmarks",
    "href": "documentation/Benchmarks.html#running-benchmarks",
    "title": "Benchmarks",
    "section": "",
    "text": "Create a local dataset.\nnote: the create_dataset.py command will download remote files the first time it runs, some of which can total &gt;100GB). Use --skip-data to avoid downloading the large base set.\nThis command will download 7.7MB of data:\n\npython create_dataset.py --dataset bigann-10M --skip-data\n\nRun the benchmarks, choosing either tiledb-flat or tiledb-ivf-flat:\n\npython run.py --dataset bigann-10M --algorithm tiledb-flat"
  }
]