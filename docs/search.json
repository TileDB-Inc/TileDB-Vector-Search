[
  {
    "objectID": "documentation/Benchmarks.html",
    "href": "documentation/Benchmarks.html",
    "title": "Benchmarks",
    "section": "",
    "text": "We have implemented a big-ann-benchmarks interface for TileDB-Vector-Search, which is available in the tiledb branch of our fork:\n\nhttps://github.com/TileDB-Inc/big-ann-benchmarks/tree/tiledb. This interface implements two new algorithms: tiledb-flat and tiledb-ivf-flat, which are usable within the framework’s runner.\n\n\n\n\nBuild the Dockerfile at the root of this repository:\n\ncd tiledb-vector-search\ndocker build -f Dockerfile . -t tiledb_vs\n\nBuild the TileDB docker image in the big-ann fork (requires image from step 1):\n\ngit clone https://github.com/TileDB-Inc/big-ann-benchmarks/tree/tiledb\ncd big-ann-benchmarks\ndocker build -f install/Dockerfile.tiledb . -t billion-scale-benchmark-tiledb\n\n\n\n\nCreate a local dataset.\nnote: the create_dataset.py command will download remote files the first time it runs, some of which can total &gt;100GB). Use --skip-data to avoid downloading the large base set.\nThis command will download 7.7MB of data:\n\npython create_dataset.py --dataset bigann-10M --skip-data\n\nRun the benchmarks, choosing either tiledb-flat or tiledb-ivf-flat:\n\npython run.py --dataset bigann-10M --algorithm tiledb-flat",
    "crumbs": [
      "Home page",
      "Benchmarks"
    ]
  },
  {
    "objectID": "documentation/Benchmarks.html#building",
    "href": "documentation/Benchmarks.html#building",
    "title": "Benchmarks",
    "section": "",
    "text": "Build the Dockerfile at the root of this repository:\n\ncd tiledb-vector-search\ndocker build -f Dockerfile . -t tiledb_vs\n\nBuild the TileDB docker image in the big-ann fork (requires image from step 1):\n\ngit clone https://github.com/TileDB-Inc/big-ann-benchmarks/tree/tiledb\ncd big-ann-benchmarks\ndocker build -f install/Dockerfile.tiledb . -t billion-scale-benchmark-tiledb",
    "crumbs": [
      "Home page",
      "Benchmarks"
    ]
  },
  {
    "objectID": "documentation/Benchmarks.html#running-benchmarks",
    "href": "documentation/Benchmarks.html#running-benchmarks",
    "title": "Benchmarks",
    "section": "",
    "text": "Create a local dataset.\nnote: the create_dataset.py command will download remote files the first time it runs, some of which can total &gt;100GB). Use --skip-data to avoid downloading the large base set.\nThis command will download 7.7MB of data:\n\npython create_dataset.py --dataset bigann-10M --skip-data\n\nRun the benchmarks, choosing either tiledb-flat or tiledb-ivf-flat:\n\npython run.py --dataset bigann-10M --algorithm tiledb-flat",
    "crumbs": [
      "Home page",
      "Benchmarks"
    ]
  },
  {
    "objectID": "documentation/reference/ingestion.html",
    "href": "documentation/reference/ingestion.html",
    "title": "ingestion",
    "section": "",
    "text": "vector_search.ingestion\nVector Search ingestion Utilities\nThis contains the ingestion implementation for different TileDB Vector Search algorithms.\nIt enables:\n\nLocal ingestion:\n\nMulti-threaded execution that can leverage all the available local computing resources.\n\nDistributed ingestion:\n\nDistributed ingestion execution with multiple workers in TileDB Cloud. This can be used to ingest large datasets and speedup ingestion latency.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ningest\nIngest vectors into TileDB.\n\n\n\n\n\nvector_search.ingestion.ingest(index_type, index_uri, *, input_vectors=None, source_uri=None, source_type=None, external_ids=None, external_ids_uri='', external_ids_type=None, updates_uri=None, index_timestamp=None, config=None, namespace=None, size=-1, partitions=-1, training_sampling_policy=TrainingSamplingPolicy.FIRST_N, copy_centroids_uri=None, training_sample_size=-1, training_input_vectors=None, training_source_uri=None, training_source_type=None, workers=-1, input_vectors_per_work_item=-1, max_tasks_per_stage=-1, input_vectors_per_work_item_during_sampling=-1, max_sampling_tasks=-1, storage_version=STORAGE_VERSION, verbose=False, trace_id=None, use_sklearn=True, mode=Mode.LOCAL, acn=None, ingest_resources=None, consolidate_partition_resources=None, copy_centroids_resources=None, random_sample_resources=None, kmeans_resources=None, compute_new_centroids_resources=None, assign_points_and_partial_new_centroids_resources=None, write_centroids_resources=None, partial_index_resources=None, **kwargs)\nIngest vectors into TileDB.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nindex_type\nstr\nType of vector index (FLAT, IVF_FLAT, VAMANA).\nrequired\n\n\nindex_uri\nstr\nVector index URI (stored as TileDB group).\nrequired\n\n\ninput_vectors\nnp.ndarray\nInput vectors, if this is provided it takes precedence over source_uri and source_type.\nNone\n\n\nsource_uri\nstr\nVectors source URI.\nNone\n\n\nsource_type\nstr\nType of the source vectors. If left empty it is auto-detected.\nNone\n\n\nexternal_ids\nnp.array\nInput vector external_ids, if this is provided it takes precedence over external_ids_uri and external_ids_type.\nNone\n\n\nexternal_ids_uri\nstr\nSource URI for external_ids.\n''\n\n\nexternal_ids_type\nstr\nFile type of external_ids_uri. If left empty it is auto-detected.\nNone\n\n\nupdates_uri\nstr\nUpdates array URI. Used for consolidation of updates.\nNone\n\n\nindex_timestamp\nint\nTimestamp to use for writing and reading data. By default it uses the current unix ms timestamp.\nNone\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nnamespace\nOptional[str]\nTileDB-Cloud namespace to use for Cloud execution.\nNone\n\n\nsize\nint\nNumber of input vectors, if not provided use the full size of the input dataset. If provided, we filter the first vectors from the input source.\n-1\n\n\npartitions\nint\nNumber of partitions to load the data with, if not provided, is auto-configured based on the dataset size.\n-1\n\n\ncopy_centroids_uri\nstr\nTileDB array URI to copy centroids from, if not provided, centroids are build running k-means.\nNone\n\n\ntraining_sample_size\nint\nSample size to use for computing k-means. If not provided, is auto-configured based on the dataset sizes. Should not be provided if training_source_uri is provided.\n-1\n\n\ntraining_input_vectors\nnp.ndarray\nTraining input vectors, if this is provided it takes precedence over training_source_uri and training_source_type. Should not be provided if training_sample_size or training_source_uri are provided.\nNone\n\n\ntraining_source_uri\nstr\nThe source URI to use for training centroids when building a IVF_FLAT vector index. If not provided, the first training_sample_size vectors from source_uri are used. Should not be provided if training_sample_size or training_input_vectors is provided.\nNone\n\n\ntraining_source_type\nstr\nType of the training source data in training_source_uri. If left empty, is auto-detected. Should only be provided when training_source_uri is provided.\nNone\n\n\nworkers\nint\nNumber of distributed workers to use for vector ingestion. If not provided, is auto-configured based on the dataset size.\n-1\n\n\ninput_vectors_per_work_item\nint\nNumber of vectors per ingestion work item. If not provided, is auto-configured.\n-1\n\n\nmax_tasks_per_stage\nint\nMax number of tasks per execution stage of ingestion. If not provided, is auto-configured.\n-1\n\n\ninput_vectors_per_work_item_during_sampling\nint\nNumber of vectors per sample ingestion work item. iIf not provided, is auto-configured. Only valid with training_sampling_policy=TrainingSamplingPolicy.RANDOM.\n-1\n\n\nmax_sampling_tasks\nint\nMax number of tasks per execution stage of sampling. If not provided, is auto-configured Only valid with training_sampling_policy=TrainingSamplingPolicy.RANDOM.\n-1\n\n\nstorage_version\nstr\nVector index storage format version. If not provided, defaults to the latest version.\nSTORAGE_VERSION\n\n\nverbose\nbool\nEnables verbose logging.\nFalse\n\n\ntrace_id\nOptional[str]\ntrace ID for logging.\nNone\n\n\nuse_sklearn\nbool\nWhether to use scikit-learn’s implementation of k-means clustering instead of tiledb.vector_search’s.\nTrue\n\n\nmode\nMode\nExecution mode, defaults to LOCAL use BATCH for distributed execution.\nMode.LOCAL\n\n\nacn\nOptional[str]\nAccess credential name to be used when running in BATCH mode for object store access\nNone\n\n\ningest_resources\nOptional[Mapping[str, Any]]\nResources to request when performing vector ingestion, only applies to BATCH mode\nNone\n\n\nconsolidate_partition_resources\nOptional[Mapping[str, Any]]\nResources to request when performing consolidation of a partition, only applies to BATCH mode\nNone\n\n\ncopy_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing copy of centroids from input array to output array, only applies to BATCH mode\nNone\n\n\nrandom_sample_resources\nOptional[Mapping[str, Any]]\nResources to request when performing random sample selection, only applies to BATCH mode\nNone\n\n\nkmeans_resources\nOptional[Mapping[str, Any]]\nResources to request when performing kmeans task, only applies to BATCH mode\nNone\n\n\ncompute_new_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing centroid computation, only applies to BATCH mode\nNone\n\n\nassign_points_and_partial_new_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the computation of partial centroids, only applies to BATCH mode\nNone\n\n\nwrite_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the write of centroids, only applies to BATCH mode\nNone\n\n\npartial_index_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the computation of partial indexing, only applies to BATCH mode\nNone"
  },
  {
    "objectID": "documentation/reference/ingestion.html#functions",
    "href": "documentation/reference/ingestion.html#functions",
    "title": "ingestion",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ningest\nIngest vectors into TileDB.\n\n\n\n\n\nvector_search.ingestion.ingest(index_type, index_uri, *, input_vectors=None, source_uri=None, source_type=None, external_ids=None, external_ids_uri='', external_ids_type=None, updates_uri=None, index_timestamp=None, config=None, namespace=None, size=-1, partitions=-1, training_sampling_policy=TrainingSamplingPolicy.FIRST_N, copy_centroids_uri=None, training_sample_size=-1, training_input_vectors=None, training_source_uri=None, training_source_type=None, workers=-1, input_vectors_per_work_item=-1, max_tasks_per_stage=-1, input_vectors_per_work_item_during_sampling=-1, max_sampling_tasks=-1, storage_version=STORAGE_VERSION, verbose=False, trace_id=None, use_sklearn=True, mode=Mode.LOCAL, acn=None, ingest_resources=None, consolidate_partition_resources=None, copy_centroids_resources=None, random_sample_resources=None, kmeans_resources=None, compute_new_centroids_resources=None, assign_points_and_partial_new_centroids_resources=None, write_centroids_resources=None, partial_index_resources=None, **kwargs)\nIngest vectors into TileDB.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nindex_type\nstr\nType of vector index (FLAT, IVF_FLAT, VAMANA).\nrequired\n\n\nindex_uri\nstr\nVector index URI (stored as TileDB group).\nrequired\n\n\ninput_vectors\nnp.ndarray\nInput vectors, if this is provided it takes precedence over source_uri and source_type.\nNone\n\n\nsource_uri\nstr\nVectors source URI.\nNone\n\n\nsource_type\nstr\nType of the source vectors. If left empty it is auto-detected.\nNone\n\n\nexternal_ids\nnp.array\nInput vector external_ids, if this is provided it takes precedence over external_ids_uri and external_ids_type.\nNone\n\n\nexternal_ids_uri\nstr\nSource URI for external_ids.\n''\n\n\nexternal_ids_type\nstr\nFile type of external_ids_uri. If left empty it is auto-detected.\nNone\n\n\nupdates_uri\nstr\nUpdates array URI. Used for consolidation of updates.\nNone\n\n\nindex_timestamp\nint\nTimestamp to use for writing and reading data. By default it uses the current unix ms timestamp.\nNone\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nnamespace\nOptional[str]\nTileDB-Cloud namespace to use for Cloud execution.\nNone\n\n\nsize\nint\nNumber of input vectors, if not provided use the full size of the input dataset. If provided, we filter the first vectors from the input source.\n-1\n\n\npartitions\nint\nNumber of partitions to load the data with, if not provided, is auto-configured based on the dataset size.\n-1\n\n\ncopy_centroids_uri\nstr\nTileDB array URI to copy centroids from, if not provided, centroids are build running k-means.\nNone\n\n\ntraining_sample_size\nint\nSample size to use for computing k-means. If not provided, is auto-configured based on the dataset sizes. Should not be provided if training_source_uri is provided.\n-1\n\n\ntraining_input_vectors\nnp.ndarray\nTraining input vectors, if this is provided it takes precedence over training_source_uri and training_source_type. Should not be provided if training_sample_size or training_source_uri are provided.\nNone\n\n\ntraining_source_uri\nstr\nThe source URI to use for training centroids when building a IVF_FLAT vector index. If not provided, the first training_sample_size vectors from source_uri are used. Should not be provided if training_sample_size or training_input_vectors is provided.\nNone\n\n\ntraining_source_type\nstr\nType of the training source data in training_source_uri. If left empty, is auto-detected. Should only be provided when training_source_uri is provided.\nNone\n\n\nworkers\nint\nNumber of distributed workers to use for vector ingestion. If not provided, is auto-configured based on the dataset size.\n-1\n\n\ninput_vectors_per_work_item\nint\nNumber of vectors per ingestion work item. If not provided, is auto-configured.\n-1\n\n\nmax_tasks_per_stage\nint\nMax number of tasks per execution stage of ingestion. If not provided, is auto-configured.\n-1\n\n\ninput_vectors_per_work_item_during_sampling\nint\nNumber of vectors per sample ingestion work item. iIf not provided, is auto-configured. Only valid with training_sampling_policy=TrainingSamplingPolicy.RANDOM.\n-1\n\n\nmax_sampling_tasks\nint\nMax number of tasks per execution stage of sampling. If not provided, is auto-configured Only valid with training_sampling_policy=TrainingSamplingPolicy.RANDOM.\n-1\n\n\nstorage_version\nstr\nVector index storage format version. If not provided, defaults to the latest version.\nSTORAGE_VERSION\n\n\nverbose\nbool\nEnables verbose logging.\nFalse\n\n\ntrace_id\nOptional[str]\ntrace ID for logging.\nNone\n\n\nuse_sklearn\nbool\nWhether to use scikit-learn’s implementation of k-means clustering instead of tiledb.vector_search’s.\nTrue\n\n\nmode\nMode\nExecution mode, defaults to LOCAL use BATCH for distributed execution.\nMode.LOCAL\n\n\nacn\nOptional[str]\nAccess credential name to be used when running in BATCH mode for object store access\nNone\n\n\ningest_resources\nOptional[Mapping[str, Any]]\nResources to request when performing vector ingestion, only applies to BATCH mode\nNone\n\n\nconsolidate_partition_resources\nOptional[Mapping[str, Any]]\nResources to request when performing consolidation of a partition, only applies to BATCH mode\nNone\n\n\ncopy_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing copy of centroids from input array to output array, only applies to BATCH mode\nNone\n\n\nrandom_sample_resources\nOptional[Mapping[str, Any]]\nResources to request when performing random sample selection, only applies to BATCH mode\nNone\n\n\nkmeans_resources\nOptional[Mapping[str, Any]]\nResources to request when performing kmeans task, only applies to BATCH mode\nNone\n\n\ncompute_new_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing centroid computation, only applies to BATCH mode\nNone\n\n\nassign_points_and_partial_new_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the computation of partial centroids, only applies to BATCH mode\nNone\n\n\nwrite_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the write of centroids, only applies to BATCH mode\nNone\n\n\npartial_index_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the computation of partial indexing, only applies to BATCH mode\nNone"
  },
  {
    "objectID": "documentation/reference/index.html",
    "href": "documentation/reference/index.html",
    "title": "Python",
    "section": "",
    "text": "index.Index\nAbstract Vector Index class.\n\n\nflat_index\nFlatIndex implementation.\n\n\nivf_flat_index\nIVFFlat Index implementation.\n\n\nvamana_index\nVamana Index implementation.\n\n\ningestion\nVector Search ingestion Utilities",
    "crumbs": [
      "Home page",
      "API Reference",
      "Python"
    ]
  },
  {
    "objectID": "documentation/reference/index.html#tiledb.vector_search",
    "href": "documentation/reference/index.html#tiledb.vector_search",
    "title": "Python",
    "section": "",
    "text": "index.Index\nAbstract Vector Index class.\n\n\nflat_index\nFlatIndex implementation.\n\n\nivf_flat_index\nIVFFlat Index implementation.\n\n\nvamana_index\nVamana Index implementation.\n\n\ningestion\nVector Search ingestion Utilities",
    "crumbs": [
      "Home page",
      "API Reference",
      "Python"
    ]
  },
  {
    "objectID": "documentation/reference/ivf_flat_index.html",
    "href": "documentation/reference/ivf_flat_index.html",
    "title": "ivf_flat_index",
    "section": "",
    "text": "vector_search.ivf_flat_index\nIVFFlat Index implementation.\nIVFFlatIndex is based on k-means clustering and shuffling of the dataset vectors.\nDuring ingestion, TileDB computes the k-means clusters and shuffles the vectors into partitions. The vectors are stored grouped by partition in a 2D TileDB array allowing for partitions to be read with minimal I/O overhead.\nTo answer a query, the search focuses only on a small number of partitions, based on the query’s proximity to the k-means centroids. This is specified with a parameter called nprobe controlling how many partitions are checked for each query.\nIVFFlatIndex provides a vector search implementation that can trade-off accuracy for performance.\nQueries can be run in multiple modes:\n\nLocal main memory:\n\nLoads the entire index in memory during initialization and uses it to answer queries.\n\nLocal out of core:\n\nAvoids loading index data in memory by interleaving I/O and query execution, respecting the memory budget defined by the user.\n\nDistributed execution:\n\nExecutes the queries using multiple workers in TileDB Cloud.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nIVFFlatIndex\nOpens an IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex(self, uri, config=None, timestamp=None, memory_budget=-1, **kwargs)\nOpens an IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nmemory_budget\nint\nMain memory budget, in number of vectors, for query execution. If not provided, all index data are loaded in main memory. Otherwise, no index data are loaded in main memory and this memory budget is applied during queries.\n-1\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries an IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.query_internal(queries, k=10, nprobe=1, nthreads=-1, use_nuv_implementation=False, mode=None, resource_class=None, resources=None, num_partitions=-1, num_workers=-1, **kwargs)\nQueries an IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nnprobe\nint\nNumber of partitions to check per query. Use this parameter to trade-off accuracy for latency and cost.\n1\n\n\nnthreads\nint\nNumber of threads to use for local query execution.\n-1\n\n\nuse_nuv_implementation\nbool\nWhether to use the nuv query implementation. Default: False\nFalse\n\n\nmode\nMode\nIf provided the query will be executed using TileDB cloud taskgraphs. For distributed execution you can use REALTIME or BATCH mode. For local execution you can use LOCAL mode.\nNone\n\n\nresource_class\nOptional[str]\nThe name of the resource class to use (“standard” or “large”). Resource classes define maximum limits for cpu and memory usage. Can only be used in REALTIME or BATCH mode. Cannot be used alongside resources. In REALTIME or BATCH mode if neither resource_class nor resources are provided, we default to the “large” resource class.\nNone\n\n\nresources\nOptional[Mapping[str, Any]]\nA specification for the amount of resources to use when executing using TileDB cloud taskgraphs, of the form: {“cpu”: “6”, “memory”: “12Gi”, “gpu”: 1}. Can only be used in BATCH mode. Cannot be used alongside resource_class.\nNone\n\n\nnum_partitions\nint\nOnly relevant for taskgraph based execution. If provided, we split the query execution in that many partitions.\n-1\n\n\nnum_workers\nint\nOnly relevant for taskgraph based execution. If provided, this is the number of workers to use for the query execution.\n-1\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate\nCreates an empty IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.create(uri, dimensions, vector_type, group_exists=False, config=None, storage_version=STORAGE_VERSION, **kwargs)\nCreates an empty IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\ngroup_exists\nbool\nIf False it creates the TileDB group for the index. If True the method expects the TileDB group to be already created.\nFalse\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use the latest stable storage version.\nSTORAGE_VERSION"
  },
  {
    "objectID": "documentation/reference/ivf_flat_index.html#classes",
    "href": "documentation/reference/ivf_flat_index.html#classes",
    "title": "ivf_flat_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nIVFFlatIndex\nOpens an IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex(self, uri, config=None, timestamp=None, memory_budget=-1, **kwargs)\nOpens an IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nmemory_budget\nint\nMain memory budget, in number of vectors, for query execution. If not provided, all index data are loaded in main memory. Otherwise, no index data are loaded in main memory and this memory budget is applied during queries.\n-1\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries an IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.query_internal(queries, k=10, nprobe=1, nthreads=-1, use_nuv_implementation=False, mode=None, resource_class=None, resources=None, num_partitions=-1, num_workers=-1, **kwargs)\nQueries an IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nnprobe\nint\nNumber of partitions to check per query. Use this parameter to trade-off accuracy for latency and cost.\n1\n\n\nnthreads\nint\nNumber of threads to use for local query execution.\n-1\n\n\nuse_nuv_implementation\nbool\nWhether to use the nuv query implementation. Default: False\nFalse\n\n\nmode\nMode\nIf provided the query will be executed using TileDB cloud taskgraphs. For distributed execution you can use REALTIME or BATCH mode. For local execution you can use LOCAL mode.\nNone\n\n\nresource_class\nOptional[str]\nThe name of the resource class to use (“standard” or “large”). Resource classes define maximum limits for cpu and memory usage. Can only be used in REALTIME or BATCH mode. Cannot be used alongside resources. In REALTIME or BATCH mode if neither resource_class nor resources are provided, we default to the “large” resource class.\nNone\n\n\nresources\nOptional[Mapping[str, Any]]\nA specification for the amount of resources to use when executing using TileDB cloud taskgraphs, of the form: {“cpu”: “6”, “memory”: “12Gi”, “gpu”: 1}. Can only be used in BATCH mode. Cannot be used alongside resource_class.\nNone\n\n\nnum_partitions\nint\nOnly relevant for taskgraph based execution. If provided, we split the query execution in that many partitions.\n-1\n\n\nnum_workers\nint\nOnly relevant for taskgraph based execution. If provided, this is the number of workers to use for the query execution.\n-1"
  },
  {
    "objectID": "documentation/reference/ivf_flat_index.html#functions",
    "href": "documentation/reference/ivf_flat_index.html#functions",
    "title": "ivf_flat_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate\nCreates an empty IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.create(uri, dimensions, vector_type, group_exists=False, config=None, storage_version=STORAGE_VERSION, **kwargs)\nCreates an empty IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\ngroup_exists\nbool\nIf False it creates the TileDB group for the index. If True the method expects the TileDB group to be already created.\nFalse\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use the latest stable storage version.\nSTORAGE_VERSION"
  },
  {
    "objectID": "documentation/index.html",
    "href": "documentation/index.html",
    "title": "TileDB Vector Search",
    "section": "",
    "text": "TileDB Vector Search\nTileDB-Vector-Search is a C++ library and Python API for vector search built on top of the TileDB Storage Engine.\n\n\nQuick Links\n\nBuild Instructions\nDocumentation\nPython API reference\n\n\n\nQuick Installation\nTileDB-Vector-Search is available from PyPI or the tiledb conda channel.\nTo install from PyPI with pip, use:\npip install tiledb-vector-search\nTo install from conda, use conda or mamba:\nconda install -c tiledb -c conda-forge tiledb-vector-search\nmamba install -c tiledb -c conda-forge tiledb-vector-search\n\n\nContributing\nWe welcome contributions. Please see Building for development-build instructions. For large new features, please open an issue to discuss goals and approach in order to ensure a smooth PR integration and review process. All contributions must be licensed under the repository’s MIT License.",
    "crumbs": [
      "Home page",
      "TileDB Vector Search"
    ]
  },
  {
    "objectID": "documentation/Building.html",
    "href": "documentation/Building.html",
    "title": "Building and Running Tests",
    "section": "",
    "text": "TileDB Vector Search can be built from source for either C++ or Python.\n\n\nTo build for C++, run:\ncmake -S ./src -B ./src/build -DCMAKE_BUILD_TYPE=Debug\ncmake --build ./src/build -j3\nThen you can run the tests:\ncmake --build ./src/build --target check\nAlternatively, you can setup CLion, which is the suggested way to develop C++ in this project. To set up CLion:\n\nOpen up CLion to the root directory of this repo.\nGo to File -&gt; Settings -&gt; Build, Execution, Deployment -&gt; CMake.\n\nSet CMake options to G \"Unix Makefiles\" -DCMAKE_IDE=ON -DTileDB_DIR:PATH=/Users/&lt;name&gt;/repo/tileDB/build/dist -DTILEDB_VS_ENABLE_BLAS=on -DTILEDB_VS_PYTHON=off.\n\nNote that DTileDB_DIR will be specific to your TileDB installation. If you have it installed in a standard location, you can omit this option.\n\nSet Build directory to cmake-build-debug/libtiledbvectorsearch.\n\nNext right click on src/CMakeLists.txt and select Load CMake Project.\nAfter that you should see configurations for unit tests and build targets automatically generated by CLion.\n\n\n\n\nBefore building you may want to set up a virtual environment:\nconda create --name TileDB-Vector-Search python=3.9\nconda activate TileDB-Vector-Search\nTo build for Python, run:\npip install .\nYou can run unit tests with pytest. You’ll also need to install the test dependencies:\npip install \".[test]\"\nThen you can run the tests:\ncd apis/python\n# To run all tests.\npytest\n# To run a single test and display standard output and standard error.\npytest test/test_ingestion.py -s\nTo test Demo notebooks:\ncd apis/python\npip install -r test/ipynb/requirements.txt\npytest --nbmake test/ipynb\nCredentials:\n\nSome tests run on TileDB Cloud using your current environment variable TILEDB_REST_TOKEN - you will need a valid API token for the tests to pass. See Create API Tokens for for instructions on getting one.\nFor continuous integration, the token is configured for the unittest user and all tests should pass.\n\n\n\n\nFirst install quarto with their instructions or with Homebrew.\nThen run:\npip install quartodoc\nquartodoc build\nquarto render --fail-if-warnings\nYou can them open up docs/documentation/index.html in a web browser to preview the results.",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/Building.html#c",
    "href": "documentation/Building.html#c",
    "title": "Building and Running Tests",
    "section": "",
    "text": "To build for C++, run:\ncmake -S ./src -B ./src/build -DCMAKE_BUILD_TYPE=Debug\ncmake --build ./src/build -j3\nThen you can run the tests:\ncmake --build ./src/build --target check\nAlternatively, you can setup CLion, which is the suggested way to develop C++ in this project. To set up CLion:\n\nOpen up CLion to the root directory of this repo.\nGo to File -&gt; Settings -&gt; Build, Execution, Deployment -&gt; CMake.\n\nSet CMake options to G \"Unix Makefiles\" -DCMAKE_IDE=ON -DTileDB_DIR:PATH=/Users/&lt;name&gt;/repo/tileDB/build/dist -DTILEDB_VS_ENABLE_BLAS=on -DTILEDB_VS_PYTHON=off.\n\nNote that DTileDB_DIR will be specific to your TileDB installation. If you have it installed in a standard location, you can omit this option.\n\nSet Build directory to cmake-build-debug/libtiledbvectorsearch.\n\nNext right click on src/CMakeLists.txt and select Load CMake Project.\nAfter that you should see configurations for unit tests and build targets automatically generated by CLion.",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/Building.html#python",
    "href": "documentation/Building.html#python",
    "title": "Building and Running Tests",
    "section": "",
    "text": "Before building you may want to set up a virtual environment:\nconda create --name TileDB-Vector-Search python=3.9\nconda activate TileDB-Vector-Search\nTo build for Python, run:\npip install .\nYou can run unit tests with pytest. You’ll also need to install the test dependencies:\npip install \".[test]\"\nThen you can run the tests:\ncd apis/python\n# To run all tests.\npytest\n# To run a single test and display standard output and standard error.\npytest test/test_ingestion.py -s\nTo test Demo notebooks:\ncd apis/python\npip install -r test/ipynb/requirements.txt\npytest --nbmake test/ipynb\nCredentials:\n\nSome tests run on TileDB Cloud using your current environment variable TILEDB_REST_TOKEN - you will need a valid API token for the tests to pass. See Create API Tokens for for instructions on getting one.\nFor continuous integration, the token is configured for the unittest user and all tests should pass.",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/Building.html#quarto",
    "href": "documentation/Building.html#quarto",
    "title": "Building and Running Tests",
    "section": "",
    "text": "First install quarto with their instructions or with Homebrew.\nThen run:\npip install quartodoc\nquartodoc build\nquarto render --fail-if-warnings\nYou can them open up docs/documentation/index.html in a web browser to preview the results.",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/Building.html#linux",
    "href": "documentation/Building.html#linux",
    "title": "Building and Running Tests",
    "section": "Linux",
    "text": "Linux\nThere are several dependencies needed, for Ubuntu you can install via:\napt-get openblas-dev build-essentials cmake3\nTo build the python API after you have the dependencies, use pip:\npip install .",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/Building.html#docker",
    "href": "documentation/Building.html#docker",
    "title": "Building and Running Tests",
    "section": "Docker",
    "text": "Docker\nA docker image is also provided for simplicity:\ndocker build -t tiledb/tiledb-vector-search .\nYou run the example docker image which provides the python package with:\ndocker run --rm tiledb/tiledb-vector-search",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/reference/vamana_index.html",
    "href": "documentation/reference/vamana_index.html",
    "title": "vamana_index",
    "section": "",
    "text": "vector_search.vamana_index\nVamana Index implementation.\nVamana is based on Microsoft’s DiskANN vector search library, as described in these papers:\n  Subramanya, Suhas Jayaram, and Rohan Kadekodi. DiskANN: Fast Accurate Billion-Point Nearest Neighbor Search on a Single Node.\n\n  Singh, Aditi, et al. FreshDiskANN: A Fast and Accurate Graph-Based ANN Index for Streaming Similarity Search. arXiv:2105.09613, arXiv, 20 May 2021, http://arxiv.org/abs/2105.09613.\n\n  Gollapudi, Siddharth, et al. “Filtered-DiskANN: Graph Algorithms for Approximate Nearest Neighbor Search with Filters.” Proceedings of the ACM Web Conference 2023, ACM, 2023, pp. 3406-16, https://doi.org/10.1145/3543507.3583552.\n\n\n\n\n\nName\nDescription\n\n\n\n\nVamanaIndex\nOpens a VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.VamanaIndex(self, uri, config=None, timestamp=None, **kwargs)\nOpens a VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries a VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.VamanaIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.vamana_index.VamanaIndex.query_internal(queries, k=10, opt_l=100, **kwargs)\nQueries a VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nopt_l\nOptional[int]\nHow deep to search. Should be &gt;= k, and if it’s not, we will set it to k.\n100\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate\nCreates an empty VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.create(uri, dimensions, vector_type, config=None, storage_version=STORAGE_VERSION, **kwargs)\nCreates an empty VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use the latest stable storage version.\nSTORAGE_VERSION"
  },
  {
    "objectID": "documentation/reference/vamana_index.html#classes",
    "href": "documentation/reference/vamana_index.html#classes",
    "title": "vamana_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nVamanaIndex\nOpens a VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.VamanaIndex(self, uri, config=None, timestamp=None, **kwargs)\nOpens a VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries a VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.VamanaIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.vamana_index.VamanaIndex.query_internal(queries, k=10, opt_l=100, **kwargs)\nQueries a VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nopt_l\nOptional[int]\nHow deep to search. Should be &gt;= k, and if it’s not, we will set it to k.\n100"
  },
  {
    "objectID": "documentation/reference/vamana_index.html#functions",
    "href": "documentation/reference/vamana_index.html#functions",
    "title": "vamana_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate\nCreates an empty VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.create(uri, dimensions, vector_type, config=None, storage_version=STORAGE_VERSION, **kwargs)\nCreates an empty VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use the latest stable storage version.\nSTORAGE_VERSION"
  },
  {
    "objectID": "documentation/reference/index.Index.html",
    "href": "documentation/reference/index.Index.html",
    "title": "index.Index",
    "section": "",
    "text": "vector_search.index.Index(self, uri, config=None, timestamp=None)\nAbstract Vector Index class.\nAll Vector Index algorithm implementations are instantiations of this class. Apart from the abstract method interfaces, Index provides implementations for common tasks i.e. supporting updates, time-traveling and metadata management.\nOpens an Index reading metadata and applying time-traveling options.\nDo not use this directly but rather instantiate the concrete Index classes.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nclear_history\nClears the history maintained in a Vector Index based on its URI.\n\n\nconsolidate_updates\nConsolidates updates by merging updates form the updates table into the base index.\n\n\ndelete\nDeletes a vector by its external_id.\n\n\ndelete_batch\nDeletes vectors by their external_ids.\n\n\ndelete_index\nDeletes an index from storage based on its URI.\n\n\nget_dimensions\nAbstract method implemented by all Vector Index implementations.\n\n\nquery\nQueries an index with a set of query vectors, retrieving the k most similar vectors for each query.\n\n\nquery_internal\nAbstract method implemented by all Vector Index implementations.\n\n\nupdate\nUpdates a vector by its external_id.\n\n\nupdate_batch\nUpdates a set vectors by their external_ids.\n\n\n\n\n\nvector_search.index.Index.clear_history(uri, timestamp, config=None)\nClears the history maintained in a Vector Index based on its URI.\nThis clears the update history before the provided timestamp.\nUse this in collaboration with consolidate_updates to periodically cleanup update history.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ntimestamp\nint\nClears update history before this timestamp.\nrequired\n\n\n\n\n\n\n\nvector_search.index.Index.consolidate_updates(retrain_index=False, **kwargs)\nConsolidates updates by merging updates form the updates table into the base index.\nThe consolidation process is used to avoid query latency degradation as more updates are added to the index. It triggers a base index re-indexing, merging the non-consolidated updates and the rest of the base vectors.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nretrain_index\nbool\nIf true, retrain the index. If false, reuse data from the previous index. For IVF_FLAT retraining means we will recompute the centroids - when doing so you can pass any ingest() arguments used to configure computing centroids and we will use them when recomputing the centroids. Otherwise, if false, we will reuse the centroids from the previous index.\nFalse\n\n\n**kwargs\n\nExtra kwargs passed here are passed to ingest function.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.delete(external_id, timestamp=None)\nDeletes a vector by its external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nexternal_id\nnp.uint64\nExternal ID of the vector to be deleted.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the deletes to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.delete_batch(external_ids, timestamp=None)\nDeletes vectors by their external_ids.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nexternal_ids\nnp.array\nExternal IDs of the vectors to be deleted.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the deletes to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.delete_index(uri, config=None)\nDeletes an index from storage based on its URI.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.get_dimensions()\nAbstract method implemented by all Vector Index implementations.\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.index.Index.query(queries, k, **kwargs)\nQueries an index with a set of query vectors, retrieving the k most similar vectors for each query.\nThis provides an algorithm-agnostic implementation for updates:\n\nQueries the non-consolidated updates table.\nCalls the algorithm specific implementation of query_internal to query the base data.\nMerges the results applying the updated data.\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\nrequired\n\n\n**kwargs\n\nExtra kwargs passed here are passed to the query_internal implementation of the concrete index class.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.query_internal(queries, k, **kwargs)\nAbstract method implemented by all Vector Index implementations.\nQueries the base index with a set of query vectors, retrieving the k most similar vectors for each query.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\nrequired\n\n\n**kwargs\n\nExtra kwargs passed here for each algorithm implementation.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.update(vector, external_id, timestamp=None)\nUpdates a vector by its external_id.\nThis can be used to add new vectors or update an existing vector with the same external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvector\nnp.array\nVector data to be updated.\nrequired\n\n\nexternal_id\nnp.uint64\nExternal ID of the vector.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the update to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.update_batch(vectors, external_ids, timestamp=None)\nUpdates a set vectors by their external_ids.\nThis can be used to add new vectors or update existing vectors with the same external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvectors\nnp.ndarray\n2D array containing the vectors to be updated.\nrequired\n\n\nexternal_ids\nnp.array\nExternal IDs of the vectors.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the updates to take place at.\nNone"
  },
  {
    "objectID": "documentation/reference/index.Index.html#parameters",
    "href": "documentation/reference/index.Index.html#parameters",
    "title": "index.Index",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone"
  },
  {
    "objectID": "documentation/reference/index.Index.html#methods",
    "href": "documentation/reference/index.Index.html#methods",
    "title": "index.Index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nclear_history\nClears the history maintained in a Vector Index based on its URI.\n\n\nconsolidate_updates\nConsolidates updates by merging updates form the updates table into the base index.\n\n\ndelete\nDeletes a vector by its external_id.\n\n\ndelete_batch\nDeletes vectors by their external_ids.\n\n\ndelete_index\nDeletes an index from storage based on its URI.\n\n\nget_dimensions\nAbstract method implemented by all Vector Index implementations.\n\n\nquery\nQueries an index with a set of query vectors, retrieving the k most similar vectors for each query.\n\n\nquery_internal\nAbstract method implemented by all Vector Index implementations.\n\n\nupdate\nUpdates a vector by its external_id.\n\n\nupdate_batch\nUpdates a set vectors by their external_ids.\n\n\n\n\n\nvector_search.index.Index.clear_history(uri, timestamp, config=None)\nClears the history maintained in a Vector Index based on its URI.\nThis clears the update history before the provided timestamp.\nUse this in collaboration with consolidate_updates to periodically cleanup update history.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ntimestamp\nint\nClears update history before this timestamp.\nrequired\n\n\n\n\n\n\n\nvector_search.index.Index.consolidate_updates(retrain_index=False, **kwargs)\nConsolidates updates by merging updates form the updates table into the base index.\nThe consolidation process is used to avoid query latency degradation as more updates are added to the index. It triggers a base index re-indexing, merging the non-consolidated updates and the rest of the base vectors.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nretrain_index\nbool\nIf true, retrain the index. If false, reuse data from the previous index. For IVF_FLAT retraining means we will recompute the centroids - when doing so you can pass any ingest() arguments used to configure computing centroids and we will use them when recomputing the centroids. Otherwise, if false, we will reuse the centroids from the previous index.\nFalse\n\n\n**kwargs\n\nExtra kwargs passed here are passed to ingest function.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.delete(external_id, timestamp=None)\nDeletes a vector by its external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nexternal_id\nnp.uint64\nExternal ID of the vector to be deleted.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the deletes to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.delete_batch(external_ids, timestamp=None)\nDeletes vectors by their external_ids.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nexternal_ids\nnp.array\nExternal IDs of the vectors to be deleted.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the deletes to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.delete_index(uri, config=None)\nDeletes an index from storage based on its URI.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.get_dimensions()\nAbstract method implemented by all Vector Index implementations.\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.index.Index.query(queries, k, **kwargs)\nQueries an index with a set of query vectors, retrieving the k most similar vectors for each query.\nThis provides an algorithm-agnostic implementation for updates:\n\nQueries the non-consolidated updates table.\nCalls the algorithm specific implementation of query_internal to query the base data.\nMerges the results applying the updated data.\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\nrequired\n\n\n**kwargs\n\nExtra kwargs passed here are passed to the query_internal implementation of the concrete index class.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.query_internal(queries, k, **kwargs)\nAbstract method implemented by all Vector Index implementations.\nQueries the base index with a set of query vectors, retrieving the k most similar vectors for each query.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\nrequired\n\n\n**kwargs\n\nExtra kwargs passed here for each algorithm implementation.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.update(vector, external_id, timestamp=None)\nUpdates a vector by its external_id.\nThis can be used to add new vectors or update an existing vector with the same external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvector\nnp.array\nVector data to be updated.\nrequired\n\n\nexternal_id\nnp.uint64\nExternal ID of the vector.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the update to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.update_batch(vectors, external_ids, timestamp=None)\nUpdates a set vectors by their external_ids.\nThis can be used to add new vectors or update existing vectors with the same external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvectors\nnp.ndarray\n2D array containing the vectors to be updated.\nrequired\n\n\nexternal_ids\nnp.array\nExternal IDs of the vectors.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the updates to take place at.\nNone"
  },
  {
    "objectID": "documentation/reference/flat_index.html",
    "href": "documentation/reference/flat_index.html",
    "title": "flat_index",
    "section": "",
    "text": "vector_search.flat_index\nFlatIndex implementation.\nStores all vectors in a 2D TileDB array performing exhaustive similarity search between the query vectors and all the dataset vectors.\n\n\n\n\n\nName\nDescription\n\n\n\n\nFlatIndex\nOpens a FlatIndex loading all dataset vectors in main memory.\n\n\n\n\n\nvector_search.flat_index.FlatIndex(self, uri, config=None, timestamp=None, **kwargs)\nOpens a FlatIndex loading all dataset vectors in main memory.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries a FlatIndex using the vectors already loaded in main memory.\n\n\n\n\n\nvector_search.flat_index.FlatIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.flat_index.FlatIndex.query_internal(queries, k=10, nthreads=8, **kwargs)\nQueries a FlatIndex using the vectors already loaded in main memory.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nnthreads\nint\nNumber of threads to use for query execution.\n8\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate\nCreates an empty FlatIndex.\n\n\n\n\n\nvector_search.flat_index.create(uri, dimensions, vector_type, group_exists=False, config=None, storage_version=STORAGE_VERSION, **kwargs)\nCreates an empty FlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\ngroup_exists\nbool\nIf False it creates the TileDB group for the index. If True the method expects the TileDB group to be already created.\nFalse\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use hte latest stable storage version.\nSTORAGE_VERSION"
  },
  {
    "objectID": "documentation/reference/flat_index.html#classes",
    "href": "documentation/reference/flat_index.html#classes",
    "title": "flat_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nFlatIndex\nOpens a FlatIndex loading all dataset vectors in main memory.\n\n\n\n\n\nvector_search.flat_index.FlatIndex(self, uri, config=None, timestamp=None, **kwargs)\nOpens a FlatIndex loading all dataset vectors in main memory.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries a FlatIndex using the vectors already loaded in main memory.\n\n\n\n\n\nvector_search.flat_index.FlatIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.flat_index.FlatIndex.query_internal(queries, k=10, nthreads=8, **kwargs)\nQueries a FlatIndex using the vectors already loaded in main memory.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nnthreads\nint\nNumber of threads to use for query execution.\n8"
  },
  {
    "objectID": "documentation/reference/flat_index.html#functions",
    "href": "documentation/reference/flat_index.html#functions",
    "title": "flat_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate\nCreates an empty FlatIndex.\n\n\n\n\n\nvector_search.flat_index.create(uri, dimensions, vector_type, group_exists=False, config=None, storage_version=STORAGE_VERSION, **kwargs)\nCreates an empty FlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\ngroup_exists\nbool\nIf False it creates the TileDB group for the index. If True the method expects the TileDB group to be already created.\nFalse\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use hte latest stable storage version.\nSTORAGE_VERSION"
  }
]