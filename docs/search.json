[
  {
    "objectID": "documentation/Benchmarks.html",
    "href": "documentation/Benchmarks.html",
    "title": "Benchmarks",
    "section": "",
    "text": "We have implemented a big-ann-benchmarks interface for TileDB-Vector-Search, which is available in the tiledb branch of our fork:\n\nhttps://github.com/TileDB-Inc/big-ann-benchmarks/tree/tiledb. This interface implements two new algorithms: tiledb-flat and tiledb-ivf-flat, which are usable within the framework’s runner.\n\n\n\n\nBuild the Dockerfile at the root of this repository:\n\ncd tiledb-vector-search\ndocker build -f Dockerfile . -t tiledb_vs\n\nBuild the TileDB docker image in the big-ann fork (requires image from step 1):\n\ngit clone https://github.com/TileDB-Inc/big-ann-benchmarks/tree/tiledb\ncd big-ann-benchmarks\ndocker build -f install/Dockerfile.tiledb . -t billion-scale-benchmark-tiledb\n\n\n\n\nCreate a local dataset.\nnote: the create_dataset.py command will download remote files the first time it runs, some of which can total &gt;100GB). Use --skip-data to avoid downloading the large base set.\nThis command will download 7.7MB of data:\n\npython create_dataset.py --dataset bigann-10M --skip-data\n\nRun the benchmarks, choosing either tiledb-flat or tiledb-ivf-flat:\n\npython run.py --dataset bigann-10M --algorithm tiledb-flat",
    "crumbs": [
      "Home page",
      "Benchmarks"
    ]
  },
  {
    "objectID": "documentation/Benchmarks.html#building",
    "href": "documentation/Benchmarks.html#building",
    "title": "Benchmarks",
    "section": "",
    "text": "Build the Dockerfile at the root of this repository:\n\ncd tiledb-vector-search\ndocker build -f Dockerfile . -t tiledb_vs\n\nBuild the TileDB docker image in the big-ann fork (requires image from step 1):\n\ngit clone https://github.com/TileDB-Inc/big-ann-benchmarks/tree/tiledb\ncd big-ann-benchmarks\ndocker build -f install/Dockerfile.tiledb . -t billion-scale-benchmark-tiledb",
    "crumbs": [
      "Home page",
      "Benchmarks"
    ]
  },
  {
    "objectID": "documentation/Benchmarks.html#running-benchmarks",
    "href": "documentation/Benchmarks.html#running-benchmarks",
    "title": "Benchmarks",
    "section": "",
    "text": "Create a local dataset.\nnote: the create_dataset.py command will download remote files the first time it runs, some of which can total &gt;100GB). Use --skip-data to avoid downloading the large base set.\nThis command will download 7.7MB of data:\n\npython create_dataset.py --dataset bigann-10M --skip-data\n\nRun the benchmarks, choosing either tiledb-flat or tiledb-ivf-flat:\n\npython run.py --dataset bigann-10M --algorithm tiledb-flat",
    "crumbs": [
      "Home page",
      "Benchmarks"
    ]
  },
  {
    "objectID": "documentation/storage-format-spec.html",
    "href": "documentation/storage-format-spec.html",
    "title": "Storage Format Spec",
    "section": "",
    "text": "The underlying storage model used for indexing vectors in TileDB-Vector-Search is heavily dependent on the indexing algorithm used. However, there are also high level structures that are used across algorithms.",
    "crumbs": [
      "Home page",
      "Storage Format Spec"
    ]
  },
  {
    "objectID": "documentation/storage-format-spec.html#cross-algorithm-storage-format",
    "href": "documentation/storage-format-spec.html#cross-algorithm-storage-format",
    "title": "Storage Format Spec",
    "section": "Cross algorithm storage format",
    "text": "Cross algorithm storage format\nAll data and metadata required for a TileDB-Vector-Search index are stored inside a TileDB group (index_uri). All the listed, named arrays below are stored under this URI.\n\nIndex metadata\nMetadata values required for configuring the different properties of an index are stored in the index_uri group metadata. There are some metadata values that are required for all algorithm implementations as well as per-algorithm specific metadata values. Below is a table of all the metadata values that are recorded for all algorithms.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ndataset_type\nThe asset type for disambiguation in TileDB cloud. Value: vector_search\n\n\nindex_type\nThe index algorithm used for this index. Can be one of the following values: FLAT, IVF_FLAT, VAMANA, IVF_PQ\n\n\nstorage_version\nThe storage version used for the index. The storage version is used to make sure that indexing algorithms can update their storage logic without affecting previously created indexes and maintaining backwards compatibility.\n\n\ndtype\nThe data type of the vector values.\n\n\ningestion_timestamps\nAn ordered list of timestamps that correspond to different calls of ingestion and update consolidation through the lifetime of the index.\n\n\nbase_sizes\nAn ordered list of number of vectors in the base index at the different ingestion timestamps.\n\n\nhas_updates\nBoolean value denoting if there are updates recorded in the updates array.\n\n\n\n\n\nObject metadata\nThis is a 1D sparse array with external_id as dimension and attributes the user defined metadata attributes for the respective vectors.\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nSparse\n\n\nRank\n1D\n\n\nCell order\nRow-major\n\n\nTile order\nRow-major\n\n\n\n\n\nDimensions\n\n\n\nDimension Name\nTileDB Datatype\n\n\n\n\nexternal_id\nuint64_t\n\n\n\n\n\n\nUpdates\nTileDB-Vector-Search offers support for updates for all different index algorithms by recording updates outside the main indexing storage structure and periodically consolidating them. This implementation is using the updates array, a sparse 1D array with dimension the external_ids of the vectors and 1 variable length attribute encoding the vector itself or an empty value if the vector is deleted.\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nSparse\n\n\nRank\n1D\n\n\nCell order\nRow-major\n\n\nTile order\nRow-major\n\n\n\n\n\nDimensions\n\n\n\nDimension Name\nTileDB Datatype\n\n\n\n\nexternal_id\nuint64_t\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvector\nvariable dtype\nContains the vector value. Empty values correspond to vector deletions.",
    "crumbs": [
      "Home page",
      "Storage Format Spec"
    ]
  },
  {
    "objectID": "documentation/storage-format-spec.html#algorithm-specific-storage-format",
    "href": "documentation/storage-format-spec.html#algorithm-specific-storage-format",
    "title": "Storage Format Spec",
    "section": "Algorithm specific storage format",
    "text": "Algorithm specific storage format\n\nFLAT\n\nshuffled_vectors\nThis is a 2D dense array that holds all the vectors with no specific ordering.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n2D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, dimensions]\nCorresponds to the vector dimensions.\n\n\ncols\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in the set of vectors.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\ndtype\nContains the vector value at the specific dimension.\n\n\n\n\n\nshuffled_ids\nThis is a 1D dense array that maps vector positions in the shuffled_vectors array to external_ids of each vector.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n1D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in shuffled_vectors.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\nuint64_t\nContains the vector’s external_id.\n\n\n\n\n\n\nIVF_FLAT\n\nMetadata\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\npartition_history\nAn ordered list of the number of partitions used at different ingestion timestamps.\n\n\n\n\n\npartition_centroids\nThis is a 2D dense array storing the k-means centroids for the different vector partitions.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n2D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, dimensions]\nCorresponds to the centroid dimensions.\n\n\ncols\nint32_t\n[0, MAX_INT32]\nCorresponds to the centroid id.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\ncentroids\ndtype\nContains the centroid value at the specific dimension.\n\n\n\n\n\npartition_indexes\nThis is a 1D dense array recording the start-end index of each partition of vectors in the shuffled_vectors array.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n1D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, MAX_INT32]\nCorresponds to the partition id.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\nuint64_t\nContains to the position of the partition split in the shuffled_vectors array.\n\n\n\n\n\nshuffled_vectors\nThis is a 2D dense array that holds all the vectors. Each vector partition is stored in a consecutive index range of this array.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n2D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, dimensions]\nCorresponds to the vector dimensions.\n\n\ncols\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in the set of vectors.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\ndtype\nContains the vector value at the specific dimension.\n\n\n\n\n\nshuffled_ids\nThis is a 1D dense array that maps vector indices in the shuffled_vectors array to external_ids of each vector.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n1D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in shuffled_vectors.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\nuint64_t\nContains the vector external_id.\n\n\n\n\n\n\nVAMANA\n\nMetadata\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nl_build\nThe l_build parameter used when constructing the graph.\n\n\nr_max_degree\nThe r_max_degree parameter used when constructing the graph.\n\n\n\n\n\nshuffled_vectors\nThis is a 2D dense array that holds all the vectors. Each vector partition is stored in a consecutive index range of this array.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n2D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, dimensions]\nCorresponds to the vector dimensions.\n\n\ncols\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in the set of vectors.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\ndtype\nContains the vector value at the specific dimension.\n\n\n\n\n\nshuffled_ids\nThis is a 1D dense array that maps vector indices in the shuffled_vectors array to external_ids of each vector.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n1D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in shuffled_vectors.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\nuint64_t\nContains the vector external_id.\n\n\n\n\n\nadjacency_row_index_array_name\nThis is a 1D dense array that holds the edges for each node in the compressed sparse row (CSR) format graph. Each value indicates where the neighbors (edges) for each successive node start in adjacency_ids and adjacency_scores. For example, we might have [0, 2, 8, 13] which indicates that the neighbors for node 0 start at index 0, the neighbors for node 1 start at index 2, and the neighbors for node 2 start at index 8. The final value is the end of the array, so the neighbors for node 2 end at index 13. With that information, we can look in adjacency_ids to determine the destination node. The source node can be inferred by the index of the Adjacency Row Indices array. Once you know the source or destination node index, you can look at that index in shuffled_vectors or shuffled_ids to get the vector or external ID for that node.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n1D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in shuffled_vectors and shuffled_ids.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\nuint64_t\nContains the start and stop indexes in adjacency_ids and adjacency_scores for the node.\n\n\n\n\n\nadjacency_ids\nThis is a 1D dense array that holds the indexes of the destination vector for each edge in the compressed sparse row (CSR) format graph. Each value is an index into the shuffled_vectors and shuffled_ids arrays. This only holds the destination nodes of the graph, the source node is in adjacency_row_index_array_name, which itself points to adjacency_ids.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n1D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in shuffled_vectors and shuffled_ids.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\nuint64_t\nContains the index of the destination vector for this edge in the graph.\n\n\n\n\n\nadjacency_scores\nThis is a 1D dense array that holds the distance of the edge in adjacency_ids in the compressed sparse row (CSR) format graph. This follows the same pattern as adjacency_ids, but holds the edge distance instead of the destination node.\n\n\nBasic schema parameters\n\n\n\nParameter\nValue\n\n\n\n\nArray type\nDense\n\n\nRank\n1D\n\n\nCell order\nCol-major\n\n\nTile order\nCol-major\n\n\n\n\n\nDimensions\n\n\n\n\n\n\n\n\n\nDimension Name\nTileDB Datatype\nDomain\nDescription\n\n\n\n\nrows\nint32_t\n[0, MAX_INT32]\nCorresponds to the vector position in adjacency_ids.\n\n\n\n\n\nAttributes\n\n\n\n\n\n\n\n\nAttribute Name\nTileDB Datatype\nDescription\n\n\n\n\nvalues\nfloat\nContains the distance between neighbors in the graph.",
    "crumbs": [
      "Home page",
      "Storage Format Spec"
    ]
  },
  {
    "objectID": "documentation/reference/index.html",
    "href": "documentation/reference/index.html",
    "title": "Python",
    "section": "",
    "text": "index.Index\nAbstract Vector Index class.\n\n\nflat_index\nFlatIndex implementation.\n\n\nivf_flat_index\nIVFFlat Index implementation.\n\n\nvamana_index\nVamana Index implementation.\n\n\ningestion\nVector Search ingestion Utilities",
    "crumbs": [
      "Home page",
      "API Reference",
      "Python"
    ]
  },
  {
    "objectID": "documentation/reference/index.html#tiledb.vector_search",
    "href": "documentation/reference/index.html#tiledb.vector_search",
    "title": "Python",
    "section": "",
    "text": "index.Index\nAbstract Vector Index class.\n\n\nflat_index\nFlatIndex implementation.\n\n\nivf_flat_index\nIVFFlat Index implementation.\n\n\nvamana_index\nVamana Index implementation.\n\n\ningestion\nVector Search ingestion Utilities",
    "crumbs": [
      "Home page",
      "API Reference",
      "Python"
    ]
  },
  {
    "objectID": "documentation/reference/index.Index.html",
    "href": "documentation/reference/index.Index.html",
    "title": "index.Index",
    "section": "",
    "text": "vector_search.index.Index(self, uri, open_for_remote_query_execution, config=None, timestamp=None)\nAbstract Vector Index class.\nAll Vector Index algorithm implementations are instantiations of this class. Apart from the abstract method interfaces, Index provides implementations for common tasks i.e. supporting updates, time-traveling and metadata management.\nOpens an Index reading metadata and applying time-traveling options.\nDo not use this directly but rather instantiate the concrete Index classes.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nclear_history\nClears the history maintained in a Vector Index based on its URI.\n\n\nconsolidate_updates\nConsolidates updates by merging updates form the updates table into the base index.\n\n\ndelete\nDeletes a vector by its external_id.\n\n\ndelete_batch\nDeletes vectors by their external_ids.\n\n\ndelete_index\nDeletes an index from storage based on its URI.\n\n\nget_dimensions\nAbstract method implemented by all Vector Index implementations.\n\n\nquery\nQueries an index with a set of query vectors, retrieving the k most similar vectors for each query.\n\n\nquery_internal\nAbstract method implemented by all Vector Index implementations.\n\n\nupdate\nUpdates a vector by its external_id.\n\n\nupdate_batch\nUpdates a set vectors by their external_ids.\n\n\n\n\n\nvector_search.index.Index.clear_history(uri, timestamp, config=None)\nClears the history maintained in a Vector Index based on its URI.\nThis clears the update history before the provided timestamp.\nUse this in collaboration with consolidate_updates to periodically cleanup update history.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ntimestamp\nint\nClears update history before this timestamp.\nrequired\n\n\n\n\n\n\n\nvector_search.index.Index.consolidate_updates(retrain_index=False, **kwargs)\nConsolidates updates by merging updates form the updates table into the base index.\nThe consolidation process is used to avoid query latency degradation as more updates are added to the index. It triggers a base index re-indexing, merging the non-consolidated updates and the rest of the base vectors.\nTODO(sc-51202): This throws with a unintuitive error message if update()/delete()/etc. has not been called.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nretrain_index\nbool\nIf true, retrain the index. If false, reuse data from the previous index. For IVF_FLAT retraining means we will recompute the centroids - when doing so you can pass any ingest() arguments used to configure computing centroids and we will use them when recomputing the centroids. Otherwise, if false, we will reuse the centroids from the previous index.\nFalse\n\n\n**kwargs\n\nExtra kwargs passed here are passed to ingest function.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.delete(external_id, timestamp=None)\nDeletes a vector by its external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nexternal_id\nnp.uint64\nExternal ID of the vector to be deleted.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the deletes to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.delete_batch(external_ids, timestamp=None)\nDeletes vectors by their external_ids.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nexternal_ids\nnp.array\nExternal IDs of the vectors to be deleted.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the deletes to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.delete_index(uri, config=None)\nDeletes an index from storage based on its URI.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.get_dimensions()\nAbstract method implemented by all Vector Index implementations.\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.index.Index.query(queries, k, driver_mode=None, driver_resources=None, driver_access_credentials_name=None, **kwargs)\nQueries an index with a set of query vectors, retrieving the k most similar vectors for each query.\nThis provides an algorithm-agnostic implementation for updates:\n\nQueries the non-consolidated updates table.\nCalls the algorithm specific implementation of query_internal to query the base data.\nMerges the results applying the updated data.\n\nYou can control where the query is executed by setting the driver_mode parameter: - With driver_mode = None, the driver logic for the query will be executed locally. - If driver_mode is not None, we will use a TileDB cloud taskgraph to re-open the index and run the query. With both options, certain implementations, i.e. IVF Flat, may let you create further TileDB taskgraphs as defined in the implementation specific query_internal methods.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\nrequired\n\n\ndriver_mode\nOptional[Mode]\nIf not None, the query will be executed in a TileDB cloud taskgraph using the driver mode specified.\nNone\n\n\ndriver_resources\nOptional[str]\nIf driver_mode was not None, the resources to use for the driver execution.\nNone\n\n\ndriver_access_credentials_name\nOptional[str]\nIf driver_mode was not None, the access credentials name to use for the driver execution.\nNone\n\n\n**kwargs\n\nExtra kwargs passed here are passed to the query_internal implementation of the concrete index class.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.query_internal(queries, k, **kwargs)\nAbstract method implemented by all Vector Index implementations.\nQueries the base index with a set of query vectors, retrieving the k most similar vectors for each query.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\nrequired\n\n\n**kwargs\n\nExtra kwargs passed here for each algorithm implementation.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.update(vector, external_id, timestamp=None)\nUpdates a vector by its external_id.\nThis can be used to add new vectors or update an existing vector with the same external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvector\nnp.array\nVector data to be updated.\nrequired\n\n\nexternal_id\nnp.uint64\nExternal ID of the vector.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the update to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.update_batch(vectors, external_ids, timestamp=None)\nUpdates a set vectors by their external_ids.\nThis can be used to add new vectors or update existing vectors with the same external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvectors\nnp.ndarray\n2D array containing the vectors to be updated.\nrequired\n\n\nexternal_ids\nnp.array\nExternal IDs of the vectors.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the updates to take place at.\nNone"
  },
  {
    "objectID": "documentation/reference/index.Index.html#parameters",
    "href": "documentation/reference/index.Index.html#parameters",
    "title": "index.Index",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nrequired"
  },
  {
    "objectID": "documentation/reference/index.Index.html#methods",
    "href": "documentation/reference/index.Index.html#methods",
    "title": "index.Index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nclear_history\nClears the history maintained in a Vector Index based on its URI.\n\n\nconsolidate_updates\nConsolidates updates by merging updates form the updates table into the base index.\n\n\ndelete\nDeletes a vector by its external_id.\n\n\ndelete_batch\nDeletes vectors by their external_ids.\n\n\ndelete_index\nDeletes an index from storage based on its URI.\n\n\nget_dimensions\nAbstract method implemented by all Vector Index implementations.\n\n\nquery\nQueries an index with a set of query vectors, retrieving the k most similar vectors for each query.\n\n\nquery_internal\nAbstract method implemented by all Vector Index implementations.\n\n\nupdate\nUpdates a vector by its external_id.\n\n\nupdate_batch\nUpdates a set vectors by their external_ids.\n\n\n\n\n\nvector_search.index.Index.clear_history(uri, timestamp, config=None)\nClears the history maintained in a Vector Index based on its URI.\nThis clears the update history before the provided timestamp.\nUse this in collaboration with consolidate_updates to periodically cleanup update history.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ntimestamp\nint\nClears update history before this timestamp.\nrequired\n\n\n\n\n\n\n\nvector_search.index.Index.consolidate_updates(retrain_index=False, **kwargs)\nConsolidates updates by merging updates form the updates table into the base index.\nThe consolidation process is used to avoid query latency degradation as more updates are added to the index. It triggers a base index re-indexing, merging the non-consolidated updates and the rest of the base vectors.\nTODO(sc-51202): This throws with a unintuitive error message if update()/delete()/etc. has not been called.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nretrain_index\nbool\nIf true, retrain the index. If false, reuse data from the previous index. For IVF_FLAT retraining means we will recompute the centroids - when doing so you can pass any ingest() arguments used to configure computing centroids and we will use them when recomputing the centroids. Otherwise, if false, we will reuse the centroids from the previous index.\nFalse\n\n\n**kwargs\n\nExtra kwargs passed here are passed to ingest function.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.delete(external_id, timestamp=None)\nDeletes a vector by its external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nexternal_id\nnp.uint64\nExternal ID of the vector to be deleted.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the deletes to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.delete_batch(external_ids, timestamp=None)\nDeletes vectors by their external_ids.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nexternal_ids\nnp.array\nExternal IDs of the vectors to be deleted.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the deletes to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.delete_index(uri, config=None)\nDeletes an index from storage based on its URI.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.get_dimensions()\nAbstract method implemented by all Vector Index implementations.\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.index.Index.query(queries, k, driver_mode=None, driver_resources=None, driver_access_credentials_name=None, **kwargs)\nQueries an index with a set of query vectors, retrieving the k most similar vectors for each query.\nThis provides an algorithm-agnostic implementation for updates:\n\nQueries the non-consolidated updates table.\nCalls the algorithm specific implementation of query_internal to query the base data.\nMerges the results applying the updated data.\n\nYou can control where the query is executed by setting the driver_mode parameter: - With driver_mode = None, the driver logic for the query will be executed locally. - If driver_mode is not None, we will use a TileDB cloud taskgraph to re-open the index and run the query. With both options, certain implementations, i.e. IVF Flat, may let you create further TileDB taskgraphs as defined in the implementation specific query_internal methods.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\nrequired\n\n\ndriver_mode\nOptional[Mode]\nIf not None, the query will be executed in a TileDB cloud taskgraph using the driver mode specified.\nNone\n\n\ndriver_resources\nOptional[str]\nIf driver_mode was not None, the resources to use for the driver execution.\nNone\n\n\ndriver_access_credentials_name\nOptional[str]\nIf driver_mode was not None, the access credentials name to use for the driver execution.\nNone\n\n\n**kwargs\n\nExtra kwargs passed here are passed to the query_internal implementation of the concrete index class.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.query_internal(queries, k, **kwargs)\nAbstract method implemented by all Vector Index implementations.\nQueries the base index with a set of query vectors, retrieving the k most similar vectors for each query.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\nrequired\n\n\n**kwargs\n\nExtra kwargs passed here for each algorithm implementation.\n{}\n\n\n\n\n\n\n\nvector_search.index.Index.update(vector, external_id, timestamp=None)\nUpdates a vector by its external_id.\nThis can be used to add new vectors or update an existing vector with the same external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvector\nnp.array\nVector data to be updated.\nrequired\n\n\nexternal_id\nnp.uint64\nExternal ID of the vector.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the update to take place at.\nNone\n\n\n\n\n\n\n\nvector_search.index.Index.update_batch(vectors, external_ids, timestamp=None)\nUpdates a set vectors by their external_ids.\nThis can be used to add new vectors or update existing vectors with the same external_id.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvectors\nnp.ndarray\n2D array containing the vectors to be updated.\nrequired\n\n\nexternal_ids\nnp.array\nExternal IDs of the vectors.\nrequired\n\n\ntimestamp\nint\nTimestamp to use for the updates to take place at.\nNone"
  },
  {
    "objectID": "documentation/reference/ingestion.html",
    "href": "documentation/reference/ingestion.html",
    "title": "ingestion",
    "section": "",
    "text": "vector_search.ingestion\nVector Search ingestion Utilities\nThis contains the ingestion implementation for different TileDB Vector Search algorithms.\nIt enables:\n\nLocal ingestion:\n\nMulti-threaded execution that can leverage all the available local computing resources.\n\nDistributed ingestion:\n\nDistributed ingestion execution with multiple workers in TileDB Cloud. This can be used to ingest large datasets and speedup ingestion latency.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ningest\nIngest vectors into TileDB.\n\n\n\n\n\nvector_search.ingestion.ingest(index_type, index_uri, *, input_vectors=None, source_uri=None, source_type=None, external_ids=None, external_ids_uri='', external_ids_type=None, updates_uri=None, index_timestamp=None, config=None, namespace=None, size=-1, partitions=-1, num_subspaces=-1, l_build=-1, r_max_degree=-1, training_sampling_policy=TrainingSamplingPolicy.FIRST_N, copy_centroids_uri=None, training_sample_size=-1, training_input_vectors=None, training_source_uri=None, training_source_type=None, workers=-1, input_vectors_per_work_item=-1, max_tasks_per_stage=-1, input_vectors_per_work_item_during_sampling=-1, max_sampling_tasks=-1, storage_version=STORAGE_VERSION, verbose=False, trace_id=None, use_sklearn=True, mode=Mode.LOCAL, acn=None, ingest_resources=None, consolidate_partition_resources=None, copy_centroids_resources=None, random_sample_resources=None, kmeans_resources=None, compute_new_centroids_resources=None, assign_points_and_partial_new_centroids_resources=None, write_centroids_resources=None, partial_index_resources=None, distance_metric=vspy.DistanceMetric.L2, normalized=False, **kwargs)\nIngest vectors into TileDB.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nindex_type\nstr\nType of vector index (FLAT, IVF_FLAT, IVF_PQ, VAMANA).\nrequired\n\n\nindex_uri\nstr\nVector index URI (stored as TileDB group).\nrequired\n\n\ninput_vectors\nOptional[np.ndarray]\nInput vectors, if this is provided it takes precedence over source_uri and source_type.\nNone\n\n\nsource_uri\nOptional[str]\nVectors source URI.\nNone\n\n\nsource_type\nOptional[str]\nType of the source vectors. If left empty it is auto-detected.\nNone\n\n\nexternal_ids\nOptional[np.array]\nInput vector external_ids, if this is provided it takes precedence over external_ids_uri and external_ids_type.\nNone\n\n\nexternal_ids_uri\nOptional[str]\nSource URI for external_ids.\n''\n\n\nexternal_ids_type\nOptional[str]\nFile type of external_ids_uri. If left empty it is auto-detected.\nNone\n\n\nupdates_uri\nOptional[str]\nUpdates array URI. Used for consolidation of updates.\nNone\n\n\nindex_timestamp\nOptional[int]\nTimestamp to use for writing and reading data. By default it uses the current unix ms timestamp.\nNone\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nnamespace\nOptional[str]\nTileDB-Cloud namespace to use for Cloud execution.\nNone\n\n\nsize\nint\nNumber of input vectors, if not provided use the full size of the input dataset. If provided, we filter the first vectors from the input source.\n-1\n\n\npartitions\nint\nFor IVF_FLAT and IVF_PQ indexes, the number of partitions to generate from the data during k-means clustering. If not provided, is auto-configured based on the dataset size.\n-1\n\n\nnum_subspaces\nint\nFor IVF_PQ encoded indexes, the number of subspaces to use in the PQ encoding. We will divide the dimensions into num_subspaces parts, and PQ encode each part separately. This means dimensions must be divisible by num_subspaces.\n-1\n\n\nl_build\nint\nFor Vamana indexes, the number of neighbors considered for each node during construction of the graph. Larger values will take more time to build but result in indices that provide higher recall for the same search complexity. l_build should be &gt;= r_max_degree unless you need to build indices quickly and can compromise on quality. Typically between 75 and 200. If not provided, use the default value of 100.\n-1\n\n\nr_max_degree\nint\nFor Vamana indexes, the maximum degree for each node in the final graph. Larger values will result in larger indices and longer indexing times, but better search quality. Typically between 60 and 150. If not provided, use the default value of 64.\n-1\n\n\ncopy_centroids_uri\nOptional[str]\nTileDB array URI to copy centroids from, if not provided, centroids are build running k-means.\nNone\n\n\ntraining_sample_size\nint\nSample size to use for computing k-means. If not provided, is auto-configured based on the dataset sizes. Should not be provided if training_source_uri is provided.\n-1\n\n\ntraining_input_vectors\nOptional[np.ndarray]\nTraining input vectors, if this is provided it takes precedence over training_source_uri and training_source_type. Should not be provided if training_sample_size or training_source_uri are provided.\nNone\n\n\ntraining_source_uri\nOptional[str]\nThe source URI to use for training centroids when building a IVF_FLAT vector index. If not provided, the first training_sample_size vectors from source_uri are used. Should not be provided if training_sample_size or training_input_vectors is provided.\nNone\n\n\ntraining_source_type\nOptional[str]\nType of the training source data in training_source_uri. If left empty, is auto-detected. Should only be provided when training_source_uri is provided.\nNone\n\n\nworkers\nint\nNumber of distributed workers to use for vector ingestion. If not provided, is auto-configured based on the dataset size.\n-1\n\n\ninput_vectors_per_work_item\nint\nNumber of vectors per ingestion work item. If not provided, is auto-configured.\n-1\n\n\nmax_tasks_per_stage\nint\nMax number of tasks per execution stage of ingestion. If not provided, is auto-configured.\n-1\n\n\ninput_vectors_per_work_item_during_sampling\nint\nNumber of vectors per sample ingestion work item. iIf not provided, is auto-configured. Only valid with training_sampling_policy=TrainingSamplingPolicy.RANDOM.\n-1\n\n\nmax_sampling_tasks\nint\nMax number of tasks per execution stage of sampling. If not provided, is auto-configured Only valid with training_sampling_policy=TrainingSamplingPolicy.RANDOM.\n-1\n\n\nstorage_version\nstr\nVector index storage format version. If not provided, defaults to the latest version.\nSTORAGE_VERSION\n\n\nverbose\nbool\nEnables verbose logging.\nFalse\n\n\ntrace_id\nOptional[str]\ntrace ID for logging.\nNone\n\n\nuse_sklearn\nbool\nWhether to use scikit-learn’s implementation of k-means clustering instead of tiledb.vector_search’s.\nTrue\n\n\nmode\nMode\nExecution mode, defaults to LOCAL use BATCH for distributed execution.\nMode.LOCAL\n\n\nacn\nOptional[str]\nAccess credential name to be used when running in BATCH mode for object store access\nNone\n\n\ningest_resources\nOptional[Mapping[str, Any]]\nResources to request when performing vector ingestion, only applies to BATCH mode\nNone\n\n\nconsolidate_partition_resources\nOptional[Mapping[str, Any]]\nResources to request when performing consolidation of a partition, only applies to BATCH mode\nNone\n\n\ncopy_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing copy of centroids from input array to output array, only applies to BATCH mode\nNone\n\n\nrandom_sample_resources\nOptional[Mapping[str, Any]]\nResources to request when performing random sample selection, only applies to BATCH mode\nNone\n\n\nkmeans_resources\nOptional[Mapping[str, Any]]\nResources to request when performing kmeans task, only applies to BATCH mode\nNone\n\n\ncompute_new_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing centroid computation, only applies to BATCH mode\nNone\n\n\nassign_points_and_partial_new_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the computation of partial centroids, only applies to BATCH mode\nNone\n\n\nwrite_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the write of centroids, only applies to BATCH mode\nNone\n\n\npartial_index_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the computation of partial indexing, only applies to BATCH mode\nNone\n\n\ndistance_metric\nvspy.DistanceMetric\nDistance metric to use for the index, defaults to ‘vspy.DistanceMetric.L2’. Options are ‘vspy.DistanceMetric.L2’, ‘vspy.DistanceMetric.INNER_PRODUCT’, ‘vspy.DistanceMetric.COSINE’.\nvspy.DistanceMetric.L2"
  },
  {
    "objectID": "documentation/reference/ingestion.html#functions",
    "href": "documentation/reference/ingestion.html#functions",
    "title": "ingestion",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ningest\nIngest vectors into TileDB.\n\n\n\n\n\nvector_search.ingestion.ingest(index_type, index_uri, *, input_vectors=None, source_uri=None, source_type=None, external_ids=None, external_ids_uri='', external_ids_type=None, updates_uri=None, index_timestamp=None, config=None, namespace=None, size=-1, partitions=-1, num_subspaces=-1, l_build=-1, r_max_degree=-1, training_sampling_policy=TrainingSamplingPolicy.FIRST_N, copy_centroids_uri=None, training_sample_size=-1, training_input_vectors=None, training_source_uri=None, training_source_type=None, workers=-1, input_vectors_per_work_item=-1, max_tasks_per_stage=-1, input_vectors_per_work_item_during_sampling=-1, max_sampling_tasks=-1, storage_version=STORAGE_VERSION, verbose=False, trace_id=None, use_sklearn=True, mode=Mode.LOCAL, acn=None, ingest_resources=None, consolidate_partition_resources=None, copy_centroids_resources=None, random_sample_resources=None, kmeans_resources=None, compute_new_centroids_resources=None, assign_points_and_partial_new_centroids_resources=None, write_centroids_resources=None, partial_index_resources=None, distance_metric=vspy.DistanceMetric.L2, normalized=False, **kwargs)\nIngest vectors into TileDB.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nindex_type\nstr\nType of vector index (FLAT, IVF_FLAT, IVF_PQ, VAMANA).\nrequired\n\n\nindex_uri\nstr\nVector index URI (stored as TileDB group).\nrequired\n\n\ninput_vectors\nOptional[np.ndarray]\nInput vectors, if this is provided it takes precedence over source_uri and source_type.\nNone\n\n\nsource_uri\nOptional[str]\nVectors source URI.\nNone\n\n\nsource_type\nOptional[str]\nType of the source vectors. If left empty it is auto-detected.\nNone\n\n\nexternal_ids\nOptional[np.array]\nInput vector external_ids, if this is provided it takes precedence over external_ids_uri and external_ids_type.\nNone\n\n\nexternal_ids_uri\nOptional[str]\nSource URI for external_ids.\n''\n\n\nexternal_ids_type\nOptional[str]\nFile type of external_ids_uri. If left empty it is auto-detected.\nNone\n\n\nupdates_uri\nOptional[str]\nUpdates array URI. Used for consolidation of updates.\nNone\n\n\nindex_timestamp\nOptional[int]\nTimestamp to use for writing and reading data. By default it uses the current unix ms timestamp.\nNone\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nnamespace\nOptional[str]\nTileDB-Cloud namespace to use for Cloud execution.\nNone\n\n\nsize\nint\nNumber of input vectors, if not provided use the full size of the input dataset. If provided, we filter the first vectors from the input source.\n-1\n\n\npartitions\nint\nFor IVF_FLAT and IVF_PQ indexes, the number of partitions to generate from the data during k-means clustering. If not provided, is auto-configured based on the dataset size.\n-1\n\n\nnum_subspaces\nint\nFor IVF_PQ encoded indexes, the number of subspaces to use in the PQ encoding. We will divide the dimensions into num_subspaces parts, and PQ encode each part separately. This means dimensions must be divisible by num_subspaces.\n-1\n\n\nl_build\nint\nFor Vamana indexes, the number of neighbors considered for each node during construction of the graph. Larger values will take more time to build but result in indices that provide higher recall for the same search complexity. l_build should be &gt;= r_max_degree unless you need to build indices quickly and can compromise on quality. Typically between 75 and 200. If not provided, use the default value of 100.\n-1\n\n\nr_max_degree\nint\nFor Vamana indexes, the maximum degree for each node in the final graph. Larger values will result in larger indices and longer indexing times, but better search quality. Typically between 60 and 150. If not provided, use the default value of 64.\n-1\n\n\ncopy_centroids_uri\nOptional[str]\nTileDB array URI to copy centroids from, if not provided, centroids are build running k-means.\nNone\n\n\ntraining_sample_size\nint\nSample size to use for computing k-means. If not provided, is auto-configured based on the dataset sizes. Should not be provided if training_source_uri is provided.\n-1\n\n\ntraining_input_vectors\nOptional[np.ndarray]\nTraining input vectors, if this is provided it takes precedence over training_source_uri and training_source_type. Should not be provided if training_sample_size or training_source_uri are provided.\nNone\n\n\ntraining_source_uri\nOptional[str]\nThe source URI to use for training centroids when building a IVF_FLAT vector index. If not provided, the first training_sample_size vectors from source_uri are used. Should not be provided if training_sample_size or training_input_vectors is provided.\nNone\n\n\ntraining_source_type\nOptional[str]\nType of the training source data in training_source_uri. If left empty, is auto-detected. Should only be provided when training_source_uri is provided.\nNone\n\n\nworkers\nint\nNumber of distributed workers to use for vector ingestion. If not provided, is auto-configured based on the dataset size.\n-1\n\n\ninput_vectors_per_work_item\nint\nNumber of vectors per ingestion work item. If not provided, is auto-configured.\n-1\n\n\nmax_tasks_per_stage\nint\nMax number of tasks per execution stage of ingestion. If not provided, is auto-configured.\n-1\n\n\ninput_vectors_per_work_item_during_sampling\nint\nNumber of vectors per sample ingestion work item. iIf not provided, is auto-configured. Only valid with training_sampling_policy=TrainingSamplingPolicy.RANDOM.\n-1\n\n\nmax_sampling_tasks\nint\nMax number of tasks per execution stage of sampling. If not provided, is auto-configured Only valid with training_sampling_policy=TrainingSamplingPolicy.RANDOM.\n-1\n\n\nstorage_version\nstr\nVector index storage format version. If not provided, defaults to the latest version.\nSTORAGE_VERSION\n\n\nverbose\nbool\nEnables verbose logging.\nFalse\n\n\ntrace_id\nOptional[str]\ntrace ID for logging.\nNone\n\n\nuse_sklearn\nbool\nWhether to use scikit-learn’s implementation of k-means clustering instead of tiledb.vector_search’s.\nTrue\n\n\nmode\nMode\nExecution mode, defaults to LOCAL use BATCH for distributed execution.\nMode.LOCAL\n\n\nacn\nOptional[str]\nAccess credential name to be used when running in BATCH mode for object store access\nNone\n\n\ningest_resources\nOptional[Mapping[str, Any]]\nResources to request when performing vector ingestion, only applies to BATCH mode\nNone\n\n\nconsolidate_partition_resources\nOptional[Mapping[str, Any]]\nResources to request when performing consolidation of a partition, only applies to BATCH mode\nNone\n\n\ncopy_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing copy of centroids from input array to output array, only applies to BATCH mode\nNone\n\n\nrandom_sample_resources\nOptional[Mapping[str, Any]]\nResources to request when performing random sample selection, only applies to BATCH mode\nNone\n\n\nkmeans_resources\nOptional[Mapping[str, Any]]\nResources to request when performing kmeans task, only applies to BATCH mode\nNone\n\n\ncompute_new_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing centroid computation, only applies to BATCH mode\nNone\n\n\nassign_points_and_partial_new_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the computation of partial centroids, only applies to BATCH mode\nNone\n\n\nwrite_centroids_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the write of centroids, only applies to BATCH mode\nNone\n\n\npartial_index_resources\nOptional[Mapping[str, Any]]\nResources to request when performing the computation of partial indexing, only applies to BATCH mode\nNone\n\n\ndistance_metric\nvspy.DistanceMetric\nDistance metric to use for the index, defaults to ‘vspy.DistanceMetric.L2’. Options are ‘vspy.DistanceMetric.L2’, ‘vspy.DistanceMetric.INNER_PRODUCT’, ‘vspy.DistanceMetric.COSINE’.\nvspy.DistanceMetric.L2"
  },
  {
    "objectID": "documentation/index.html",
    "href": "documentation/index.html",
    "title": "TileDB Vector Search",
    "section": "",
    "text": "TileDB Vector Search\nTileDB-Vector-Search is a C++ library and Python API for vector search built on top of the TileDB Storage Engine.\n\n\nQuick Links\n\nBuild Instructions\nDocumentation\nPython API reference\n\n\n\nQuick Installation\nTileDB-Vector-Search is available from PyPI or the tiledb conda channel.\nTo install from PyPI with pip, use:\npip install tiledb-vector-search\nTo install from conda, use conda or mamba:\nconda install -c tiledb -c conda-forge tiledb-vector-search\nmamba install -c tiledb -c conda-forge tiledb-vector-search\n\n\nContributing\nWe welcome contributions. Please see Building for development-build instructions. For large new features, please open an issue to discuss goals and approach in order to ensure a smooth PR integration and review process. All contributions must be licensed under the repository’s MIT License.",
    "crumbs": [
      "Home page",
      "TileDB Vector Search"
    ]
  },
  {
    "objectID": "documentation/reference/vamana_index.html",
    "href": "documentation/reference/vamana_index.html",
    "title": "vamana_index",
    "section": "",
    "text": "vector_search.vamana_index\nVamana Index implementation.\nVamana is based on Microsoft’s DiskANN vector search library, as described in these papers:\n  Subramanya, Suhas Jayaram, and Rohan Kadekodi. DiskANN: Fast Accurate Billion-Point Nearest Neighbor Search on a Single Node.\n\n  Singh, Aditi, et al. FreshDiskANN: A Fast and Accurate Graph-Based ANN Index for Streaming Similarity Search. arXiv:2105.09613, arXiv, 20 May 2021, http://arxiv.org/abs/2105.09613.\n\n  Gollapudi, Siddharth, et al. “Filtered-DiskANN: Graph Algorithms for Approximate Nearest Neighbor Search with Filters.” Proceedings of the ACM Web Conference 2023, ACM, 2023, pp. 3406-16, https://doi.org/10.1145/3543507.3583552.\n\n\n\n\n\nName\nDescription\n\n\n\n\nVamanaIndex\nOpens a VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.VamanaIndex(self, uri, config=None, timestamp=None, open_for_remote_query_execution=False, **kwargs)\nOpens a VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nFalse\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries a VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.VamanaIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.vamana_index.VamanaIndex.query_internal(queries, k=10, l_search=L_SEARCH_DEFAULT, **kwargs)\nQueries a VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nl_search\nOptional[int]\nHow deep to search. Larger parameters will result in slower latencies, but higher accuracies. Should be &gt;= k, and if it’s not, we will set it to k.\nL_SEARCH_DEFAULT\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate\nCreates an empty VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.create(uri, dimensions, vector_type, l_build=L_BUILD_DEFAULT, r_max_degree=R_MAX_DEGREE_DEFAULT, config=None, storage_version=STORAGE_VERSION, distance_metric=vspy.DistanceMetric.L2, **kwargs)\nCreates an empty VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\nl_build\nint\nThe number of neighbors considered for each node during construction of the graph. Larger values will take more time to build but result in indices that provide higher recall for the same search complexity. l_build should be &gt;= r_max_degree unless you need to build indices quickly and can compromise on quality. Typically between 75 and 200. If not provided, use the default value of 100.\nL_BUILD_DEFAULT\n\n\nr_max_degree\nint\nThe maximum degree for each node in the final graph. Larger values will result in larger indices and longer indexing times, but better search quality. Typically between 60 and 150. If not provided, use the default value of 64.\nR_MAX_DEGREE_DEFAULT\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use the latest stable storage version.\nSTORAGE_VERSION"
  },
  {
    "objectID": "documentation/reference/vamana_index.html#classes",
    "href": "documentation/reference/vamana_index.html#classes",
    "title": "vamana_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nVamanaIndex\nOpens a VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.VamanaIndex(self, uri, config=None, timestamp=None, open_for_remote_query_execution=False, **kwargs)\nOpens a VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nFalse\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries a VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.VamanaIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.vamana_index.VamanaIndex.query_internal(queries, k=10, l_search=L_SEARCH_DEFAULT, **kwargs)\nQueries a VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nl_search\nOptional[int]\nHow deep to search. Larger parameters will result in slower latencies, but higher accuracies. Should be &gt;= k, and if it’s not, we will set it to k.\nL_SEARCH_DEFAULT"
  },
  {
    "objectID": "documentation/reference/vamana_index.html#functions",
    "href": "documentation/reference/vamana_index.html#functions",
    "title": "vamana_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate\nCreates an empty VamanaIndex.\n\n\n\n\n\nvector_search.vamana_index.create(uri, dimensions, vector_type, l_build=L_BUILD_DEFAULT, r_max_degree=R_MAX_DEGREE_DEFAULT, config=None, storage_version=STORAGE_VERSION, distance_metric=vspy.DistanceMetric.L2, **kwargs)\nCreates an empty VamanaIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\nl_build\nint\nThe number of neighbors considered for each node during construction of the graph. Larger values will take more time to build but result in indices that provide higher recall for the same search complexity. l_build should be &gt;= r_max_degree unless you need to build indices quickly and can compromise on quality. Typically between 75 and 200. If not provided, use the default value of 100.\nL_BUILD_DEFAULT\n\n\nr_max_degree\nint\nThe maximum degree for each node in the final graph. Larger values will result in larger indices and longer indexing times, but better search quality. Typically between 60 and 150. If not provided, use the default value of 64.\nR_MAX_DEGREE_DEFAULT\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use the latest stable storage version.\nSTORAGE_VERSION"
  },
  {
    "objectID": "documentation/reference/ivf_flat_index.html",
    "href": "documentation/reference/ivf_flat_index.html",
    "title": "ivf_flat_index",
    "section": "",
    "text": "vector_search.ivf_flat_index\nIVFFlat Index implementation.\nIVFFlatIndex is based on k-means clustering and shuffling of the dataset vectors.\nDuring ingestion, TileDB computes the k-means clusters and shuffles the vectors into partitions. The vectors are stored grouped by partition in a 2D TileDB array allowing for partitions to be read with minimal I/O overhead.\nTo answer a query, the search focuses only on a small number of partitions, based on the query’s proximity to the k-means centroids. This is specified with a parameter called nprobe controlling how many partitions are checked for each query.\nIVFFlatIndex provides a vector search implementation that can trade-off accuracy for performance.\nQueries can be run in multiple modes:\n\nLocal main memory:\n\nLoads the entire index in memory during initialization and uses it to answer queries.\n\nLocal out of core:\n\nAvoids loading index data in memory by interleaving I/O and query execution, respecting the memory budget defined by the user.\n\nDistributed execution:\n\nExecutes the queries using multiple workers in TileDB Cloud.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nIVFFlatIndex\nOpens an IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex(self, uri, config=None, timestamp=None, memory_budget=-1, open_for_remote_query_execution=False, **kwargs)\nOpens an IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nmemory_budget\nint\nMain memory budget, in number of vectors, for query execution. If not provided, all index data are loaded in main memory. Otherwise, no index data are loaded in main memory and this memory budget is applied during queries.\n-1\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). We then load index data in the taskgraph based on memory_budget. If False, load index data in main memory locally according to memory_budget. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph..\nFalse\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries an IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.query_internal(queries, k=10, nprobe=1, nthreads=-1, use_nuv_implementation=False, mode=None, resource_class=None, resources=None, num_partitions=-1, num_workers=-1, **kwargs)\nQueries an IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nnprobe\nint\nNumber of partitions to check per query. Use this parameter to trade-off accuracy for latency and cost. As a rule of thumb, configuring nprobe to be the square root of partitions should result in accuracy close to 100%.\n1\n\n\nnthreads\nint\nNumber of threads to use for local query execution.\n-1\n\n\nuse_nuv_implementation\nbool\nWhether to use the nuv query implementation. Default: False\nFalse\n\n\nmode\nOptional[Mode]\nIf provided the query will be executed using TileDB cloud taskgraphs. For distributed execution you can use REALTIME or BATCH mode. For local execution you can use LOCAL mode.\nNone\n\n\nresource_class\nOptional[str]\nThe name of the resource class to use (“standard” or “large”). Resource classes define maximum limits for cpu and memory usage. Can only be used in REALTIME or BATCH mode. Cannot be used alongside resources. In REALTIME or BATCH mode if neither resource_class nor resources are provided, we default to the “large” resource class.\nNone\n\n\nresources\nOptional[Mapping[str, Any]]\nA specification for the amount of resources to use when executing using TileDB cloud taskgraphs, of the form: {“cpu”: “6”, “memory”: “12Gi”, “gpu”: 1}. Can only be used in BATCH mode. Cannot be used alongside resource_class.\nNone\n\n\nnum_partitions\nint\nOnly relevant for taskgraph based execution. If provided, we split the query execution in that many partitions.\n-1\n\n\nnum_workers\nint\nOnly relevant for taskgraph based execution. If provided, this is the number of workers to use for the query execution.\n-1\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate\nCreates an empty IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.create(uri, dimensions, vector_type, group_exists=False, config=None, storage_version=STORAGE_VERSION, distance_metric=vspy.DistanceMetric.L2, **kwargs)\nCreates an empty IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\ngroup_exists\nbool\nIf False it creates the TileDB group for the index. If True the method expects the TileDB group to be already created.\nFalse\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use the latest stable storage version.\nSTORAGE_VERSION"
  },
  {
    "objectID": "documentation/reference/ivf_flat_index.html#classes",
    "href": "documentation/reference/ivf_flat_index.html#classes",
    "title": "ivf_flat_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nIVFFlatIndex\nOpens an IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex(self, uri, config=None, timestamp=None, memory_budget=-1, open_for_remote_query_execution=False, **kwargs)\nOpens an IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nmemory_budget\nint\nMain memory budget, in number of vectors, for query execution. If not provided, all index data are loaded in main memory. Otherwise, no index data are loaded in main memory and this memory budget is applied during queries.\n-1\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). We then load index data in the taskgraph based on memory_budget. If False, load index data in main memory locally according to memory_budget. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph..\nFalse\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries an IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.ivf_flat_index.IVFFlatIndex.query_internal(queries, k=10, nprobe=1, nthreads=-1, use_nuv_implementation=False, mode=None, resource_class=None, resources=None, num_partitions=-1, num_workers=-1, **kwargs)\nQueries an IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nnprobe\nint\nNumber of partitions to check per query. Use this parameter to trade-off accuracy for latency and cost. As a rule of thumb, configuring nprobe to be the square root of partitions should result in accuracy close to 100%.\n1\n\n\nnthreads\nint\nNumber of threads to use for local query execution.\n-1\n\n\nuse_nuv_implementation\nbool\nWhether to use the nuv query implementation. Default: False\nFalse\n\n\nmode\nOptional[Mode]\nIf provided the query will be executed using TileDB cloud taskgraphs. For distributed execution you can use REALTIME or BATCH mode. For local execution you can use LOCAL mode.\nNone\n\n\nresource_class\nOptional[str]\nThe name of the resource class to use (“standard” or “large”). Resource classes define maximum limits for cpu and memory usage. Can only be used in REALTIME or BATCH mode. Cannot be used alongside resources. In REALTIME or BATCH mode if neither resource_class nor resources are provided, we default to the “large” resource class.\nNone\n\n\nresources\nOptional[Mapping[str, Any]]\nA specification for the amount of resources to use when executing using TileDB cloud taskgraphs, of the form: {“cpu”: “6”, “memory”: “12Gi”, “gpu”: 1}. Can only be used in BATCH mode. Cannot be used alongside resource_class.\nNone\n\n\nnum_partitions\nint\nOnly relevant for taskgraph based execution. If provided, we split the query execution in that many partitions.\n-1\n\n\nnum_workers\nint\nOnly relevant for taskgraph based execution. If provided, this is the number of workers to use for the query execution.\n-1"
  },
  {
    "objectID": "documentation/reference/ivf_flat_index.html#functions",
    "href": "documentation/reference/ivf_flat_index.html#functions",
    "title": "ivf_flat_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate\nCreates an empty IVFFlatIndex.\n\n\n\n\n\nvector_search.ivf_flat_index.create(uri, dimensions, vector_type, group_exists=False, config=None, storage_version=STORAGE_VERSION, distance_metric=vspy.DistanceMetric.L2, **kwargs)\nCreates an empty IVFFlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\ngroup_exists\nbool\nIf False it creates the TileDB group for the index. If True the method expects the TileDB group to be already created.\nFalse\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use the latest stable storage version.\nSTORAGE_VERSION"
  },
  {
    "objectID": "documentation/reference/flat_index.html",
    "href": "documentation/reference/flat_index.html",
    "title": "flat_index",
    "section": "",
    "text": "vector_search.flat_index\nFlatIndex implementation.\nStores all vectors in a 2D TileDB array performing exhaustive similarity search between the query vectors and all the dataset vectors.\n\n\n\n\n\nName\nDescription\n\n\n\n\nFlatIndex\nOpens a FlatIndex loading all dataset vectors in main memory.\n\n\n\n\n\nvector_search.flat_index.FlatIndex(self, uri, config=None, timestamp=None, open_for_remote_query_execution=False, **kwargs)\nOpens a FlatIndex loading all dataset vectors in main memory.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nFalse\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries a FlatIndex using the vectors already loaded in main memory.\n\n\n\n\n\nvector_search.flat_index.FlatIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.flat_index.FlatIndex.query_internal(queries, k=10, nthreads=8, **kwargs)\nQueries a FlatIndex using the vectors already loaded in main memory.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nnthreads\nint\nNumber of threads to use for query execution.\n8\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate\nCreates an empty FlatIndex.\n\n\n\n\n\nvector_search.flat_index.create(uri, dimensions, vector_type, group_exists=False, config=None, storage_version=STORAGE_VERSION, distance_metric=vspy.DistanceMetric.L2, **kwargs)\nCreates an empty FlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\ngroup_exists\nbool\nIf False it creates the TileDB group for the index. If True the method expects the TileDB group to be already created.\nFalse\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use hte latest stable storage version.\nSTORAGE_VERSION\n\n\ndistance_metric\nvspy.DistanceMetric\nDistance metric to use for the index. If not provided, use L2 distance.\nvspy.DistanceMetric.L2"
  },
  {
    "objectID": "documentation/reference/flat_index.html#classes",
    "href": "documentation/reference/flat_index.html#classes",
    "title": "flat_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nFlatIndex\nOpens a FlatIndex loading all dataset vectors in main memory.\n\n\n\n\n\nvector_search.flat_index.FlatIndex(self, uri, config=None, timestamp=None, open_for_remote_query_execution=False, **kwargs)\nOpens a FlatIndex loading all dataset vectors in main memory.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\ntimestamp\n\nIf int, open the index at a given timestamp. If tuple, open at the given start and end timestamps.\nNone\n\n\nopen_for_remote_query_execution\nbool\nIf True, do not load any index data in main memory locally, and instead load index data in the TileDB Cloud taskgraph created when a non-None driver_mode is passed to query(). If False, load index data in main memory locally. Note that you can still use a taskgraph for query execution, you’ll just end up loading the data both on your local machine and in the cloud taskgraph.\nFalse\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_dimensions\nReturns the dimension of the vectors in the index.\n\n\nquery_internal\nQueries a FlatIndex using the vectors already loaded in main memory.\n\n\n\n\n\nvector_search.flat_index.FlatIndex.get_dimensions()\nReturns the dimension of the vectors in the index.\n\n\n\nvector_search.flat_index.FlatIndex.query_internal(queries, k=10, nthreads=8, **kwargs)\nQueries a FlatIndex using the vectors already loaded in main memory.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnp.ndarray\n2D array of query vectors. This can be used as a batch query interface by passing multiple queries in one call.\nrequired\n\n\nk\nint\nNumber of results to return per query vector.\n10\n\n\nnthreads\nint\nNumber of threads to use for query execution.\n8"
  },
  {
    "objectID": "documentation/reference/flat_index.html#functions",
    "href": "documentation/reference/flat_index.html#functions",
    "title": "flat_index",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate\nCreates an empty FlatIndex.\n\n\n\n\n\nvector_search.flat_index.create(uri, dimensions, vector_type, group_exists=False, config=None, storage_version=STORAGE_VERSION, distance_metric=vspy.DistanceMetric.L2, **kwargs)\nCreates an empty FlatIndex.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of the index.\nrequired\n\n\ndimensions\nint\nNumber of dimensions for the vectors to be stored in the index.\nrequired\n\n\nvector_type\nnp.dtype\nDatatype of vectors. Supported values (uint8, int8, float32).\nrequired\n\n\ngroup_exists\nbool\nIf False it creates the TileDB group for the index. If True the method expects the TileDB group to be already created.\nFalse\n\n\nconfig\nOptional[Mapping[str, Any]]\nTileDB config dictionary.\nNone\n\n\nstorage_version\nstr\nThe TileDB vector search storage version to use. If not provided, use hte latest stable storage version.\nSTORAGE_VERSION\n\n\ndistance_metric\nvspy.DistanceMetric\nDistance metric to use for the index. If not provided, use L2 distance.\nvspy.DistanceMetric.L2"
  },
  {
    "objectID": "documentation/Building.html",
    "href": "documentation/Building.html",
    "title": "Building and Running Tests",
    "section": "",
    "text": "TileDB Vector Search can be built from source for either C++ or Python.\n\n\nTo build for C++, run:\ncmake -S ./src -B ./src/build -DCMAKE_BUILD_TYPE=Debug\ncmake --build ./src/build -j3\nThen you can run the tests:\ncmake --build ./src/build --target check\nAlternatively, you can setup CLion, which is the suggested way to develop C++ in this project. To set up CLion:\n\nOpen up CLion to the root directory of this repo.\nGo to File -&gt; Settings -&gt; Build, Execution, Deployment -&gt; CMake.\n\nSet CMake options to G \"Unix Makefiles\" -DCMAKE_IDE=ON -DTileDB_DIR:PATH=/Users/&lt;name&gt;/repo/tileDB/build/dist -DTILEDB_VS_ENABLE_BLAS=on -DTILEDB_VS_PYTHON=off.\n\nNote that DTileDB_DIR will be specific to your TileDB installation. If you have it installed in a standard location, you can omit this option.\n\nSet Build directory to cmake-build-debug/libtiledbvectorsearch.\n\nNext right click on src/CMakeLists.txt and select Load CMake Project.\nAfter that you should see configurations for unit tests and build targets automatically generated by CLion.\n\nTo build with sanitizers, you can add -DTILEDB_SANITIZER=\"${sanitizer}\", where sanitizer = (address|memory|leak|thread). For example:\ncmake -S ./src -B ./src/build -DCMAKE_BUILD_TYPE=Debug -DTILEDB_SANITIZER=\"address\"\ncmake --build ./src/build -j3\ncmake --build ./src/build --target check\n\n\n\nBefore building you may want to set up a virtual environment:\nconda create --name TileDB-Vector-Search python=3.9\nconda activate TileDB-Vector-Search\nTo build for Python, run:\npip install .\nYou can run unit tests with pytest. You’ll also need to install the test dependencies:\npip install \".[test]\"\nThen you can run the tests:\ncd apis/python\n# To run all tests.\npytest\n# To run a single test and display standard output and standard error.\npytest test/test_ingestion.py -s\nTo test Demo notebooks:\ncd apis/python\npip install -r test/ipynb/requirements.txt\npytest --nbmake test/ipynb\nCredentials:\n\nSome tests run on TileDB Cloud using your current environment variable TILEDB_REST_TOKEN - you will need a valid API token for the tests to pass. See Create API Tokens for for instructions on getting one.\nFor continuous integration, the token is configured for the unittest user and all tests should pass.\n\n\n\n\nFirst install quarto with their instructions or with Homebrew.\nThen run:\npip install quartodoc\nquartodoc build\nquarto render --fail-if-warnings\nYou can them open up docs/documentation/index.html in a web browser to preview the results.",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/Building.html#c",
    "href": "documentation/Building.html#c",
    "title": "Building and Running Tests",
    "section": "",
    "text": "To build for C++, run:\ncmake -S ./src -B ./src/build -DCMAKE_BUILD_TYPE=Debug\ncmake --build ./src/build -j3\nThen you can run the tests:\ncmake --build ./src/build --target check\nAlternatively, you can setup CLion, which is the suggested way to develop C++ in this project. To set up CLion:\n\nOpen up CLion to the root directory of this repo.\nGo to File -&gt; Settings -&gt; Build, Execution, Deployment -&gt; CMake.\n\nSet CMake options to G \"Unix Makefiles\" -DCMAKE_IDE=ON -DTileDB_DIR:PATH=/Users/&lt;name&gt;/repo/tileDB/build/dist -DTILEDB_VS_ENABLE_BLAS=on -DTILEDB_VS_PYTHON=off.\n\nNote that DTileDB_DIR will be specific to your TileDB installation. If you have it installed in a standard location, you can omit this option.\n\nSet Build directory to cmake-build-debug/libtiledbvectorsearch.\n\nNext right click on src/CMakeLists.txt and select Load CMake Project.\nAfter that you should see configurations for unit tests and build targets automatically generated by CLion.\n\nTo build with sanitizers, you can add -DTILEDB_SANITIZER=\"${sanitizer}\", where sanitizer = (address|memory|leak|thread). For example:\ncmake -S ./src -B ./src/build -DCMAKE_BUILD_TYPE=Debug -DTILEDB_SANITIZER=\"address\"\ncmake --build ./src/build -j3\ncmake --build ./src/build --target check",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/Building.html#python",
    "href": "documentation/Building.html#python",
    "title": "Building and Running Tests",
    "section": "",
    "text": "Before building you may want to set up a virtual environment:\nconda create --name TileDB-Vector-Search python=3.9\nconda activate TileDB-Vector-Search\nTo build for Python, run:\npip install .\nYou can run unit tests with pytest. You’ll also need to install the test dependencies:\npip install \".[test]\"\nThen you can run the tests:\ncd apis/python\n# To run all tests.\npytest\n# To run a single test and display standard output and standard error.\npytest test/test_ingestion.py -s\nTo test Demo notebooks:\ncd apis/python\npip install -r test/ipynb/requirements.txt\npytest --nbmake test/ipynb\nCredentials:\n\nSome tests run on TileDB Cloud using your current environment variable TILEDB_REST_TOKEN - you will need a valid API token for the tests to pass. See Create API Tokens for for instructions on getting one.\nFor continuous integration, the token is configured for the unittest user and all tests should pass.",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/Building.html#quarto",
    "href": "documentation/Building.html#quarto",
    "title": "Building and Running Tests",
    "section": "",
    "text": "First install quarto with their instructions or with Homebrew.\nThen run:\npip install quartodoc\nquartodoc build\nquarto render --fail-if-warnings\nYou can them open up docs/documentation/index.html in a web browser to preview the results.",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/Building.html#linux",
    "href": "documentation/Building.html#linux",
    "title": "Building and Running Tests",
    "section": "Linux",
    "text": "Linux\nThere are several dependencies needed, for Ubuntu you can install via:\napt-get openblas-dev build-essentials cmake3\nTo build the python API after you have the dependencies, use pip:\npip install .",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  },
  {
    "objectID": "documentation/Building.html#docker",
    "href": "documentation/Building.html#docker",
    "title": "Building and Running Tests",
    "section": "Docker",
    "text": "Docker\nA docker image is also provided for simplicity:\ndocker build -t tiledb/tiledb-vector-search .\nYou run the example docker image which provides the python package with:\ndocker run --rm tiledb/tiledb-vector-search",
    "crumbs": [
      "Home page",
      "Building and Running Tests"
    ]
  }
]