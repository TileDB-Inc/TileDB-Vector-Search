[
  {
    "objectID": "documentation/Building.html",
    "href": "documentation/Building.html",
    "title": "Building From Source",
    "section": "",
    "text": "TileDB Vector Search can be built from source. For information on dependencies, see below.\n\n\npip install git+https://github.com/TileDB-Inc/TileDB-Vector-Search.git#subdirectory=apis/python\n\n\n\ncd apis/python\npip install ."
  },
  {
    "objectID": "documentation/Building.html#installation-from-github-with-pip",
    "href": "documentation/Building.html#installation-from-github-with-pip",
    "title": "Building From Source",
    "section": "",
    "text": "pip install git+https://github.com/TileDB-Inc/TileDB-Vector-Search.git#subdirectory=apis/python"
  },
  {
    "objectID": "documentation/Building.html#installation-from-a-local-checkout",
    "href": "documentation/Building.html#installation-from-a-local-checkout",
    "title": "Building From Source",
    "section": "",
    "text": "cd apis/python\npip install ."
  },
  {
    "objectID": "documentation/Building.html#linux",
    "href": "documentation/Building.html#linux",
    "title": "Building From Source",
    "section": "Linux",
    "text": "Linux\nThere are several dependencies needed, for Ubuntu you can install via:\napt-get openblas-dev build-essentials cmake3\nTo build the python API after you have the dependencies, use pip:\ncd apis/python\npip install ."
  },
  {
    "objectID": "documentation/Building.html#docker",
    "href": "documentation/Building.html#docker",
    "title": "Building From Source",
    "section": "Docker",
    "text": "Docker\nA docker image is also provided for simplicity:\ndocker build -t tiledb/tiledb-vector-search .\nYou run the example docker image which provides the python package with:\ndocker run --rm tiledb/tiledb-vector-search"
  },
  {
    "objectID": "documentation/reference/index.FlatIndex.html",
    "href": "documentation/reference/index.FlatIndex.html",
    "title": "index.FlatIndex",
    "section": "",
    "text": "vector_search.index.FlatIndex(self, uri, config=None)\nOpen a flat index\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of datataset\nrequired\n\n\ndtype\n\ndatatype float32 or uint8\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nquery\nQuery a flat index\n\n\n\n\n\nvector_search.index.FlatIndex.query(self, targets, k=10, nthreads=8, query_type='heap')\nQuery a flat index\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntargets\nnumpy.ndarray\nND Array of query targets\nrequired\n\n\nk\nint\nNumber of top results to return per target\n10\n\n\nnqueries\n\nNumber of queries\nrequired\n\n\nnthreads\nint\nNumber of threads to use for query\n8"
  },
  {
    "objectID": "documentation/reference/index.FlatIndex.html#parameters",
    "href": "documentation/reference/index.FlatIndex.html#parameters",
    "title": "index.FlatIndex",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nuri\nstr\nURI of datataset\nrequired\n\n\ndtype\n\ndatatype float32 or uint8\nrequired"
  },
  {
    "objectID": "documentation/reference/index.FlatIndex.html#methods",
    "href": "documentation/reference/index.FlatIndex.html#methods",
    "title": "index.FlatIndex",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nquery\nQuery a flat index\n\n\n\n\n\nvector_search.index.FlatIndex.query(self, targets, k=10, nthreads=8, query_type='heap')\nQuery a flat index\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntargets\nnumpy.ndarray\nND Array of query targets\nrequired\n\n\nk\nint\nNumber of top results to return per target\n10\n\n\nnqueries\n\nNumber of queries\nrequired\n\n\nnthreads\nint\nNumber of threads to use for query\n8"
  },
  {
    "objectID": "documentation/reference/index.html",
    "href": "documentation/reference/index.html",
    "title": "Python",
    "section": "",
    "text": "index.Index\n\n\n\nindex.FlatIndex\nOpen a flat index\n\n\nindex.IVFFlatIndex\nOpen a IVF Flat index\n\n\ningestion"
  },
  {
    "objectID": "documentation/reference/index.html#tiledb.vector_search",
    "href": "documentation/reference/index.html#tiledb.vector_search",
    "title": "Python",
    "section": "",
    "text": "index.Index\n\n\n\nindex.FlatIndex\nOpen a flat index\n\n\nindex.IVFFlatIndex\nOpen a IVF Flat index\n\n\ningestion"
  },
  {
    "objectID": "documentation/Benchmarks.html",
    "href": "documentation/Benchmarks.html",
    "title": "Benchmarks",
    "section": "",
    "text": "We have implemented a big-ann-benchmarks interface for TileDB-Vector-Search, which is available in the tiledb branch of our fork: - https://github.com/TileDB-Inc/big-ann-benchmarks/tree/tiledb. This interface implements two new algorithms: tiledb-flat and tiledb-ivf-flat, which are usable within the framework’s runner.\n\n\n\nBuild the Dockerfile at the root of this repository:\n\ncd tiledb-vector-search\ndocker build -f Dockerfile . -t tiledb_vs\n\nBuild the TileDB docker image in the big-ann fork (requires image from step 1):\n\ngit clone https://github.com/TileDB-Inc/big-ann-benchmarks/tree/tiledb\ncd big-ann-benchmarks\ndocker build -f install/Dockerfile.tiledb . -t billion-scale-benchmark-tiledb\n\n\n\n\nCreate a local dataset.\nnote: the create_dataset.py command will download remote files the first time it runs, some of which can total &gt;100GB). Use --skip-data to avoid downloading the large base set.\nThis command will download 7.7MB of data:\n\npython create_dataset.py --dataset bigann-10M --skip-data\n\nRun the benchmarks, choosing either tiledb-flat or tiledb-ivf-flat:\n\npython run.py --dataset bigann-10M --algorithm tiledb-flat"
  },
  {
    "objectID": "documentation/Benchmarks.html#building",
    "href": "documentation/Benchmarks.html#building",
    "title": "Benchmarks",
    "section": "",
    "text": "Build the Dockerfile at the root of this repository:\n\ncd tiledb-vector-search\ndocker build -f Dockerfile . -t tiledb_vs\n\nBuild the TileDB docker image in the big-ann fork (requires image from step 1):\n\ngit clone https://github.com/TileDB-Inc/big-ann-benchmarks/tree/tiledb\ncd big-ann-benchmarks\ndocker build -f install/Dockerfile.tiledb . -t billion-scale-benchmark-tiledb"
  },
  {
    "objectID": "documentation/Benchmarks.html#running-benchmarks",
    "href": "documentation/Benchmarks.html#running-benchmarks",
    "title": "Benchmarks",
    "section": "",
    "text": "Create a local dataset.\nnote: the create_dataset.py command will download remote files the first time it runs, some of which can total &gt;100GB). Use --skip-data to avoid downloading the large base set.\nThis command will download 7.7MB of data:\n\npython create_dataset.py --dataset bigann-10M --skip-data\n\nRun the benchmarks, choosing either tiledb-flat or tiledb-ivf-flat:\n\npython run.py --dataset bigann-10M --algorithm tiledb-flat"
  },
  {
    "objectID": "documentation/index.html",
    "href": "documentation/index.html",
    "title": "TileDB Vector Search",
    "section": "",
    "text": "TileDB Vector Search\nTileDB-Vector-Search is a C++ library and Python API for vector search built on top of the TileDB Storage Engine.\n\n\nQuick Links\n\nBuild Instructions\nDocumentation\nPython API reference\n\n\n\nQuick Installation\nTileDB-Vector-Search is available from PyPI or the tiledb conda channel.\nTo install from PyPI with pip, use:\npip install tiledb-vector-search\nTo install from conda, use conda or mamba:\nconda install -c tiledb -c conda-forge tiledb-vector-search\nmamba install -c tiledb -c conda-forge tiledb-vector-search\n\n\nContributing\nWe welcome contributions. Please see Building for development-build instructions. For large new features, please open an issue to discuss goals and approach in order to ensure a smooth PR integration and review process. All contributions must be licensed under the repository’s MIT License."
  },
  {
    "objectID": "documentation/reference/index.Index.html",
    "href": "documentation/reference/index.Index.html",
    "title": "index.Index",
    "section": "",
    "text": "index.Index\nvector_search.index.Index()"
  },
  {
    "objectID": "documentation/reference/ingestion.html",
    "href": "documentation/reference/ingestion.html",
    "title": "ingestion",
    "section": "",
    "text": "vector_search.ingestion\n\n\n\n\n\nName\nDescription\n\n\n\n\ningest\nIngest vectors into TileDB.\n\n\n\n\n\nvector_search.ingestion.ingest(index_type, index_uri, source_uri, source_type, *, config=None, namespace=None, size=-1, partitions=-1, copy_centroids_uri=None, training_sample_size=-1, workers=-1, input_vectors_per_work_item=-1, verbose=False, trace_id=None, mode=Mode.LOCAL)\nIngest vectors into TileDB.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nindex_type\nstr\nType of vector index (FLAT, IVF_FLAT)\nrequired\n\n\nindex_uri\nstr\nVector index URI (stored as TileDB group)\nrequired\n\n\nsource_uri\nstr\nData source URI\nrequired\n\n\nsource_type\nstr\nType of the source data\nrequired\n\n\nconfig\n\nconfig dictionary, defaults to None\nNone\n\n\nnamespace\ntyping.Optional[str]\nTileDB-Cloud namespace, defaults to None\nNone\n\n\nsize\nint\nNumber of input vectors, if not provided use the full size of the input dataset\n-1\n\n\npartitions\nint\nNumber of partitions to load the data with, if not provided, is auto-configured based on the dataset size\n-1\n\n\ncopy_centroids_uri\nstr\nTileDB array URI to copy centroids from, if not provided, centroids are build running kmeans\nNone\n\n\ntraining_sample_size\nint\nvector sample size to train centroids with, if not provided, is auto-configured based on the dataset size\n-1\n\n\nworkers\nint\nnumber of workers for vector ingestion, if not provided, is auto-configured based on the dataset size\n-1\n\n\ninput_vectors_per_work_item\nint\nnumber of vectors per ingestion work item, if not provided, is auto-configured\n-1\n\n\nverbose\nbool\nverbose logging, defaults to False\nFalse\n\n\ntrace_id\ntyping.Optional[str]\ntrace ID for logging, defaults to None\nNone\n\n\nmode\nMode\nexecution mode, defaults to LOCAL use BATCH for distributed execution\nMode.LOCAL"
  },
  {
    "objectID": "documentation/reference/ingestion.html#functions",
    "href": "documentation/reference/ingestion.html#functions",
    "title": "ingestion",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ningest\nIngest vectors into TileDB.\n\n\n\n\n\nvector_search.ingestion.ingest(index_type, index_uri, source_uri, source_type, *, config=None, namespace=None, size=-1, partitions=-1, copy_centroids_uri=None, training_sample_size=-1, workers=-1, input_vectors_per_work_item=-1, verbose=False, trace_id=None, mode=Mode.LOCAL)\nIngest vectors into TileDB.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nindex_type\nstr\nType of vector index (FLAT, IVF_FLAT)\nrequired\n\n\nindex_uri\nstr\nVector index URI (stored as TileDB group)\nrequired\n\n\nsource_uri\nstr\nData source URI\nrequired\n\n\nsource_type\nstr\nType of the source data\nrequired\n\n\nconfig\n\nconfig dictionary, defaults to None\nNone\n\n\nnamespace\ntyping.Optional[str]\nTileDB-Cloud namespace, defaults to None\nNone\n\n\nsize\nint\nNumber of input vectors, if not provided use the full size of the input dataset\n-1\n\n\npartitions\nint\nNumber of partitions to load the data with, if not provided, is auto-configured based on the dataset size\n-1\n\n\ncopy_centroids_uri\nstr\nTileDB array URI to copy centroids from, if not provided, centroids are build running kmeans\nNone\n\n\ntraining_sample_size\nint\nvector sample size to train centroids with, if not provided, is auto-configured based on the dataset size\n-1\n\n\nworkers\nint\nnumber of workers for vector ingestion, if not provided, is auto-configured based on the dataset size\n-1\n\n\ninput_vectors_per_work_item\nint\nnumber of vectors per ingestion work item, if not provided, is auto-configured\n-1\n\n\nverbose\nbool\nverbose logging, defaults to False\nFalse\n\n\ntrace_id\ntyping.Optional[str]\ntrace ID for logging, defaults to None\nNone\n\n\nmode\nMode\nexecution mode, defaults to LOCAL use BATCH for distributed execution\nMode.LOCAL"
  },
  {
    "objectID": "documentation/reference/index.IVFFlatIndex.html",
    "href": "documentation/reference/index.IVFFlatIndex.html",
    "title": "index.IVFFlatIndex",
    "section": "",
    "text": "vector_search.index.IVFFlatIndex(self, uri, memory_budget=-1, config=None)\nOpen a IVF Flat index\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nuri\n\nURI of datataset\nrequired\n\n\ndtype\n\ndatatype float32 or uint8\nrequired\n\n\nmemory_budget\nint\nMain memory budget. If not provided no memory budget is applied.\n-1\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nquery\nQuery an IVF_FLAT index\n\n\ntaskgraph_query\nQuery an IVF_FLAT index using TileDB cloud taskgraphs\n\n\n\n\n\nvector_search.index.IVFFlatIndex.query(self, queries, k=10, nprobe=1, nthreads=-1, use_nuv_implementation=False, mode=None, num_partitions=-1, num_workers=-1)\nQuery an IVF_FLAT index\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnumpy.ndarray\nND Array of queries\nrequired\n\n\nk\nint\nNumber of top results to return per target\n10\n\n\nnprobe\nint\nnumber of probes\n1\n\n\nnthreads\nint\nNumber of threads to use for query\n-1\n\n\nuse_nuv_implementation\nbool\nwether to use the nuv query implementation. Default: False\nFalse\n\n\nmode\nMode\nIf provided the query will be executed using TileDB cloud taskgraphs. For distributed execution you can use REALTIME or BATCH mode\nNone\n\n\nnum_partitions\nint\nOnly relevant for taskgraph based execution. If provided, we split the query execution in that many partitions.\n-1\n\n\nnum_workers\nint\nOnly relevant for taskgraph based execution. If provided, this is the number of workers to use for the query execution.\n-1\n\n\n\n\n\n\n\nvector_search.index.IVFFlatIndex.taskgraph_query(self, queries, k=10, nprobe=10, nthreads=-1, mode=None, num_partitions=-1, num_workers=-1, config=None)\nQuery an IVF_FLAT index using TileDB cloud taskgraphs\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnumpy.ndarray\nND Array of queries\nrequired\n\n\nk\nint\nNumber of top results to return per target\n10\n\n\nnprobe\nint\nnumber of probes\n10\n\n\nnthreads\nint\nNumber of threads to use for query\n-1\n\n\nuse_nuv_implementation\n\nwether to use the nuv query implementation. Default: False\nrequired\n\n\nmode\nMode\nIf provided the query will be executed using TileDB cloud taskgraphs. For distributed execution you can use REALTIME or BATCH mode\nNone\n\n\nnum_partitions\nint\nOnly relevant for taskgraph based execution. If provided, we split the query execution in that many partitions.\n-1\n\n\nnum_workers\nint\nOnly relevant for taskgraph based execution. If provided, this is the number of workers to use for the query execution.\n-1"
  },
  {
    "objectID": "documentation/reference/index.IVFFlatIndex.html#parameters",
    "href": "documentation/reference/index.IVFFlatIndex.html#parameters",
    "title": "index.IVFFlatIndex",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nuri\n\nURI of datataset\nrequired\n\n\ndtype\n\ndatatype float32 or uint8\nrequired\n\n\nmemory_budget\nint\nMain memory budget. If not provided no memory budget is applied.\n-1"
  },
  {
    "objectID": "documentation/reference/index.IVFFlatIndex.html#methods",
    "href": "documentation/reference/index.IVFFlatIndex.html#methods",
    "title": "index.IVFFlatIndex",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nquery\nQuery an IVF_FLAT index\n\n\ntaskgraph_query\nQuery an IVF_FLAT index using TileDB cloud taskgraphs\n\n\n\n\n\nvector_search.index.IVFFlatIndex.query(self, queries, k=10, nprobe=1, nthreads=-1, use_nuv_implementation=False, mode=None, num_partitions=-1, num_workers=-1)\nQuery an IVF_FLAT index\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnumpy.ndarray\nND Array of queries\nrequired\n\n\nk\nint\nNumber of top results to return per target\n10\n\n\nnprobe\nint\nnumber of probes\n1\n\n\nnthreads\nint\nNumber of threads to use for query\n-1\n\n\nuse_nuv_implementation\nbool\nwether to use the nuv query implementation. Default: False\nFalse\n\n\nmode\nMode\nIf provided the query will be executed using TileDB cloud taskgraphs. For distributed execution you can use REALTIME or BATCH mode\nNone\n\n\nnum_partitions\nint\nOnly relevant for taskgraph based execution. If provided, we split the query execution in that many partitions.\n-1\n\n\nnum_workers\nint\nOnly relevant for taskgraph based execution. If provided, this is the number of workers to use for the query execution.\n-1\n\n\n\n\n\n\n\nvector_search.index.IVFFlatIndex.taskgraph_query(self, queries, k=10, nprobe=10, nthreads=-1, mode=None, num_partitions=-1, num_workers=-1, config=None)\nQuery an IVF_FLAT index using TileDB cloud taskgraphs\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nqueries\nnumpy.ndarray\nND Array of queries\nrequired\n\n\nk\nint\nNumber of top results to return per target\n10\n\n\nnprobe\nint\nnumber of probes\n10\n\n\nnthreads\nint\nNumber of threads to use for query\n-1\n\n\nuse_nuv_implementation\n\nwether to use the nuv query implementation. Default: False\nrequired\n\n\nmode\nMode\nIf provided the query will be executed using TileDB cloud taskgraphs. For distributed execution you can use REALTIME or BATCH mode\nNone\n\n\nnum_partitions\nint\nOnly relevant for taskgraph based execution. If provided, we split the query execution in that many partitions.\n-1\n\n\nnum_workers\nint\nOnly relevant for taskgraph based execution. If provided, this is the number of workers to use for the query execution.\n-1"
  }
]