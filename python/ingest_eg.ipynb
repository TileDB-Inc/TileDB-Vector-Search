{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d8527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tiledb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a68408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lums/TileDB/feature-vector-prototype/python\n"
     ]
    }
   ],
   "source": [
    "os.system('pwd');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43318e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = tiledb.Ctx().config()\n",
    "\n",
    "# cfg[\"py.init_buffer_bytes\"] = 1024**2 * 50\n",
    "# cfg[\"vfs.s3.scheme\"] = \"https\" \n",
    "# cfg[\"vfs.s3.region\"] = \"us-west-2\"\n",
    "# cfg[\"vfs.s3.endpoint_override\"] = \"\"\n",
    "# cfg[\"vfs.s3.use_virtual_addressing\"] = \"true\"\n",
    "# cfg[\"vfs.s3.aws_access_key_id\"] = \"AKIA2HZNSCDDICHRA6P2\";\n",
    "# cfg[\"vfs.s3.aws_secret_access_key\"] = \"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\";\n",
    "\n",
    "tiledb.default_ctx({\"vfs.s3.region\": \"us-west-2\"});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c28e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_info(filename):\n",
    "    # Check if filename exists\n",
    "    if (not os.path.exists(filename)):\n",
    "        raise Exception(f'{filename} does not exist.')\n",
    "\n",
    "    file_size = os.path.getsize(filename)\n",
    "    print(f'The size of {filename} is {file_size} bytes.')\n",
    "\n",
    "    f = open(filename, 'rb')\n",
    "    dimension = np.fromfile(f, dtype=np.int32, count=1)[0]\n",
    "    num_vectors = file_size // (4 + dimension * 4)   # Four bytes for float or int\n",
    "\n",
    "    print(f'num_vectors is {num_vectors}, dimension is {dimension}')\n",
    "    f.close()\n",
    "    \n",
    "    return num_vectors, dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d8f65f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fvecs_generator(filename, num_vectors, dimension, block_size):\n",
    "\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    if (ext == '.fvecs'):\n",
    "        element_type = np.float32\n",
    "    elif (ext == '.ivecs'):\n",
    "        element_type = np.int32\n",
    "    elif (ext == '.bvecs'):\n",
    "        element_type = np.uint8\n",
    "    else:\n",
    "        raise Exception(f'Unkown extension {ext}')\n",
    "    \n",
    "    f = open(filename, 'rb')\n",
    "    \n",
    "    num_vectors_read = 0\n",
    "    chunk_size = block_size * (dimension + 1)  # number of vectors by number of elements / vector\n",
    "    print(f'In generator chunk_size is {chunk_size}, block_size is {block_size}, dimension is {dimension}')\n",
    "    while True:\n",
    "        count = block_size\n",
    "        if ((num_vectors_read + block_size) > num_vectors):\n",
    "            count = (num_vectors_read + block_size) - num_vectors\n",
    "\n",
    "        chunk_size = count * (dimension + 1)\n",
    "        # chunk_size is number of elements\n",
    "        # if num_vectors // block_size == 0\n",
    "        # remaining vectors is num_vectors % block_size\n",
    "\n",
    "        chunk = np.fromfile(f, dtype=element_type, count=chunk_size)\n",
    "        if chunk.size == 0:\n",
    "            if (num_vectors_read != num_vectors):\n",
    "                raise Exception(f'{num_vectors_read} != {num_vectors}')\n",
    "            break\n",
    "        \n",
    "        # print(f'before reshape chunk is {type(chunk)} and size {chunk.shape}')\n",
    "        b = chunk.reshape(count, dimension+1)\n",
    "        b = np.transpose(b[:, 1:dimension+1])\n",
    "            \n",
    "        num_vectors_read = num_vectors_read + block_size\n",
    "\n",
    "        # print(f'after reshape chunk is {type(b)} and size {b.shape}')\n",
    "\n",
    "        yield b\n",
    "    print(f'total read {num_vectors_read}'')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3d1f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_array(array_name, num_vectors, dimension, tile_size):\n",
    "    \n",
    "    print(f'Creating array {array_name}: {dimension} by {num_vectors} with tile_size {tile_size}')\n",
    "    \n",
    "    # The array will be dimension by num_vectors                                                  \n",
    "    dom = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"rows\", domain=(0, dimension-1), tile=dimension, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"cols\", domain=(0, num_vectors-1), tile=tile_size, dtype=np.int32),\n",
    "    )\n",
    "\n",
    "    # The array will be dense with a single attribute \"a\" so each (i,j) cell can store a float.                                  \n",
    "    schema = tiledb.ArraySchema(\n",
    "        domain=dom, sparse=False, attrs=[tiledb.Attr(name=\"a\", dtype=np.float32)], \n",
    "        cell_order='col-major', tile_order='col-major'\n",
    "    )\n",
    "\n",
    "    # Create the (empty) array on disk.   \n",
    "    if (tiledb.object_type(array_name) == \"array\"):\n",
    "        print(f\"Array {array_name} already exists.  Deleting\")\n",
    "        tiledb.remove(array_name)\n",
    "    tiledb.DenseArray.create(array_name, schema)\n",
    "    \n",
    "    # Check size\n",
    "    # with tiledb.DenseArray(array_name, mode=\"r\") as A:\n",
    "    #    data = A[:]\n",
    "    #    print(f'After creation, array shape is {data[\"a\"].shape}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcd7da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_array(array_name, num_vectors, dimension, block_size):\n",
    "\n",
    "    print(f'Opening array {array_name} for writing with num_vectors {num_vectors} and dimension {dimension}')\n",
    "    \n",
    "    # Open the TileDB array for writing\n",
    "    A = tiledb.DenseArray(array_name, mode='w')\n",
    "\n",
    "    # Read data blocks from the file and write them to the TileDB array\n",
    "    generator = fvecs_generator(filename, num_vectors, dimension, block_size)\n",
    "\n",
    "    begin = 0\n",
    "    for block in generator:\n",
    "        # print(f'Read block number {begin} : block is {type(block)} with shape {block.shape}')\n",
    "        A[0:dimension, begin*block_size:(begin+1)*block_size] = block\n",
    "        begin = begin + 1\n",
    "        if begin*block_size >= num_vectors:\n",
    "            break\n",
    "\n",
    "    # Close the TileDB array\n",
    "    A.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0794bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '/Users/lums/TileDB/feature-vector-prototype/external/data/sift/sift_base.fvecs'\n",
    "# array_name = 'sift_base'\n",
    "# array_name = 's3://tiledb-lums/sift_base'\n",
    "# array_name = 'tiledb://lums/sift_base'\n",
    "# array_name = 'https://tiledb-lums.s3.amazonaws.com/sift_base'\n",
    "# array_name = 'https://tiledb-lums.s3-us-west-2.amazonaws.com/sift_base'\n",
    "\n",
    "const_block_size = 10000\n",
    "# const_dim = 128\n",
    "tile_size = const_block_size\n",
    "# tile_size = const_dim\n",
    "\n",
    "\n",
    "# filename = '/Users/lums/TileDB/feature-vector-prototype/external/data/sift/sift_base.fvecs'\n",
    "# array_name = 's3://tiledb-lums/sift_base'\n",
    "\n",
    "\n",
    "filebase = '/Users/lums/TileDB/feature-vector-prototype/external/data'\n",
    "array_base = 's3://tiledb-lums'\n",
    "\n",
    "files = ['siftsmall/siftsmall_base.fvecs',\n",
    "        'siftsmall/siftsmall_groundtruth.ivecs',\n",
    "        'siftsmall/siftsmall_learn.fvecs',\n",
    "        'siftsmall/siftsmall_query.fvecs',\n",
    "        'sift/sift_base.fvecs',\n",
    "        'sift/sift_groundtruth.ivecs',\n",
    "        'sift/sift_learn.fvecs',\n",
    "        'sift/sift_query.fvecs']\n",
    "\n",
    "arrays= ['siftsmall_base',\n",
    "        'siftsmall_groundtruth',\n",
    "        'siftsmall_learn',\n",
    "        'siftsmall_query',\n",
    "        'sift_base',\n",
    "        'sift_groundtruth',\n",
    "        'sift_learn',\n",
    "        'sift_query']\n",
    "\n",
    "for f, a in zip(files, arrays):\n",
    "    filename = os.path.join(filebase, f)\n",
    "    array_name = os.path.join(array_base, a)\n",
    "    print(f'{filename} -> {array_name}')\n",
    "\n",
    "    num_vectors, dimension = get_data_info(filename)\n",
    "    tile_size = min(num_vectors, const_block_size)\n",
    "    block_size = min(num_vectors, const_block_size)\n",
    "    create_array(array_name, num_vectors, dimension, tile_size)\n",
    "    write_array(array_name, num_vectors, dimension, block_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f92a01",
   "metadata": {},
   "source": [
    "### For bigann compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89909b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import io\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f1d6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_bvecs_gz(filename):\n",
    "    # Check if filename exists\n",
    "    if (not os.path.exists(filename)):\n",
    "        raise Exception(f'{filename} does not exist.')\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    if (ext != '.gz'):\n",
    "        raise Exception(f'{filename} is not a gz file')\n",
    "    \n",
    "    base, ext = os.path.splitext(base)\n",
    "    if (ext != '.bvecs'):\n",
    "        raise Exception(f'{filename} is not a bvecs file')\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1dd288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gz_data_info(filename):\n",
    "    \n",
    "    # Check if filename exists\n",
    "    if (not is_valid_bvecs_gz(filename)):\n",
    "        raise Exception(f'Invalid file {filename}')\n",
    "\n",
    "    file_size = os.path.getsize(filename)\n",
    "    print(f'The size of the compressed {filename} is {file_size} bytes.')\n",
    "\n",
    "    # bigann_query.bvecs.gz\n",
    "    uncompressed_chunk_size = 4   # one int32\n",
    "\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        with io.BufferedReader(f, buffer_size=uncompressed_chunk_size) as reader:\n",
    "            bytes = reader.read(uncompressed_chunk_size)\n",
    "            if not bytes:\n",
    "                raise Exception('Could not get dimension size')\n",
    "            # Process chunk of uncompressed data\n",
    "            print(f'Read {len(bytes)} bytes')\n",
    "\n",
    "            dimension = np.frombuffer(bytes, dtype=np.int32, count=1)[0]\n",
    "            print(f'dimension is {dimension}')\n",
    "       \n",
    "    f.close()\n",
    "    \n",
    "    return None, dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3609116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bvecs_gz_generator(filename, num_vectors, dimension, block_size):\n",
    "    \n",
    "    # Check if filename exists\n",
    "    if (not is_valid_bvecs_gz(filename)):\n",
    "        raise Exception(f'Invalid file {filename}')\n",
    "    \n",
    "    element_type = np.uint8\n",
    "    \n",
    "    uncompressed_chunk_size = block_size * (dimension + 1)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        with io.BufferedReader(f, buffer_size=uncompressed_chunk_size) as reader:\n",
    "                \n",
    "            num_vectors_read = 0\n",
    "            \n",
    "            print(f'In generator uncompressed_chunk_size is {uncompressed_chunk_size}, block_size is {block_size}, dimension is {dimension}')\n",
    "            print(f'        num_vectors is {num_vectors}')\n",
    "            while True:\n",
    "                count = block_size\n",
    "                if ((num_vectors_read + block_size) > num_vectors):\n",
    "                    count = (num_vectors_read + block_size) - num_vectors\n",
    "\n",
    "                uncompressed_chunk_size = count * (dimension + 1)\n",
    "                bytes = reader.read(uncompressed_chunk_size * 4)\n",
    "                \n",
    "                print(f'In generator uncompressed_chunk_size is {uncompressed_chunk_size}, block_size is {block_size}, dimension is {dimension}')\n",
    "                print(f'    count is {count}, lenbytes is {len(bytes)}')\n",
    "                if (len(bytes) == 0):\n",
    "                    print(f'end of file len_bytes is {len(bytes)}')\n",
    "                    break\n",
    "                chunk = np.frombuffer(bytes, dtype=element_type, count=uncompressed_chunk_size)\n",
    "                \n",
    "                if chunk.size == 0:\n",
    "                    print(f'end of file')\n",
    "                    if (num_vectors_read != num_vectors):\n",
    "                        raise Exception(f'{num_vectors_read} != {num_vectors}')\n",
    "                    break\n",
    "                if (num_vectors_read == num_vectors):\n",
    "                    print(f'read to {num_vectors_read} == {num_vectors}')\n",
    "                    break\n",
    "        \n",
    "                # print(f'before reshape chunk is {type(chunk)} and size {chunk.shape}')\n",
    "                b = chunk.reshape(count, dimension+1)\n",
    "                b = np.transpose(b[:, 1:dimension+1])\n",
    "                    \n",
    "                num_vectors_read = num_vectors_read + block_size\n",
    "                \n",
    "                print(f'num_vectors_read is {num_vectors_read} of {num_vectors}')\n",
    "\n",
    "                # print(f'after reshape chunk is {type(b)} and size {b.shape}')\n",
    "\n",
    "                yield b\n",
    "       \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5cd6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_gz_array(array_name, num_vectors, dimension, block_size):\n",
    "\n",
    "    print(f'Opening array {array_name} for writing with num_vectors {num_vectors} and dimension {dimension}')\n",
    "    \n",
    "    # Open the TileDB array for writing\n",
    "    A = tiledb.DenseArray(array_name, mode='w')\n",
    "\n",
    "    # Read data blocks from the file and write them to the TileDB array\n",
    "    generator = bvecs_gz_generator(filename, num_vectors, dimension, block_size)\n",
    "\n",
    "    begin = 0\n",
    "    for block in generator:\n",
    "        \n",
    "        print(f'Read block number {begin} : block is {type(block)} with shape {block.shape}')\n",
    "        \n",
    "        A[0:dimension, begin*block_size:(begin+1)*block_size] = block\n",
    "        begin = begin + 1\n",
    "        if begin*block_size >= num_vectors:\n",
    "            break\n",
    "\n",
    "    # Close the TileDB array\n",
    "    A.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3feb573a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lums/TileDB/feature-vector-prototype/external/data/bigann_query.bvecs.gz -> s3://tiledb-lums/sift/bigann_query\n",
      "The size of the compressed /Users/lums/TileDB/feature-vector-prototype/external/data/bigann_query.bvecs.gz is 986411 bytes.\n",
      "Read 4 bytes\n",
      "dimension is 128\n",
      "Creating array s3://tiledb-lums/sift/bigann_query: 128 by 10000 with tile_size 10000\n",
      "Array s3://tiledb-lums/sift/bigann_query already exists.  Deleting\n",
      "Opening array s3://tiledb-lums/sift/bigann_query for writing with num_vectors 10000 and dimension 128\n",
      "In generator uncompressed_chunk_size is 1290000, block_size is 10000, dimension is 128\n",
      "        num_vectors is 10000\n",
      "In generator uncompressed_chunk_size is 1290000, block_size is 10000, dimension is 128\n",
      "    count is 10000, lenbytes is 1320000\n",
      "num_vectors_read is 10000 of 10000\n",
      "Read block number 0 : block is <class 'numpy.ndarray'> with shape (128, 10000)\n",
      "/Users/lums/TileDB/feature-vector-prototype/external/data/bigann_learn.bvecs.gz -> s3://tiledb-lums/sift/bigann_learn\n",
      "The size of the compressed /Users/lums/TileDB/feature-vector-prototype/external/data/bigann_learn.bvecs.gz is 9746888942 bytes.\n",
      "Read 4 bytes\n",
      "dimension is 128\n",
      "Creating array s3://tiledb-lums/sift/bigann_learn: 128 by 100000000 with tile_size 1000000\n",
      "Array s3://tiledb-lums/sift/bigann_learn already exists.  Deleting\n",
      "Opening array s3://tiledb-lums/sift/bigann_learn for writing with num_vectors 100000000 and dimension 128\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "        num_vectors is 100000000\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 1000000 of 100000000\n",
      "Read block number 0 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 2000000 of 100000000\n",
      "Read block number 1 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 3000000 of 100000000\n",
      "Read block number 2 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 4000000 of 100000000\n",
      "Read block number 3 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 5000000 of 100000000\n",
      "Read block number 4 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 6000000 of 100000000\n",
      "Read block number 5 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 7000000 of 100000000\n",
      "Read block number 6 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 8000000 of 100000000\n",
      "Read block number 7 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 9000000 of 100000000\n",
      "Read block number 8 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 10000000 of 100000000\n",
      "Read block number 9 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 11000000 of 100000000\n",
      "Read block number 10 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 12000000 of 100000000\n",
      "Read block number 11 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 13000000 of 100000000\n",
      "Read block number 12 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 14000000 of 100000000\n",
      "Read block number 13 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 15000000 of 100000000\n",
      "Read block number 14 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 16000000 of 100000000\n",
      "Read block number 15 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 17000000 of 100000000\n",
      "Read block number 16 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 18000000 of 100000000\n",
      "Read block number 17 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 19000000 of 100000000\n",
      "Read block number 18 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 20000000 of 100000000\n",
      "Read block number 19 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 21000000 of 100000000\n",
      "Read block number 20 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 22000000 of 100000000\n",
      "Read block number 21 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 23000000 of 100000000\n",
      "Read block number 22 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 24000000 of 100000000\n",
      "Read block number 23 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 25000000 of 100000000\n",
      "Read block number 24 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 300000000\n",
      "num_vectors_read is 26000000 of 100000000\n",
      "Read block number 25 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 0\n",
      "end of file len_bytes is 0\n",
      "/Users/lums/TileDB/feature-vector-prototype/external/data/bigann_base.bvecs.gz -> s3://tiledb-lums/sift/bigann_base\n",
      "The size of the compressed /Users/lums/TileDB/feature-vector-prototype/external/data/bigann_base.bvecs.gz is 97941899519 bytes.\n",
      "Read 4 bytes\n",
      "dimension is 128\n",
      "Creating array s3://tiledb-lums/sift/bigann_base: 128 by 1000000000 with tile_size 1000000\n",
      "Array s3://tiledb-lums/sift/bigann_base already exists.  Deleting\n",
      "Opening array s3://tiledb-lums/sift/bigann_base for writing with num_vectors 1000000000 and dimension 128\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "        num_vectors is 1000000000\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 1000000 of 1000000000\n",
      "Read block number 0 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 2000000 of 1000000000\n",
      "Read block number 1 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 3000000 of 1000000000\n",
      "Read block number 2 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 4000000 of 1000000000\n",
      "Read block number 3 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 5000000 of 1000000000\n",
      "Read block number 4 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 6000000 of 1000000000\n",
      "Read block number 5 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 7000000 of 1000000000\n",
      "Read block number 6 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 8000000 of 1000000000\n",
      "Read block number 7 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 9000000 of 1000000000\n",
      "Read block number 8 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 10000000 of 1000000000\n",
      "Read block number 9 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 11000000 of 1000000000\n",
      "Read block number 10 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 12000000 of 1000000000\n",
      "Read block number 11 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 13000000 of 1000000000\n",
      "Read block number 12 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 14000000 of 1000000000\n",
      "Read block number 13 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 15000000 of 1000000000\n",
      "Read block number 14 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 16000000 of 1000000000\n",
      "Read block number 15 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 17000000 of 1000000000\n",
      "Read block number 16 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 18000000 of 1000000000\n",
      "Read block number 17 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 19000000 of 1000000000\n",
      "Read block number 18 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 20000000 of 1000000000\n",
      "Read block number 19 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 21000000 of 1000000000\n",
      "Read block number 20 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 22000000 of 1000000000\n",
      "Read block number 21 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 23000000 of 1000000000\n",
      "Read block number 22 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 24000000 of 1000000000\n",
      "Read block number 23 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 25000000 of 1000000000\n",
      "Read block number 24 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 26000000 of 1000000000\n",
      "Read block number 25 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 27000000 of 1000000000\n",
      "Read block number 26 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 28000000 of 1000000000\n",
      "Read block number 27 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 29000000 of 1000000000\n",
      "Read block number 28 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 30000000 of 1000000000\n",
      "Read block number 29 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 31000000 of 1000000000\n",
      "Read block number 30 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 32000000 of 1000000000\n",
      "Read block number 31 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 33000000 of 1000000000\n",
      "Read block number 32 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 34000000 of 1000000000\n",
      "Read block number 33 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 35000000 of 1000000000\n",
      "Read block number 34 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 36000000 of 1000000000\n",
      "Read block number 35 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 37000000 of 1000000000\n",
      "Read block number 36 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 38000000 of 1000000000\n",
      "Read block number 37 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 39000000 of 1000000000\n",
      "Read block number 38 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 40000000 of 1000000000\n",
      "Read block number 39 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 41000000 of 1000000000\n",
      "Read block number 40 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 42000000 of 1000000000\n",
      "Read block number 41 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 43000000 of 1000000000\n",
      "Read block number 42 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 44000000 of 1000000000\n",
      "Read block number 43 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 45000000 of 1000000000\n",
      "Read block number 44 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 46000000 of 1000000000\n",
      "Read block number 45 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 47000000 of 1000000000\n",
      "Read block number 46 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 48000000 of 1000000000\n",
      "Read block number 47 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 49000000 of 1000000000\n",
      "Read block number 48 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 50000000 of 1000000000\n",
      "Read block number 49 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 51000000 of 1000000000\n",
      "Read block number 50 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 52000000 of 1000000000\n",
      "Read block number 51 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 53000000 of 1000000000\n",
      "Read block number 52 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 54000000 of 1000000000\n",
      "Read block number 53 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 55000000 of 1000000000\n",
      "Read block number 54 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 56000000 of 1000000000\n",
      "Read block number 55 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 57000000 of 1000000000\n",
      "Read block number 56 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 58000000 of 1000000000\n",
      "Read block number 57 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 59000000 of 1000000000\n",
      "Read block number 58 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 60000000 of 1000000000\n",
      "Read block number 59 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 61000000 of 1000000000\n",
      "Read block number 60 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 62000000 of 1000000000\n",
      "Read block number 61 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 63000000 of 1000000000\n",
      "Read block number 62 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 64000000 of 1000000000\n",
      "Read block number 63 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 65000000 of 1000000000\n",
      "Read block number 64 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 66000000 of 1000000000\n",
      "Read block number 65 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 67000000 of 1000000000\n",
      "Read block number 66 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 68000000 of 1000000000\n",
      "Read block number 67 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 69000000 of 1000000000\n",
      "Read block number 68 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 70000000 of 1000000000\n",
      "Read block number 69 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 71000000 of 1000000000\n",
      "Read block number 70 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 72000000 of 1000000000\n",
      "Read block number 71 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 73000000 of 1000000000\n",
      "Read block number 72 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 74000000 of 1000000000\n",
      "Read block number 73 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 75000000 of 1000000000\n",
      "Read block number 74 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 76000000 of 1000000000\n",
      "Read block number 75 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 77000000 of 1000000000\n",
      "Read block number 76 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 78000000 of 1000000000\n",
      "Read block number 77 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 79000000 of 1000000000\n",
      "Read block number 78 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 80000000 of 1000000000\n",
      "Read block number 79 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 81000000 of 1000000000\n",
      "Read block number 80 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 82000000 of 1000000000\n",
      "Read block number 81 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 83000000 of 1000000000\n",
      "Read block number 82 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 84000000 of 1000000000\n",
      "Read block number 83 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 85000000 of 1000000000\n",
      "Read block number 84 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 86000000 of 1000000000\n",
      "Read block number 85 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 87000000 of 1000000000\n",
      "Read block number 86 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 88000000 of 1000000000\n",
      "Read block number 87 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 89000000 of 1000000000\n",
      "Read block number 88 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 90000000 of 1000000000\n",
      "Read block number 89 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 91000000 of 1000000000\n",
      "Read block number 90 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 92000000 of 1000000000\n",
      "Read block number 91 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 93000000 of 1000000000\n",
      "Read block number 92 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 94000000 of 1000000000\n",
      "Read block number 93 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 95000000 of 1000000000\n",
      "Read block number 94 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 96000000 of 1000000000\n",
      "Read block number 95 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 97000000 of 1000000000\n",
      "Read block number 96 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 98000000 of 1000000000\n",
      "Read block number 97 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 99000000 of 1000000000\n",
      "Read block number 98 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 100000000 of 1000000000\n",
      "Read block number 99 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 101000000 of 1000000000\n",
      "Read block number 100 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 102000000 of 1000000000\n",
      "Read block number 101 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 103000000 of 1000000000\n",
      "Read block number 102 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 104000000 of 1000000000\n",
      "Read block number 103 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 105000000 of 1000000000\n",
      "Read block number 104 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 106000000 of 1000000000\n",
      "Read block number 105 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 107000000 of 1000000000\n",
      "Read block number 106 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 108000000 of 1000000000\n",
      "Read block number 107 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 109000000 of 1000000000\n",
      "Read block number 108 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 110000000 of 1000000000\n",
      "Read block number 109 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 111000000 of 1000000000\n",
      "Read block number 110 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 112000000 of 1000000000\n",
      "Read block number 111 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 113000000 of 1000000000\n",
      "Read block number 112 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 114000000 of 1000000000\n",
      "Read block number 113 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 115000000 of 1000000000\n",
      "Read block number 114 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 116000000 of 1000000000\n",
      "Read block number 115 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 117000000 of 1000000000\n",
      "Read block number 116 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 118000000 of 1000000000\n",
      "Read block number 117 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 119000000 of 1000000000\n",
      "Read block number 118 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 120000000 of 1000000000\n",
      "Read block number 119 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 121000000 of 1000000000\n",
      "Read block number 120 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 122000000 of 1000000000\n",
      "Read block number 121 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 123000000 of 1000000000\n",
      "Read block number 122 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 124000000 of 1000000000\n",
      "Read block number 123 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 125000000 of 1000000000\n",
      "Read block number 124 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 126000000 of 1000000000\n",
      "Read block number 125 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 127000000 of 1000000000\n",
      "Read block number 126 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 128000000 of 1000000000\n",
      "Read block number 127 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 129000000 of 1000000000\n",
      "Read block number 128 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 130000000 of 1000000000\n",
      "Read block number 129 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 131000000 of 1000000000\n",
      "Read block number 130 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 132000000 of 1000000000\n",
      "Read block number 131 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 133000000 of 1000000000\n",
      "Read block number 132 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 134000000 of 1000000000\n",
      "Read block number 133 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 135000000 of 1000000000\n",
      "Read block number 134 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 136000000 of 1000000000\n",
      "Read block number 135 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 137000000 of 1000000000\n",
      "Read block number 136 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 138000000 of 1000000000\n",
      "Read block number 137 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 139000000 of 1000000000\n",
      "Read block number 138 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 140000000 of 1000000000\n",
      "Read block number 139 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 141000000 of 1000000000\n",
      "Read block number 140 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 142000000 of 1000000000\n",
      "Read block number 141 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 143000000 of 1000000000\n",
      "Read block number 142 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 144000000 of 1000000000\n",
      "Read block number 143 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 145000000 of 1000000000\n",
      "Read block number 144 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 146000000 of 1000000000\n",
      "Read block number 145 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 147000000 of 1000000000\n",
      "Read block number 146 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 148000000 of 1000000000\n",
      "Read block number 147 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 149000000 of 1000000000\n",
      "Read block number 148 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 150000000 of 1000000000\n",
      "Read block number 149 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 151000000 of 1000000000\n",
      "Read block number 150 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 152000000 of 1000000000\n",
      "Read block number 151 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 153000000 of 1000000000\n",
      "Read block number 152 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 154000000 of 1000000000\n",
      "Read block number 153 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 155000000 of 1000000000\n",
      "Read block number 154 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 156000000 of 1000000000\n",
      "Read block number 155 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 157000000 of 1000000000\n",
      "Read block number 156 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 158000000 of 1000000000\n",
      "Read block number 157 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 159000000 of 1000000000\n",
      "Read block number 158 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 160000000 of 1000000000\n",
      "Read block number 159 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 161000000 of 1000000000\n",
      "Read block number 160 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 162000000 of 1000000000\n",
      "Read block number 161 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 163000000 of 1000000000\n",
      "Read block number 162 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 164000000 of 1000000000\n",
      "Read block number 163 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 165000000 of 1000000000\n",
      "Read block number 164 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 166000000 of 1000000000\n",
      "Read block number 165 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 167000000 of 1000000000\n",
      "Read block number 166 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 168000000 of 1000000000\n",
      "Read block number 167 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 169000000 of 1000000000\n",
      "Read block number 168 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 170000000 of 1000000000\n",
      "Read block number 169 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 171000000 of 1000000000\n",
      "Read block number 170 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 172000000 of 1000000000\n",
      "Read block number 171 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 173000000 of 1000000000\n",
      "Read block number 172 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 174000000 of 1000000000\n",
      "Read block number 173 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 175000000 of 1000000000\n",
      "Read block number 174 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 176000000 of 1000000000\n",
      "Read block number 175 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 177000000 of 1000000000\n",
      "Read block number 176 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 178000000 of 1000000000\n",
      "Read block number 177 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 179000000 of 1000000000\n",
      "Read block number 178 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 180000000 of 1000000000\n",
      "Read block number 179 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 181000000 of 1000000000\n",
      "Read block number 180 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 182000000 of 1000000000\n",
      "Read block number 181 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 183000000 of 1000000000\n",
      "Read block number 182 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 184000000 of 1000000000\n",
      "Read block number 183 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 185000000 of 1000000000\n",
      "Read block number 184 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 186000000 of 1000000000\n",
      "Read block number 185 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 187000000 of 1000000000\n",
      "Read block number 186 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 188000000 of 1000000000\n",
      "Read block number 187 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 189000000 of 1000000000\n",
      "Read block number 188 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 190000000 of 1000000000\n",
      "Read block number 189 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 191000000 of 1000000000\n",
      "Read block number 190 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 192000000 of 1000000000\n",
      "Read block number 191 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 193000000 of 1000000000\n",
      "Read block number 192 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 194000000 of 1000000000\n",
      "Read block number 193 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 195000000 of 1000000000\n",
      "Read block number 194 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 196000000 of 1000000000\n",
      "Read block number 195 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 197000000 of 1000000000\n",
      "Read block number 196 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 198000000 of 1000000000\n",
      "Read block number 197 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 199000000 of 1000000000\n",
      "Read block number 198 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 200000000 of 1000000000\n",
      "Read block number 199 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 201000000 of 1000000000\n",
      "Read block number 200 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 202000000 of 1000000000\n",
      "Read block number 201 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 203000000 of 1000000000\n",
      "Read block number 202 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 204000000 of 1000000000\n",
      "Read block number 203 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 205000000 of 1000000000\n",
      "Read block number 204 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 206000000 of 1000000000\n",
      "Read block number 205 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 207000000 of 1000000000\n",
      "Read block number 206 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 208000000 of 1000000000\n",
      "Read block number 207 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 209000000 of 1000000000\n",
      "Read block number 208 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 210000000 of 1000000000\n",
      "Read block number 209 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 211000000 of 1000000000\n",
      "Read block number 210 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 212000000 of 1000000000\n",
      "Read block number 211 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 213000000 of 1000000000\n",
      "Read block number 212 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 214000000 of 1000000000\n",
      "Read block number 213 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 215000000 of 1000000000\n",
      "Read block number 214 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 216000000 of 1000000000\n",
      "Read block number 215 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 217000000 of 1000000000\n",
      "Read block number 216 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 218000000 of 1000000000\n",
      "Read block number 217 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 219000000 of 1000000000\n",
      "Read block number 218 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 220000000 of 1000000000\n",
      "Read block number 219 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 221000000 of 1000000000\n",
      "Read block number 220 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 222000000 of 1000000000\n",
      "Read block number 221 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 223000000 of 1000000000\n",
      "Read block number 222 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 224000000 of 1000000000\n",
      "Read block number 223 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 225000000 of 1000000000\n",
      "Read block number 224 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 226000000 of 1000000000\n",
      "Read block number 225 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 227000000 of 1000000000\n",
      "Read block number 226 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 228000000 of 1000000000\n",
      "Read block number 227 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 229000000 of 1000000000\n",
      "Read block number 228 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 230000000 of 1000000000\n",
      "Read block number 229 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 231000000 of 1000000000\n",
      "Read block number 230 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 232000000 of 1000000000\n",
      "Read block number 231 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 233000000 of 1000000000\n",
      "Read block number 232 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 234000000 of 1000000000\n",
      "Read block number 233 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 235000000 of 1000000000\n",
      "Read block number 234 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 236000000 of 1000000000\n",
      "Read block number 235 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 237000000 of 1000000000\n",
      "Read block number 236 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 238000000 of 1000000000\n",
      "Read block number 237 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 239000000 of 1000000000\n",
      "Read block number 238 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 240000000 of 1000000000\n",
      "Read block number 239 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 241000000 of 1000000000\n",
      "Read block number 240 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 242000000 of 1000000000\n",
      "Read block number 241 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 243000000 of 1000000000\n",
      "Read block number 242 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 244000000 of 1000000000\n",
      "Read block number 243 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 245000000 of 1000000000\n",
      "Read block number 244 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 246000000 of 1000000000\n",
      "Read block number 245 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 247000000 of 1000000000\n",
      "Read block number 246 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 248000000 of 1000000000\n",
      "Read block number 247 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 249000000 of 1000000000\n",
      "Read block number 248 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 250000000 of 1000000000\n",
      "Read block number 249 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 251000000 of 1000000000\n",
      "Read block number 250 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 252000000 of 1000000000\n",
      "Read block number 251 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 253000000 of 1000000000\n",
      "Read block number 252 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 254000000 of 1000000000\n",
      "Read block number 253 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 516000000\n",
      "num_vectors_read is 255000000 of 1000000000\n",
      "Read block number 254 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 420000000\n",
      "num_vectors_read is 256000000 of 1000000000\n",
      "Read block number 255 : block is <class 'numpy.ndarray'> with shape (128, 1000000)\n",
      "In generator uncompressed_chunk_size is 129000000, block_size is 1000000, dimension is 128\n",
      "    count is 1000000, lenbytes is 0\n",
      "end of file len_bytes is 0\n"
     ]
    }
   ],
   "source": [
    "# filename = '/Users/lums/TileDB/feature-vector-prototype/external/data/sift/sift_base.fvecs'\n",
    "# array_name = 'sift_base'\n",
    "# array_name = 's3://tiledb-lums/sift_base'\n",
    "# array_name = 'tiledb://lums/sift_base'\n",
    "# array_name = 'https://tiledb-lums.s3.amazonaws.com/sift_base'\n",
    "# array_name = 'https://tiledb-lums.s3-us-west-2.amazonaws.com/sift_base'\n",
    "\n",
    "const_block_size = 1000000\n",
    "# const_dim = 128\n",
    "tile_size = const_block_size\n",
    "# tile_size = const_dim\n",
    "\n",
    "\n",
    "# filename = '/Users/lums/TileDB/feature-vector-prototype/external/data/sift/sift_base.fvecs'\n",
    "# array_name = 's3://tiledb-lums/sift_base'\n",
    "\n",
    "\n",
    "filebase = '/Users/lums/TileDB/feature-vector-prototype/external/data'\n",
    "array_base = 's3://tiledb-lums/sift'\n",
    "\n",
    "files = ['bigann_query.bvecs.gz',\n",
    "         'bigann_learn.bvecs.gz',\n",
    "         'bigann_base.bvecs.gz']\n",
    "\n",
    "arrays = ['bigann_query',\n",
    "          'bigann_learn',\n",
    "          'bigann_base']\n",
    "\n",
    "nums = [ 10000,\n",
    "         100000000,\n",
    "         1000000000]\n",
    "\n",
    "for f, a, num_vectors in zip(files, arrays, nums):\n",
    "    filename = os.path.join(filebase, f)\n",
    "    array_name = os.path.join(array_base, a)\n",
    "    print(f'{filename} -> {array_name}')\n",
    "\n",
    "    _, dimension = get_gz_data_info(filename)\n",
    "    tile_size = min(num_vectors, const_block_size)\n",
    "    block_size = min(num_vectors, const_block_size)\n",
    "    create_array(array_name, num_vectors, dimension, tile_size)\n",
    "    write_gz_array(array_name, num_vectors, dimension, block_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e51c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5069b1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/lums/TileDB/feature-vector-prototype/external/data/bigann_base.bvecs.gz'\n",
    "a, b = get_gz_data(filename)\n",
    "print(f'dimension b is {b}')\n",
    "g = fvecs_gz_generator(filename, 10, b, 5)\n",
    "print(f'g is {type(g)}')\n",
    "j = 0\n",
    "for i in g:\n",
    "    print(f'i is {type(i)} with shape {i.shape}')\n",
    "    if (j == 5):\n",
    "        break\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d07141b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24dd0645",
   "metadata": {},
   "source": [
    "### Some prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c49f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#bigann_query.bvecs.gz\n",
    "uncompressed_chunk_size = 1024 * 1024 # 1 MB chunk size\n",
    "i = 0\n",
    "with gzip.open('/Users/lums/TileDB/feature-vector-prototype/external/data/bigann_base.bvecs.gz', 'rb') as f:\n",
    "    with io.BufferedReader(f, buffer_size=uncompressed_chunk_size) as reader:\n",
    "        while i < 3:\n",
    "            bytes = reader.read(uncompressed_chunk_size)\n",
    "            if not bytes:\n",
    "                break\n",
    "            # Process chunk of uncompressed data\n",
    "            print(f'Read {len(bytes)} bytes')\n",
    "            chunk = np.frombuffer(bytes, dtype=np.uint8)\n",
    "            print(f'chunk is {len(chunk)}')\n",
    "            print(bytes[0:10])\n",
    "            print(chunk[0:10])\n",
    "            i = i+1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe32dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filebase = '/Users/lums/TileDB/feature-vector-prototype/external/data'\n",
    "array_base = 's3://tiledb-lums'\n",
    "\n",
    "files = ['siftsmall/siftsmall_base.fvecs',\n",
    "        'siftsmall/siftsmall_groundtruth.ivecs',\n",
    "        'siftsmall/siftsmall_learn.fvecs',\n",
    "        'siftsmall/siftsmall_query.fvecs',\n",
    "        'sift/sift_base.fvecs',\n",
    "        'sift/sift_groundtruth.ivecs',\n",
    "        'sift/sift_learn.fvecs',\n",
    "        'sift/sift_query.fvecs']\n",
    "arrays= ['siftsmall_base',\n",
    "        'siftsmall_groundtruth',\n",
    "        'siftsmall_learn',\n",
    "        'siftsmall_query',\n",
    "        'sift_base',\n",
    "        'sift_groundtruth',\n",
    "        'sift_learn',\n",
    "        'sift_query']\n",
    "\n",
    "for f, a in zip(files, arrays):\n",
    "    filename = os.path.join(filebase, f)\n",
    "    array_name = os.path.join(array_base, a)\n",
    "    print(f'{filename} -> {array_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f91616f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b9e83",
   "metadata": {},
   "source": [
    "### Some testing below here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b9b748",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d9f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiledb\n",
    "\n",
    "filename = '/Users/lums/TileDB/feature-vector-prototype/external/data/sift/sift_base.fvecs'\n",
    "array_name = 's3://tiledb-lums/sift_base'\n",
    "# array_name = 'sift_base'\n",
    "\n",
    "A = tiledb.open(array_name)\n",
    "f = open(filename, 'rb')\n",
    "dim = np.fromfile(f, dtype=np.int32, count=1)[0]\n",
    "\n",
    "chunk = np.fromfile(f, dtype=np.float32, count=dim * 1000000)\n",
    "B = chunk.reshape(1000000, dim)\n",
    "B = np.transpose(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'A is {type(A)} with shape {A.shape}')\n",
    "print(f'B is {type(A)} with shape {B.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e806204",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunk[0:10])\n",
    "print(A[0:10,0:5]['a'])\n",
    "print(B[0:10,0:5])\n",
    "\n",
    "A.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f141517a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00fe0a62",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9321b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import io\n",
    "\n",
    "#bigann_query.bvecs.gz\n",
    "uncompressed_chunk_size = 1024 * 1024 # 1 MB chunk size\n",
    "i = 0\n",
    "with gzip.open('/Users/lums/TileDB/feature-vector-prototype/external/data/bigann_base.bvecs.gz', 'rb') as f:\n",
    "    with io.BufferedReader(f, buffer_size=uncompressed_chunk_size) as reader:\n",
    "        while i < 3:\n",
    "            bytes = reader.read(uncompressed_chunk_size)\n",
    "            if not bytes:\n",
    "                break\n",
    "            # Process chunk of uncompressed data\n",
    "            print(f'Read {len(bytes)} bytes')\n",
    "            chunk = np.frombuffer(bytes, dtype=np.uint8)\n",
    "            print(f'chunk is {len(chunk)}')\n",
    "            print(bytes[0:10])\n",
    "            print(chunk[0:10])\n",
    "            i = i+1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7833c82",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa87d5e",
   "metadata": {},
   "source": [
    "### Cruft below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c89da0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9858a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2173cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b41d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the array to create.                                                                                                      \n",
    "array_name = \"writing_dense_multiple\"\n",
    "\n",
    "def create_array():\n",
    "    # The array will be 4x4 with dimensions \"rows\" and \"cols\", with domain [1,4].                                                   \n",
    "    dom = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"rows\", domain=(0, 3), tile=2, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"cols\", domain=(0, 4), tile=2, dtype=np.int32),\n",
    "    )\n",
    "\n",
    "    # The array will be dense with a single attribute \"a\" so each (i,j) cell can store an integer.                                  \n",
    "    schema = tiledb.ArraySchema(\n",
    "        domain=dom, sparse=False, attrs=[tiledb.Attr(name=\"a\", dtype=np.int32)]\n",
    "    )\n",
    "\n",
    "    # Create the (empty) array on disk.                                                                                             \n",
    "    tiledb.DenseArray.create(array_name, schema)\n",
    "\n",
    "\n",
    "def write_array():\n",
    "    # Open the array and write to it.                                                                                               \n",
    "    with tiledb.DenseArray(array_name, mode=\"w\") as A:\n",
    "        # First write                                                                                                               \n",
    "        data = np.array(([0, 22, 33], [2, 44, 77]))\n",
    "        A[0:2, 0:3] = data\n",
    "\n",
    "        # Second write                                                                                                              \n",
    "        data = np.array(([5, 6, 7, 8], [9, 10, 11, 12]))\n",
    "        A[1:3, 1:5] = data\n",
    "\n",
    "\n",
    "def read_array():\n",
    "    # Open the array and read from it.                                                                                              \n",
    "    with tiledb.DenseArray(array_name, mode=\"r\") as A:\n",
    "        # Slice the entire array                                                                                                    \n",
    "        data = A[:]\n",
    "        print(data[\"a\"])\n",
    "    return data\n",
    "\n",
    "\n",
    "if tiledb.object_type(array_name) != \"array\":\n",
    "    create_array()\n",
    "    write_array()\n",
    "\n",
    "data = read_array()\n",
    "\n",
    "print(f'data is {type(data[\"a\"])} with shape {data[\"a\"].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca9f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Name of the array to create.                                                                                                      \n",
    "array_name = \"writing_dense_multiple\"\n",
    "\n",
    "\n",
    "def create_array():\n",
    "    # The array will be 4x4 with dimensions \"rows\" and \"cols\", with domain [1,4].                                                   \n",
    "    dom = tiledb.Domain(\n",
    "        tiledb.Dim(name=\"rows\", domain=(1, 4), tile=2, dtype=np.int32),\n",
    "        tiledb.Dim(name=\"cols\", domain=(1, 4), tile=2, dtype=np.int32),\n",
    "    )\n",
    "\n",
    "    # The array will be dense with a single attribute \"a\" so each (i,j) cell can store an integer.                                  \n",
    "    schema = tiledb.ArraySchema(\n",
    "        domain=dom, sparse=False, attrs=[tiledb.Attr(name=\"a\", dtype=np.int32)]\n",
    "    )\n",
    "\n",
    "    # Create the (empty) array on disk.                                                                                             \n",
    "    tiledb.DenseArray.create(array_name, schema)\n",
    "    \n",
    "            # First write                                                                                                               \n",
    "        data = np.array(([1, 2], [3, 4]))\n",
    "        A[1:3, 1:3] = data\n",
    "\n",
    "        # Second write                                                                                                              \n",
    "        data = np.array(([5, 6, 7, 8], [9, 10, 11, 12]))\n",
    "        A[2:4, 1:5] = data\n",
    "\n",
    "\n",
    "def write_array():\n",
    "    # Open the array and write to it.                                                                                               \n",
    "    with tiledb.DenseArray(array_name, mode=\"w\") as A:\n",
    "        # First write                                                                                                               \n",
    "        data = np.array(([1, 2], [3, 4]))\n",
    "        A[1:3, 1:3] = data\n",
    "\n",
    "        # Second write                                                                                                              \n",
    "        data = np.array(([5, 6, 7, 8], [9, 10, 11, 12]))\n",
    "        A[2:4, 1:5] = data\n",
    "\n",
    "\n",
    "def read_array():\n",
    "    # Open the array and read from it.                                                                                              \n",
    "    with tiledb.DenseArray(array_name, mode=\"r\") as A:\n",
    "        # Slice the entire array                                                                                                    \n",
    "        data = A[:]\n",
    "        print(data[\"a\"])\n",
    "\n",
    "\n",
    "if tiledb.object_type(array_name) != \"array\":\n",
    "    create_array()\n",
    "    write_array()\n",
    "\n",
    "read_array()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e8011",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/lums/TileDB/feature-vector-prototype/external/data/sift/sift_base.fvecs'\n",
    "# array_name = 'sift_base'\n",
    "array_name = 's3://tiledb-lums/sift_base'\n",
    "tile_size = 100000\n",
    "block_size = 10000\n",
    "create_fvecs_array(filename, array_name, tile_size, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022d4fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fvecs_array(filename, array_name, tile_size, block_size):\n",
    "    with tiledb.from_numpy(array_name, np.zeros((0,))) as A:\n",
    "        dim = None\n",
    "        offset = 0\n",
    "        for block in fvecs_generator(filename, block_size):\n",
    "            if dim is None:\n",
    "                dim = block.shape[1]\n",
    "                A.schema.set_domain((0, None), (0, dim))\n",
    "                A.schema.set_tile((tile_size, dim))\n",
    "                A.schema.set_cell_order(tiledb.Layout.ROW_MAJOR)\n",
    "                A.schema.set_sparse(False)\n",
    "                A.schema.set_attrs(tiledb.Attr(\"features\", dtype=np.float32, var=False))\n",
    "            num_rows = block.shape[0]\n",
    "            A[offset:offset+num_rows] = block\n",
    "            offset += num_rows\n",
    "    A.schema.set_capacity(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35bb066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2675bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf2d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/lums/TileDB/feature-vector-prototype/external/data/sift/sift_base.fvecs'\n",
    "block_size = 1000\n",
    "dimension = 128\n",
    "gen = fvecs_generator(filename, block_size, dimension)\n",
    "a = next(gen)\n",
    "print(f'a is {type(a)} with shape {a.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9b5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e3566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tiledb\n",
    "\n",
    "def fvecs_generator(filename, block_size):\n",
    "    f = open(filename, 'rb')\n",
    "    dim = np.fromfile(f, dtype=np.int32, count=1)[0]\n",
    "    chunk_size = block_size * dim\n",
    "    while True:\n",
    "        chunk = np.fromfile(f, dtype=np.float32, count=chunk_size)\n",
    "        if chunk.size == 0:\n",
    "            break\n",
    "        yield chunk.reshape((-1, dim))\n",
    "    f.close()\n",
    "\n",
    "def create_fvecs_array(filename, array_name, tile_size, block_size):\n",
    "    with tiledb.from_numpy(array_name, np.zeros((0,))) as A:\n",
    "        dim = None\n",
    "        offset = 0\n",
    "        for block in fvecs_generator(filename, block_size):\n",
    "            if dim is None:\n",
    "                dim = block.shape[1]\n",
    "                A.schema.set_domain((0, None), (0, dim))\n",
    "                A.schema.set_tile((tile_size, dim))\n",
    "                A.schema.set_cell_order(tiledb.Layout.ROW_MAJOR)\n",
    "                A.schema.set_sparse(False)\n",
    "                A.schema.set_attrs(tiledb.Attr(\"features\", dtype=np.float32, var=False))\n",
    "            num_rows = block.shape[0]\n",
    "            A[offset:offset+num_rows] = block\n",
    "            offset += num_rows\n",
    "    A.schema.set_capacity(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e8833",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'external/data/sift/sift_base.fvecs'\n",
    "array_name = 'sift_base'\n",
    "tile_size = 100000\n",
    "block_size = 10000\n",
    "create_fvecs_array(filename, array_name, tile_size, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0dd079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
